<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Nipun Batra</title><link>http://nipunbatra.github.io/</link><description></description><atom:link href="http://nipunbatra.github.io/feeds/nipunbatra.rss.xml" rel="self"></atom:link><lastBuildDate>Tue, 09 Jun 2015 19:22:00 +0530</lastBuildDate><item><title>Efficiently iterating Pandas rows</title><link>http://nipunbatra.github.io/2015/06/pandas-iteration/</link><description>&lt;p&gt;Often in my Pandas code, I've had to iterate through the rows. The first thing which comes to mind (as would do to any one who has studied C/C++ as the first language) is to access elements by index and loop on the index. This is considered "unPythonic". For this exact same reason, for loops in Python are written as &lt;code&gt;for a in list&lt;/code&gt;. So, here's a quick comparison of two ways of iterating row-wise over a dataframe and accessing different attributes. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;di&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;a&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;b&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;c&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;d&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]}&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;di&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; 
             &lt;span class="n"&gt;a&lt;/span&gt;         &lt;span class="n"&gt;b&lt;/span&gt;         &lt;span class="n"&gt;c&lt;/span&gt;         &lt;span class="n"&gt;d&lt;/span&gt;
&lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.924205&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.278529&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.261998&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.005286&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;     &lt;span class="mf"&gt;0.392045&lt;/span&gt;  &lt;span class="mf"&gt;1.609994&lt;/span&gt;  &lt;span class="mf"&gt;1.733763&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.539745&lt;/span&gt;
&lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.085711&lt;/span&gt;  &lt;span class="mf"&gt;0.756263&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.084361&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.424867&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;2.082346&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.593061&lt;/span&gt;  &lt;span class="mf"&gt;0.758439&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.522798&lt;/span&gt;
&lt;span class="mi"&gt;4&lt;/span&gt;     &lt;span class="mf"&gt;1.064134&lt;/span&gt;  &lt;span class="mf"&gt;0.307272&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.829989&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.373749&lt;/span&gt;
&lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;2.428269&lt;/span&gt;  &lt;span class="mf"&gt;0.601626&lt;/span&gt;  &lt;span class="mf"&gt;1.421557&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.451481&lt;/span&gt;
&lt;span class="mi"&gt;6&lt;/span&gt;     &lt;span class="mf"&gt;0.926092&lt;/span&gt;  &lt;span class="mf"&gt;0.100844&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.553302&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.135587&lt;/span&gt;
&lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.302778&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.064894&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.207799&lt;/span&gt;  &lt;span class="mf"&gt;0.729668&lt;/span&gt;
&lt;span class="mi"&gt;8&lt;/span&gt;     &lt;span class="mf"&gt;1.428392&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.144769&lt;/span&gt;  &lt;span class="mf"&gt;0.567246&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.119571&lt;/span&gt;
&lt;span class="mi"&gt;9&lt;/span&gt;     &lt;span class="mf"&gt;0.619530&lt;/span&gt;  &lt;span class="mf"&gt;1.140406&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.576779&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.522187&lt;/span&gt;
&lt;span class="mi"&gt;10&lt;/span&gt;   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.281899&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.375088&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.775103&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.618582&lt;/span&gt;
&lt;span class="mi"&gt;11&lt;/span&gt;    &lt;span class="mf"&gt;1.773310&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.416744&lt;/span&gt;  &lt;span class="mf"&gt;0.274547&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.060010&lt;/span&gt;
&lt;span class="mi"&gt;12&lt;/span&gt;   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.204412&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.999966&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.055934&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.275807&lt;/span&gt;
&lt;span class="mi"&gt;13&lt;/span&gt;    &lt;span class="mf"&gt;0.438753&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.375763&lt;/span&gt;  &lt;span class="mf"&gt;1.540492&lt;/span&gt;  &lt;span class="mf"&gt;0.902932&lt;/span&gt;
&lt;span class="mi"&gt;14&lt;/span&gt;    &lt;span class="mf"&gt;1.259921&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.532213&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.092128&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.384513&lt;/span&gt;
&lt;span class="mi"&gt;15&lt;/span&gt;   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.524382&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.344728&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.593565&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.821939&lt;/span&gt;
&lt;span class="mi"&gt;16&lt;/span&gt;   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.428570&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.054547&lt;/span&gt;  &lt;span class="mf"&gt;0.330548&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.161294&lt;/span&gt;
&lt;span class="mi"&gt;17&lt;/span&gt;   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.281139&lt;/span&gt;  &lt;span class="mf"&gt;1.874195&lt;/span&gt;  &lt;span class="mf"&gt;0.919508&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.497726&lt;/span&gt;
&lt;span class="mi"&gt;18&lt;/span&gt;   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.176930&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.404015&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.174419&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.352054&lt;/span&gt;
&lt;span class="mi"&gt;19&lt;/span&gt;    &lt;span class="mf"&gt;1.358412&lt;/span&gt;  &lt;span class="mf"&gt;0.443367&lt;/span&gt;  &lt;span class="mf"&gt;0.230506&lt;/span&gt;  &lt;span class="mf"&gt;1.451986&lt;/span&gt;
&lt;span class="mi"&gt;20&lt;/span&gt;    &lt;span class="mf"&gt;0.200444&lt;/span&gt;  &lt;span class="mf"&gt;2.118015&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.217391&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.431538&lt;/span&gt;
&lt;span class="mi"&gt;21&lt;/span&gt;    &lt;span class="mf"&gt;0.517777&lt;/span&gt;  &lt;span class="mf"&gt;0.201681&lt;/span&gt;  &lt;span class="mf"&gt;0.171583&lt;/span&gt;  &lt;span class="mf"&gt;0.738541&lt;/span&gt;
&lt;span class="mi"&gt;22&lt;/span&gt;   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.485768&lt;/span&gt;  &lt;span class="mf"&gt;0.449038&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.666890&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.287601&lt;/span&gt;
&lt;span class="mi"&gt;23&lt;/span&gt;   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.360219&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.572025&lt;/span&gt;  &lt;span class="mf"&gt;0.758204&lt;/span&gt;  &lt;span class="mf"&gt;1.118197&lt;/span&gt;
&lt;span class="mi"&gt;24&lt;/span&gt;    &lt;span class="mf"&gt;0.936122&lt;/span&gt;  &lt;span class="mf"&gt;0.752759&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.584876&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.547799&lt;/span&gt;
&lt;span class="mi"&gt;25&lt;/span&gt;    &lt;span class="mf"&gt;0.196639&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.954793&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.226771&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.471533&lt;/span&gt;
&lt;span class="mi"&gt;26&lt;/span&gt;    &lt;span class="mf"&gt;0.797900&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.127020&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.725855&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.788692&lt;/span&gt;
&lt;span class="mi"&gt;27&lt;/span&gt;    &lt;span class="mf"&gt;0.574896&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.225201&lt;/span&gt;  &lt;span class="mf"&gt;0.231093&lt;/span&gt;  &lt;span class="mf"&gt;0.353555&lt;/span&gt;
&lt;span class="mi"&gt;28&lt;/span&gt;    &lt;span class="mf"&gt;0.729240&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.204078&lt;/span&gt;  &lt;span class="mf"&gt;0.895284&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.171200&lt;/span&gt;
&lt;span class="mi"&gt;29&lt;/span&gt;   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.267616&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.768759&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.013787&lt;/span&gt;  &lt;span class="mf"&gt;0.602042&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;        &lt;span class="o"&gt;...&lt;/span&gt;       &lt;span class="o"&gt;...&lt;/span&gt;       &lt;span class="o"&gt;...&lt;/span&gt;       &lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="mi"&gt;9970&lt;/span&gt;  &lt;span class="mf"&gt;0.065751&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.160771&lt;/span&gt;  &lt;span class="mf"&gt;0.399800&lt;/span&gt;  &lt;span class="mf"&gt;0.088873&lt;/span&gt;
&lt;span class="mi"&gt;9971&lt;/span&gt;  &lt;span class="mf"&gt;1.705634&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.555078&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.124514&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.123454&lt;/span&gt;
&lt;span class="mi"&gt;9972&lt;/span&gt;  &lt;span class="mf"&gt;0.103970&lt;/span&gt;  &lt;span class="mf"&gt;0.055869&lt;/span&gt;  &lt;span class="mf"&gt;0.170443&lt;/span&gt;  &lt;span class="mf"&gt;0.337169&lt;/span&gt;
&lt;span class="mi"&gt;9973&lt;/span&gt;  &lt;span class="mf"&gt;0.901626&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.216274&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.024024&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.604295&lt;/span&gt;
&lt;span class="mi"&gt;9974&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.090337&lt;/span&gt;  &lt;span class="mf"&gt;1.025474&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.060774&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.037345&lt;/span&gt;
&lt;span class="mi"&gt;9975&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.321273&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.720859&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.189354&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.624089&lt;/span&gt;
&lt;span class="mi"&gt;9976&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.967506&lt;/span&gt;  &lt;span class="mf"&gt;0.670755&lt;/span&gt;  &lt;span class="mf"&gt;2.122024&lt;/span&gt;  &lt;span class="mf"&gt;0.280750&lt;/span&gt;
&lt;span class="mi"&gt;9977&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.919644&lt;/span&gt;  &lt;span class="mf"&gt;1.380600&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.547376&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.475826&lt;/span&gt;
&lt;span class="mi"&gt;9978&lt;/span&gt;  &lt;span class="mf"&gt;1.706442&lt;/span&gt;  &lt;span class="mf"&gt;1.236540&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.286835&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.374051&lt;/span&gt;
&lt;span class="mi"&gt;9979&lt;/span&gt;  &lt;span class="mf"&gt;0.338149&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.415665&lt;/span&gt;  &lt;span class="mf"&gt;0.200910&lt;/span&gt;  &lt;span class="mf"&gt;1.906486&lt;/span&gt;
&lt;span class="mi"&gt;9980&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.696541&lt;/span&gt;  &lt;span class="mf"&gt;0.725571&lt;/span&gt;  &lt;span class="mf"&gt;0.974992&lt;/span&gt;  &lt;span class="mf"&gt;1.804216&lt;/span&gt;
&lt;span class="mi"&gt;9981&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.400005&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.888944&lt;/span&gt;  &lt;span class="mf"&gt;0.921454&lt;/span&gt;  &lt;span class="mf"&gt;1.564475&lt;/span&gt;
&lt;span class="mi"&gt;9982&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.455065&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.656174&lt;/span&gt;  &lt;span class="mf"&gt;1.397340&lt;/span&gt;  &lt;span class="mf"&gt;1.814911&lt;/span&gt;
&lt;span class="mi"&gt;9983&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.938067&lt;/span&gt;  &lt;span class="mf"&gt;0.021626&lt;/span&gt;  &lt;span class="mf"&gt;0.643831&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.565873&lt;/span&gt;
&lt;span class="mi"&gt;9984&lt;/span&gt;  &lt;span class="mf"&gt;0.765747&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.202373&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.674182&lt;/span&gt;  &lt;span class="mf"&gt;0.744532&lt;/span&gt;
&lt;span class="mi"&gt;9985&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.088007&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.124469&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;2.031907&lt;/span&gt;  &lt;span class="mf"&gt;0.128496&lt;/span&gt;
&lt;span class="mi"&gt;9986&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.714295&lt;/span&gt;  &lt;span class="mf"&gt;0.032928&lt;/span&gt;  &lt;span class="mf"&gt;0.178468&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.085715&lt;/span&gt;
&lt;span class="mi"&gt;9987&lt;/span&gt;  &lt;span class="mf"&gt;1.025195&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.188422&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;2.095404&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.619646&lt;/span&gt;
&lt;span class="mi"&gt;9988&lt;/span&gt;  &lt;span class="mf"&gt;0.132227&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.261682&lt;/span&gt;  &lt;span class="mf"&gt;0.244649&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.666303&lt;/span&gt;
&lt;span class="mi"&gt;9989&lt;/span&gt;  &lt;span class="mf"&gt;0.786193&lt;/span&gt;  &lt;span class="mf"&gt;1.509406&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.202992&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.225874&lt;/span&gt;
&lt;span class="mi"&gt;9990&lt;/span&gt;  &lt;span class="mf"&gt;0.473791&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.143862&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.316002&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.895491&lt;/span&gt;
&lt;span class="mi"&gt;9991&lt;/span&gt;  &lt;span class="mf"&gt;0.400169&lt;/span&gt;  &lt;span class="mf"&gt;0.677086&lt;/span&gt;  &lt;span class="mf"&gt;0.924509&lt;/span&gt;  &lt;span class="mf"&gt;0.359508&lt;/span&gt;
&lt;span class="mi"&gt;9992&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.997034&lt;/span&gt;  &lt;span class="mf"&gt;1.188000&lt;/span&gt;  &lt;span class="mf"&gt;0.529767&lt;/span&gt;  &lt;span class="mf"&gt;3.023600&lt;/span&gt;
&lt;span class="mi"&gt;9993&lt;/span&gt;  &lt;span class="mf"&gt;0.611606&lt;/span&gt;  &lt;span class="mf"&gt;0.870376&lt;/span&gt;  &lt;span class="mf"&gt;0.111409&lt;/span&gt;  &lt;span class="mf"&gt;0.791074&lt;/span&gt;
&lt;span class="mi"&gt;9994&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.139214&lt;/span&gt;  &lt;span class="mf"&gt;1.621675&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.175538&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.434139&lt;/span&gt;
&lt;span class="mi"&gt;9995&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.114247&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.242445&lt;/span&gt;  &lt;span class="mf"&gt;0.863734&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.562891&lt;/span&gt;
&lt;span class="mi"&gt;9996&lt;/span&gt;  &lt;span class="mf"&gt;0.236475&lt;/span&gt;  &lt;span class="mf"&gt;1.685572&lt;/span&gt;  &lt;span class="mf"&gt;0.372954&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.154444&lt;/span&gt;
&lt;span class="mi"&gt;9997&lt;/span&gt;  &lt;span class="mf"&gt;0.382693&lt;/span&gt;  &lt;span class="mf"&gt;0.246771&lt;/span&gt;  &lt;span class="mf"&gt;0.452163&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.418974&lt;/span&gt;
&lt;span class="mi"&gt;9998&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.135619&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;2.219971&lt;/span&gt;  &lt;span class="mf"&gt;0.365980&lt;/span&gt;  &lt;span class="mf"&gt;0.334584&lt;/span&gt;
&lt;span class="mi"&gt;9999&lt;/span&gt;  &lt;span class="mf"&gt;0.200453&lt;/span&gt;  &lt;span class="mf"&gt;0.638034&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.827149&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.516329&lt;/span&gt;

&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; 
          &lt;span class="n"&gt;a&lt;/span&gt;         &lt;span class="n"&gt;b&lt;/span&gt;         &lt;span class="n"&gt;c&lt;/span&gt;         &lt;span class="n"&gt;d&lt;/span&gt;
&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.924205&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.278529&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.261998&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.005286&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="mf"&gt;0.392045&lt;/span&gt;  &lt;span class="mf"&gt;1.609994&lt;/span&gt;  &lt;span class="mf"&gt;1.733763&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.539745&lt;/span&gt;
&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.085711&lt;/span&gt;  &lt;span class="mf"&gt;0.756263&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.084361&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.424867&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;2.082346&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.593061&lt;/span&gt;  &lt;span class="mf"&gt;0.758439&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.522798&lt;/span&gt;
&lt;span class="mi"&gt;4&lt;/span&gt;  &lt;span class="mf"&gt;1.064134&lt;/span&gt;  &lt;span class="mf"&gt;0.307272&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.829989&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.373749&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt;
   &lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
   &lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;     &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ix&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;
   &lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; 
&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;849&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iterrows&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;
   &lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; 
&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;224&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can see that the "Pythonic" way of doing this is about 4 times quicker and looks more clear. Thus, the recommended way is to use&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;for index, row in df.iterrows():
    row[&amp;#39;a&amp;#39;], index
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It should be noted that this is similar in syntax to the &lt;code&gt;enumerate&lt;/code&gt; syntax we are used to seeing in iteration over Python lists.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Tue, 09 Jun 2015 19:22:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2015-06-09:2015/06/pandas-iteration/</guid><category>pandas</category></item><item><title>Collection of Stack Overflow questions on Pandas, Numpy, and Python</title><link>http://nipunbatra.github.io/2015/06/collection_questions/</link><description>&lt;p&gt;Often I find myself looking up similar questions on StackOverflow pertaining to my day to day data analysis. I'm documenting these questions up here. &lt;/p&gt;
&lt;p&gt;Please feel free to fork &lt;a href="https://gist.github.com/nipunreddevil/c8d9d3acbe9abb6eafc0"&gt;this gist&lt;/a&gt; and submit PR if you have any recommendations.&lt;/p&gt;
&lt;script src="https://gist.github.com/nipunreddevil/c8d9d3acbe9abb6eafc0.js"&gt;&lt;/script&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sun, 07 Jun 2015 18:45:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2015-06-07:2015/06/collection_questions/</guid><category>nilm</category><category>buildings</category><category>energy</category></item><item><title>Insights into home energy consumption in India</title><link>http://nipunbatra.github.io/2014/09/insights-energy-india/</link><description>&lt;p&gt;At Buildsys 2013, I had presented my work on Insights into home energy consumption in India. Recenly I made a poster/infographic on it and presented at my university.
&lt;img src="http://nipunbatra.github.io/downloads/files/batra_rs2014.png" alt="[poster]" title="[poster]"&gt;&lt;/p&gt;
&lt;p&gt;You may find the pdf version of this infographic &lt;a href="http://nipunbatra.github.io/downloads/files/batra_rs2014.pdf"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For the interested, here are the details of the work which I presented at Buildsys.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://dl.dropboxusercontent.com/u/75845627/buildsys_paper.pdf"&gt;Paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://dl.dropboxusercontent.com/u/75845627/builldsys.pdf"&gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nipunreddevil.github.io/Home_Deployment/"&gt;Github page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://iawe.github.io"&gt;Data set page&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sat, 27 Sep 2014 20:30:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-09-27:2014/09/insights-energy-india/</guid><category>nilm</category><category>buildings</category><category>energy</category></item><item><title>Buildsys 2014 papers from my research group</title><link>http://nipunbatra.github.io/2014/09/buildsys-papers/</link><description>&lt;p&gt;So, it is that time of the year again when &lt;a href="http://www.buildsys.org/2014/"&gt;Buildsys&lt;/a&gt; program is notified. Our &lt;a href="http://energy.iiitd.edu.in/"&gt;research lab&lt;/a&gt; (which works primarily in energy sustainability and smart home applications) has expanded significantly since last year's Buildsys. This time we submitted a total of 5 papers, a poster and a demo. Given the really tough competition this time around, I think the group did a good job of getting 2 papers, a poster and a demo through. In this post I'll quickly discuss about the accepted work and why you should come and attend our talks/demos.&lt;/p&gt;
&lt;h3&gt;&lt;a href="http://arxiv.org/abs/1409.4438"&gt;An In Depth Study into Using EMI Signatures for Appliance Identification&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://manojgulati.wordpress.com/"&gt;Manoj&lt;/a&gt; led this interesting paper. &lt;a href="http://www.kevinli.net/courses/mobilehci_w2013/papers/ElectriSense.pdf"&gt;Previous work&lt;/a&gt; around 2010 had hypothesized that household appliances cause electromagnetic interference (EMI) on the power line and this can be exploited for appliance disaggregation (aka NILM). Fast forward to 2014- appliances have become better and would be expected to have lesser interference, extension cords in homes are increasingly coming with EMI suppressors. Would such an approach still work. This work presents answers to some pertinent questions such as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;How many appliances "actually" put EMI on the power line?&lt;/li&gt;
&lt;li&gt;How does the analysis vary with background noise- could using a UPS instead of AC mains give better results?&lt;/li&gt;
&lt;li&gt;Would it matter if my appliance is connected 2 meters from the measurement equipment as opposed to 10 meters?&lt;/li&gt;
&lt;li&gt;What happens if multiple appliances are used in parallel?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I'll not disclose their results in this post to avoid killing the excitement! The authors also release simulation studies and their data set (&lt;a href="http://hfed.github.io/"&gt;HFED&lt;/a&gt;) collected in laboratory and residential settings.&lt;/p&gt;
&lt;h3&gt;&lt;a href="https://dl.dropboxusercontent.com/u/95976723/papers/wattshare_buildsys14.pdf"&gt;WattShare: Detailed Energy Apportionment in Shared Living Spaces within Commercial Buildings&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Imagine that your university proposes a new rule to increase energy awareness. You won't be charged a fixed amount for your dorm electricity consumption- but would only need to pay for what you use. Interesting! But, surely, the university does not have the resources to instrument each and every dorm room. Here comes a work by &lt;a href="http://shailjathakur.wordpress.com/"&gt;Shailja&lt;/a&gt; and &lt;a href="http://manaswisaha.wordpress.com/"&gt;Manaswi&lt;/a&gt; done in collaboration with &lt;a href="http://www.synergylabs.org/yuvraj/"&gt;Yuvraj&lt;/a&gt;. Smartphones are getting ubiquitous and they can easily collect a lot of data! WattShare is a system which fuses information from smartphones (audio and WiFi) with the smart meter data to break down overall energy consumption in a dorm like setting. A week long experiment in a student dorm in our IIITD campus and the evaluation thereof, suggests that such a system can be viable for room level energy apportionment in commercial buildings which resemble the scenario used in this paper.&lt;/p&gt;
&lt;h3&gt;&lt;a href="http://arxiv-web3.library.cornell.edu/abs/1409.5907"&gt;Bits and Watts: Improving energy disaggregation performance using power line communication modems&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This is a work which I led and involved Manoj and Puneet from IIITD and &lt;a href="http://www.cs.virginia.edu/~whitehouse/"&gt;Kamin Whitehouse&lt;/a&gt; from UVa. NILM techniques have been known for long. But, they are fairly limited in disaggregating low power appliances and multiple instances of similar appliances. How does powerline communication even come in the picture? We found that even a cheap COTS PLC worth 30 dollars (Yes! you read it right 30 dollars) can help when complex machine learning may fail. We use a simple system where we observe the change in throughput between two PLC modems as different appliances are used in a home. I'll let the following image speak for itself!&lt;/p&gt;
&lt;p&gt;&lt;img src="../../../images/ewma.png" alt="[alt]" title="[alt]"&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a href="http://arxiv-web3.library.cornell.edu/abs/1409.5908v1"&gt;NILMTK v0.2: A Non-intrusive Load Monitoring Toolkit for Large Scale Data Sets&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://nilmtk.github.io/"&gt;nilmtk&lt;/a&gt; simply rocked! Does it need any enhancements? Yup! nilmtk was limited in the amount of data it could process. It could only handle data sets which would fit in memory. Surely, this wasn't something we wanted. Particularly since &lt;a href="http://www.pecanstreet.org/"&gt;Pecan Street&lt;/a&gt; research announced &lt;a href="http://wiki-energy.org/"&gt;Wiki-Energy&lt;/a&gt; NILM data set which may not fit in a standard laptop's memory in the coming 10 years! So, nilmtk v0.2 was a complete rewrite of the initial version. It now comes with NILM-metadata which makes it way more efficient to handle the differences among different data sets. This paper involved a lot of effort from &lt;a href="http://www.jack-kelly.com/"&gt;Jack&lt;/a&gt; while &lt;a href="http://www.oliverparson.co.uk/"&gt;Oliver&lt;/a&gt; and I supported along.&lt;/p&gt;
&lt;p&gt;Maybe, I have whetted your appetite? I'd be happy to hear any feedback.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Fri, 26 Sep 2014 18:45:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-09-26:2014/09/buildsys-papers/</guid><category>nilm</category><category>buildings</category><category>energy</category></item><item><title>A comparison of NILM methods for commercial and residential buildings</title><link>http://nipunbatra.github.io/2014/09/comparison-nilm/</link><description>&lt;p&gt;I am happy to announce my new tech. report entitled- A comparison of NILM methods for commercial and residential buildings. I had the privilege to work with &lt;a href="http://www.marioberges.com/"&gt;Mario Berges&lt;/a&gt;, &lt;a href="http://blog.oliverparson.co.uk/"&gt;Oliver Parson&lt;/a&gt; and his supervisor, alongside my supervisor on this report. The paper can be found on arxiv &lt;a href="http://arxiv.org/abs/1408.6595"&gt;here&lt;/a&gt;. This paper also accompanies the release of &lt;a href="http://combed.github.io/"&gt;Commercial Building Energy data set (COMBED)&lt;/a&gt;. I have also recently developed a converter for this data set for usage with NILMTK, which is also available on the data set page.&lt;/p&gt;
&lt;p&gt;The paper abstract reads as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Non intrusive load monitoring (NILM), or energy disaggregation, is the process of separating the total electricity consumption of a building as measured at single point into the building's constituent loads. Previous research in the field has mostly focused on residential buildings, and although the potential benefits of applying this technology to commercial buildings have been recognised since the field's conception, NILM in the commercial domain has been largely unexplored by the academic community. As a result of the heterogeneity of this section of the building stock (i.e., encompassing buildings as diverse as airports, malls and coffee shops), and hence the loads within them, many of the solutions developed for residential energy disaggregation do not apply directly. In this paper we highlight some insights for NILM in the commercial domain using data collected from a large smart meter deployment within an educational campus in Delhi, India, of which a subset of the data has been released for public use. We present an empirical characterisation of loads in commercial buildings, highlighting the differences in energy consumption and load characteristics between residential and commercial buildings. We assess the validity of the assumptions generally made by NILM solutions for residential buildings when applied to measurements from commercial facilities. Based on our observations, we discuss the required traits for a NILM system for commercial buildings, and run benchmark residential NILM algorithms on our data set to confirm our observations. To advance the research in commercial buildings energy disaggregation, we release a subset of our data set, called COMBED (commercial building energy data set).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Happy to hear feedback about this paper!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sun, 21 Sep 2014 13:35:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-09-21:2014/09/comparison-nilm/</guid><category>nilm</category><category>Python</category></item><item><title>Tips and tricks</title><link>http://nipunbatra.github.io/2014/09/tips/</link><description>&lt;p&gt;In this post I'll mention a few handy tips and tricks. I intend to keep this list updated and thus thought of linking a gist up here.&lt;/p&gt;
&lt;script src="https://gist.github.com/nipunreddevil/b348568e2acfe7343e91.js"&gt;&lt;/script&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Tue, 02 Sep 2014 20:12:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-09-02:2014/09/tips/</guid></item><item><title>Notes on the Prototype NILM paper from George Hart released in 1985</title><link>http://nipunbatra.github.io/2014/08/hart,%20nilm,%20nilmtk/</link><description>&lt;p&gt;The following post contains my notes from reading &lt;a href="http://georgehart.com/"&gt;George Hart&lt;/a&gt;'s &lt;a href="http://georgehart.com/research/Hart1985.pdf"&gt;1985 report on the prototype NILM system&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Microprocessor based&lt;/li&gt;
&lt;li&gt;First determines the number of appliances and then the electrical nature of each of these&lt;/li&gt;
&lt;li&gt;Process is completely automatic without any appliance survey or contact with the occupants&lt;/li&gt;
&lt;li&gt;Limitations&lt;ul&gt;
&lt;li&gt;Performance degrades as we consider low power consuming appliances&lt;ul&gt;
&lt;li&gt;Useful threshold of 100-200 W. Appliances consuming less than this unlikely to do well.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Best suited for on-off appliances&lt;ul&gt;
&lt;li&gt;Either ignore multi-state appliances or learn individual components&lt;/li&gt;
&lt;li&gt;Was able to detect the two state appliances with an accuracy of 75-90% across 3 homes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Two state algorithm&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Two different use cases are considered:&lt;ul&gt;
&lt;li&gt;Static optimization: Where we have sufficient storage and we can store an year worth of data. Given the data find the most likely set to explain the observations.&lt;/li&gt;
&lt;li&gt;Dynamic optimisation: Where we are constrained by memory and at each time point explain data up to that point. Sufficient statistics are maintained and given the low memory constraints, they are a good fit.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Static two state load monitor consists of the following stages:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Measurement&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Measure both real and reactive power for both legs&lt;/li&gt;
&lt;li&gt;In addition measure the voltage&lt;/li&gt;
&lt;li&gt;Sampling above 10 Hz not found to be useful&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Normalization&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adjust real and reactive power given that the utility can vary voltage which impacts power consumption&lt;/li&gt;
&lt;li&gt;
&lt;div class="math"&gt;$$\mathrm{Adjusted Power = Measured Power * } {\frac{Rated voltage}{measured voltage}}^2$$&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;Eliminates changes in power due only to voltage fluctuation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Edge detection&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Divide sequence into time periods which are steady and changing. &lt;ul&gt;
&lt;li&gt;Steady period: sequence of minimum length where the power does not vary more than a threshold&lt;/li&gt;
&lt;li&gt;Current implementation used 2 seconds as minimum length and 15 W or VAR as threshold&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Compute the change in power between two steady states&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Clustering&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cluster together similar changes in power between two steady states&lt;/li&gt;
&lt;li&gt;Necessary as the power change between two steady states may vary due to a variety of reasons: sensors, measurement noise, A/D conversion, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On-off matching&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On-off pairs of each appliance are grouped together.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Separating simultaneous changes&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Say, we observe a step change of +700 W. This can be due to +500 W and +200 W appliances turning on. &lt;/li&gt;
&lt;li&gt;Can be separated based on the following:&lt;ol&gt;
&lt;li&gt;+700 W does not occur often&lt;/li&gt;
&lt;li&gt;+700 occurs between two on or off event of an appliance signifying that this event was missed&lt;/li&gt;
&lt;li&gt;Observed change is appx. sum of two known changes (+500 and +200)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Identification&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Observe the properties of on-off cluster and determine which appliance it is&lt;/li&gt;
&lt;li&gt;Algorithm would compare against a table, which contains information such as:&lt;ol&gt;
&lt;li&gt;Active and reactive power consumption of different appliance classes, e.g. refrigerator: 100-500 W, water heater: 4000 W&lt;/li&gt;
&lt;li&gt;Weather correlation with appliance, e.g. space heating more likely to be used when it is cold outside&lt;/li&gt;
&lt;li&gt;Timing information:&lt;ol&gt;
&lt;li&gt;Average length of on/off cycle&lt;/li&gt;
&lt;li&gt;Number of cycles per day&lt;/li&gt;
&lt;li&gt;Time of day properties, e.g. light more likely to be used in the night&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Real time implementation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Implemented on an HP9845B computer. Pretty low end compared to today's watches!&lt;/li&gt;
&lt;li&gt;1500 lines of BASIC code requiring 64K memory&lt;/li&gt;
&lt;li&gt;Dynamic edge detection algorithm
-- Memory efficient version of the static edge detection algorithm discussed above
-- Steady state power is the average of the power observed during the steady state&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Dynamic edge detection&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# Initialization&lt;/span&gt;
&lt;span class="n"&gt;steady_state_power&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;last_steady_state_power&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;previous_measurement&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;power_changing&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
&lt;span class="n"&gt;power_change_progress&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;

&lt;span class="c"&gt;# Maximum difference in successive readings during steady state&lt;/span&gt;
&lt;span class="n"&gt;steady_state_threshold&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt; &lt;span class="n"&gt;W&lt;/span&gt;
&lt;span class="c"&gt;# Don&amp;#39;t consider appliances below this level&lt;/span&gt;
&lt;span class="n"&gt;noise_level&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;70&lt;/span&gt; &lt;span class="n"&gt;W&lt;/span&gt;

&lt;span class="c"&gt;# Loop over measurements&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;measurement&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;measurement_sequence&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;delta_power&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;power&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;previous_measurement&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;delta_power&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;steady_state_threshold&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="c"&gt;# Load is active&lt;/span&gt;
        &lt;span class="n"&gt;power_changing&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;power_changing&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;

    &lt;span class="c"&gt;#Step 3 A&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;power_changing&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;power_change_progress&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="c"&gt;# Transition is just beginning&lt;/span&gt;
        &lt;span class="n"&gt;previous_transition&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;steady_state_power&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;last_steady_state_power&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;previous_transition&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;noise_level&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="c"&gt;# Transition is significant to be considered&lt;/span&gt;
            &lt;span class="n"&gt;store&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;store&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;previous_transition&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c"&gt;# Step 3 B&lt;/span&gt;
    &lt;span class="n"&gt;last_steady_state_power&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;steady_state_power&lt;/span&gt;
    &lt;span class="n"&gt;T&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;

    &lt;span class="c"&gt;# Step 4&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;power_changing&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="c"&gt;# New steady state may be starting&lt;/span&gt;
        &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

    &lt;span class="c"&gt;# Step 5&lt;/span&gt;
    &lt;span class="c"&gt;# Update estimate for steady state power &lt;/span&gt;
    &lt;span class="n"&gt;steady_state_power&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;steady_state_power&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;measurement&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c"&gt;# Step 6&lt;/span&gt;
    &lt;span class="c"&gt;# Update count for samples in current steady state&lt;/span&gt;
    &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

    &lt;span class="c"&gt;# Step 7&lt;/span&gt;
    &lt;span class="n"&gt;power_change_progress&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;power_changing&lt;/span&gt;

    &lt;span class="c"&gt;# Step 8&lt;/span&gt;
    &lt;span class="n"&gt;previous_measurement&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;measurement&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;Dynamic on-off matching&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Pairs on and off transitions based on size&lt;/li&gt;
&lt;li&gt;Average of on transition and the negative of off transition is used for clustering purposes&lt;/li&gt;
&lt;li&gt;A pair is said to match when the following four conditions are true:&lt;ol&gt;
&lt;li&gt;They are both on the same phase&lt;/li&gt;
&lt;li&gt;They are both unmarked&lt;/li&gt;
&lt;li&gt;The earlier has a positive real component&lt;/li&gt;
&lt;li&gt;When added together, the absolute value of real power is less than 35 W or 3.5% of the positive edge (which ever is more).&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;When an appliance turns on and off many times, the ordering is very important, as there can be many possible pairings
    -The algorithm must not allow matching an on event with an off event from some other cycle. This problem is similar to parity errors. Two errors within a small time frame can occur; one is detectable, two ain't.&lt;ul&gt;
&lt;li&gt;Example: We see the following edge sequence: +1000, -1100, +1000, -1000,....
For this case, the +1000 would be matched with -1000 from the second cycle, which is wrong and overestimates the energy consumption. This is checked by looking at closer elements first for matching and gradually increase the distance. By this procedure, the second cycle would get properly matched. &lt;/li&gt;
&lt;li&gt;Another domain specific way to deal with this issue is the following. We had observed a +1000 W transition and for now we will assume that this appliance consumes 1000 W. If at any time the total power consumption falls below 1000 W, then this appliance is off. This can happen when we see an edge of -1100 W, which we earlier didn't match to +1000 W. &lt;em&gt;Specifically, the unassigned power between and on and an off transition must never fall below the operating power of the appliance&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Dynamic clustering&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Extremely unlikely that the exactly correct set of clusters would be found by any clustering technique&lt;/li&gt;
&lt;li&gt;Problem area: Two clusters which may almost merge into a single larger cluster- is it due to the presence of two similar appliances or due to a single inconsistent appliance. To mitigate this a technique for splitting clusters is discussed as follows.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;Representation system for a cluster&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Each appliance represented by three ellipses:&lt;ul&gt;
&lt;li&gt;one main ellipse indicating range of real and reactive values&lt;/li&gt;
&lt;li&gt;and, two sub ellipses which indicate sub ranges for splitting up the cluster into two smaller sub clusters&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Insights from refrigerator cluster&lt;ul&gt;
&lt;li&gt;cluster is elongated to left and right: real power tends to vary more than reactive power&lt;/li&gt;
&lt;li&gt;slight tilt to upper left and lower right: if real power is higher than average, reactive power tends to be lower than average and vice versa. This behaviour is typical of induction motors and is a consequence of non-linearity of their power consumption.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Statistical tests are used whether to join or split clusters&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Results&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;3 homes were tested&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;House 1&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;45 appliance representations found in a one week test&lt;/li&gt;
&lt;li&gt;Of these 45, only 20 contain significant number of cycles or energy&lt;/li&gt;
&lt;li&gt;Appliance names labelling each cluster were provided by the author&lt;/li&gt;
&lt;li&gt;Vast majority of appliances recognized well&lt;/li&gt;
&lt;li&gt;~3600 transitions found above 70W, which is a transition every 3 minutes&lt;/li&gt;
&lt;li&gt;Of these ~3600, 83.5% were matched into pairs&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On-off durations and time of day usage can be used to label some of the appliances&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shortcomings&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Lights and small appliances tend to be fused together in a cluster just above the noise threshold of 70W.&lt;/li&gt;
&lt;li&gt;Threshold for discrimination appears to be about 120W.&lt;/li&gt;
&lt;li&gt;Some refrigerator transitions didn't get paired together. This can be rectified by performing clustering before transition pair matching.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;House 2&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Several clusters were not identified. However, most are correctly analysed into correct single cluster.&lt;/li&gt;
&lt;li&gt;Power consumption over time ramps us as dishwasher fills with water&lt;/li&gt;
&lt;li&gt;Oven being an unbalanced load does not do well&lt;/li&gt;
&lt;li&gt;There is a large cluster around 1200 W. Likely due to a number of appliances including a hair dryer. This is a &lt;strong&gt;fundamental limitation of NILM&lt;/strong&gt;: It cannot distinguish appliances which are electrically very similar.&lt;/li&gt;
&lt;li&gt;Energy profile of kitchen light shows the three-meal-per-day pattern&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;House 3&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Largest of the 3 homes tested&lt;/li&gt;
&lt;li&gt;Contains electric water heater and central air conditioning&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Recommendations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Results from these three field tests considered satisfactory&lt;/li&gt;
&lt;li&gt;Most two state appliances performing up to expectations&lt;/li&gt;
&lt;li&gt;Adjustments to be incorporated:&lt;/li&gt;
&lt;li&gt;Simultaneous transition analysis&lt;/li&gt;
&lt;li&gt;Faster sampling- reduces simultaneous transitions&lt;/li&gt;
&lt;li&gt;Clustering before pairing- may be able to handle appliances showing variable transitions&lt;/li&gt;
&lt;li&gt;Unassigned power level or residual power&lt;/li&gt;
&lt;li&gt;Multi-state appliances&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Multi-state appliances&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;For appliances such as dishwasher or electric dryer, the two state model could not learn the characteristics&lt;/li&gt;
&lt;li&gt;Off transition for motor never found; the heating element may be easy to learn though.&lt;/li&gt;
&lt;li&gt;Each appliance can be represented by a finite state machine (FSM)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Algorithms&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Like two-state algorithms, these algorithms can be divided into two parts- the part which learns what appliances are in the home and the part which keeps track of the appliances once they are learned.&lt;/li&gt;
&lt;li&gt;Clustering&lt;/li&gt;
&lt;li&gt;Clustering must occur before on-off edge matching&lt;/li&gt;
&lt;li&gt;Assumed that each cluster of transitions can only belong to a single appliance&lt;/li&gt;
&lt;li&gt;Cyclic factor analysis&lt;/li&gt;
&lt;li&gt;Remove the easy to process on-off pairs, which correspond to two-state appliances. Here on-off pairing is on clusters and not on individual transitions. Two clusters having approx. the same number of entries and similar means are sought.&lt;/li&gt;
&lt;li&gt;A set of clusters whose mean values add approx. to zero and which contain transitions that occur in the buffer in a cyclic sequence can be sought out. Also, if the number of transitions in these clusters match, the matching is not merely coincidental&lt;/li&gt;
&lt;li&gt;Traversal analysis&lt;/li&gt;
&lt;li&gt;Used to learn complex multi-state appliances which could not be learnt by the above process&lt;/li&gt;
&lt;li&gt;Examine the transitions in sequence, while keeping track of state pointer&lt;/li&gt;
&lt;li&gt;Assume only a single multi-state appliance left at this stage&lt;/li&gt;
&lt;li&gt;Factoring&lt;/li&gt;
&lt;li&gt;If traversal analysis was done on two or more multi-state appliances, a single FSM will be learnt. &lt;/li&gt;
&lt;li&gt;This FSM needs to be broken down into two separate appliance representations.&lt;/li&gt;
&lt;li&gt;This factoring is akin to prime factorisation&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Apparatus&lt;/h2&gt;
&lt;h3&gt;Computational requirement&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Algorithms can be implemented on state-of-the-art microprocessor systems&lt;/li&gt;
&lt;li&gt;Components in such a system would include: power supply, backup battery, sensors (CTs), A/D, ROM, modem, microprocessor.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Mounting&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Expect to fit the entire load monitor in a space half the volume of a conventional meter&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Future directions&lt;/h2&gt;
&lt;h3&gt;Identification algorithm&lt;/h3&gt;
&lt;h4&gt;Selecting parameters&lt;/h4&gt;
&lt;p&gt;Some possible parameters
1. Real power
2. Reactive power
3. 120 Volt, 240 Volts
4. Time-of-day usage 
5. Usage-vs-temperature
6. On-time vs Off-time distributions&lt;/p&gt;
&lt;h4&gt;Methodology&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Classification and lookup methodology should be designed&lt;/li&gt;
&lt;li&gt;Should output something like:" There is a 92% probability that this is water heater, 3% that this is a space heater and so on"&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;DBMS&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Designed to allow load researchers to examine appliance data &lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Multi-house test&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Project will greatly benefit by research on 10 houses&lt;/li&gt;
&lt;li&gt;Benefits of multiple homes:&lt;/li&gt;
&lt;li&gt;Will prove that the method is capable of operating with a variety of residential appliances mix&lt;/li&gt;
&lt;li&gt;It will allow the performance to be quantified precisely&lt;/li&gt;
&lt;li&gt;Provides opportunity to refine the algorithms&lt;/li&gt;
&lt;li&gt;Allow assessment of multi-state appliances&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Multi-state appliances algorithms&lt;/h3&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Thu, 07 Aug 2014 16:50:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-08-07:2014/08/hart, nilm, nilmtk/</guid><category>nilm</category></item><item><title>NILMTK Independent Project for IIITD students</title><link>http://nipunbatra.github.io/2014/08/nilmtk-ip-iiitd/</link><description>&lt;p&gt;Hi everyone! I am sure all of you would have heard about &lt;a href="http://en.wikipedia.org/wiki/Google_Summer_of_Code"&gt;Google summer of code (GSoc)&lt;/a&gt;. Sounds like a good idea, doesn't it? How about doing a Gsoc kind of project while getting credits for it? Of course, money ain't involved here :(&lt;/p&gt;
&lt;p&gt;In this post, I'll be discussing about positions for Independent project for IIITD students. I have been working on non intrusive load monitoring (NILM) for close to 2 years now. The following image and paragraph is a 2 minute introduction to NILM.&lt;/p&gt;
&lt;p&gt;&lt;img alt="nilmtk image" src="http://nilmtk.github.io/img/disaggregation.png" /&gt;&lt;/p&gt;
&lt;p&gt;Just imagine that you could somehow collect data from your electricity meter in real time. Using this data, you use machine learning to determine the power consumption of different appliances. Ok, the easy stuff ends there!&lt;/p&gt;
&lt;p&gt;As you would imagine with anything involving machine learning, we too deal with data sets and quite variable ones they are! Interestingly, the research in this field was impeded due to a lot of factors- papers would present their evaluations on different data sets (which doesn't particularly be a very sound comparison), papers would use different accuracy metrics to present their results. More such issues inspired me to work closely with two UK based researchers (&lt;a href="http://www.jack-kelly.com/"&gt;Jack&lt;/a&gt; and &lt;a href="http://www.oliverparson.co.uk/"&gt;Oliver&lt;/a&gt;) to build a toolkit, called nilmtk,  specifically to address these pain points. Think of it is as &lt;a href="http://www.cs.waikato.ac.nz/ml/weka/"&gt;Weka&lt;/a&gt; for NILM. Actually, &lt;a href="http://nilmtk.github.io/"&gt;nilmtk&lt;/a&gt; is much more than that!&lt;/p&gt;
&lt;p&gt;I presented nilmtk at &lt;a href="http://arxiv.org/pdf/1404.3878v1.pdf"&gt;eEnergy 2014&lt;/a&gt;, held at Cambridge university in June. I think the slides should give a high level overview of what nilmtk is all about.&lt;/p&gt;
&lt;script async class="speakerdeck-embed" data-id="ffca6210fe1301319b0512528e555330" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"&gt;&lt;/script&gt;

&lt;p&gt;You may also visit the project page up &lt;a href="http://nilmtk.github.io/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Since that a lot of things have changed. Recently, &lt;a href="http://nilmtk.github.io/nilmtk/master/intro_nilmtk_v0_2.html"&gt;nilmtk v0.2&lt;/a&gt; was released. It is designed keeping in mind OOPS principles and designed to handle large data sets. We are not there yet in porting everything which worked in v0.1 to v0.2. &lt;/p&gt;
&lt;p&gt;Against this background, let me now get to the business end of this post.&lt;/p&gt;
&lt;h3&gt;What would this IP involve&lt;/h3&gt;
&lt;h4&gt;Initial phase&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Getting an understanding of nilmtk&lt;/li&gt;
&lt;li&gt;Closing out some of the issues on the nilmtk issue tracker&lt;/li&gt;
&lt;li&gt;Improving unit test coverage&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Later phases&lt;/h4&gt;
&lt;p&gt;In a broad sense, these phases would involve reducing the entry barrier for researchers. This would include adding more NILM algorithms, converting existing data sets for nilmtk, etc. I'll update this bit based on how the initial phase pans out.&lt;/p&gt;
&lt;h4&gt;Long term plans (and wishlist)&lt;/h4&gt;
&lt;p&gt;To ensure that nilmtk becomes a community driven project (maybe one day like scikit-learn), it helps in advacncing the state of the art....&lt;/p&gt;
&lt;h3&gt;Applying for this IP&lt;/h3&gt;
&lt;p&gt;I'll try and keep the application procedure as close to Gsoc as possible. Since nilmtk is an open source project on github, why not leverage the issue queue for the selection process. Given that the deadline for choosing courses closes on Monday, 11th August, the application should be completed before that. I'll enlist the application requirements as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install nilmtk on your local machine. I would recommend doing the same on Unix/Linux based systems. Also, I'll recommend using &lt;a href="https://store.continuum.io/cshop/anaconda/"&gt;Anaconda Python distribution&lt;/a&gt; to install all the Python dependencies in one go. Feel free to create an issue on github if you face installation issues (you are already contributing to the project this way!).&lt;/li&gt;
&lt;li&gt;Browse through the &lt;a href="https://github.com/nilmtk/nilmtk/issues"&gt;issue queue&lt;/a&gt; on github and read in detail about these different issues. In case you need more clarity, ping on the issue queue. Ask questions! Find an issue which you would like to address for this application. Looking at closed issues and the discussions around them may also prove to be very beneficial. We would often associate a code commit to close an issue. &lt;/li&gt;
&lt;li&gt;Make a pull request to solve the issue. Your pull request would be evaluated on existing unit tests and send a report if we are ready to merge. Typically, each pull request should be accompanied with a unit test for the additional functionality.&lt;/li&gt;
&lt;li&gt;Alternatively, you could also have a look at some of the projects enlisted &lt;a href="https://github.com/nilmtk/nilmtk/wiki/Development-projects"&gt;here&lt;/a&gt; and get started.&lt;/li&gt;
&lt;li&gt;Or, you come up with your own proposal for what you think nilmtk needs and provide good reasons for why you think these features may be needed.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Personally, I'll prefer people who can commit to working on the project beyond this IP. There is a significant investment from my side in each IP and the returns would be far better if the student would continue on the project.&lt;/p&gt;
&lt;p&gt;Don't feel shy in taking help from your peers. Also, don't feel intimidated by the task. This sure is non-trivial. It has taken me and other two core developers (all of whom are PhD. and above) a lot of effort to get this project to this stage. So, a lot of things would seem over the head stuff. There would be stuff which my co-developers and I have in our heads, but, is not on github. For these kinds of things, feel free to create new issues on github. &lt;/p&gt;
&lt;h3&gt;Assessment&lt;/h3&gt;
&lt;p&gt;On the lines of Gsoc, you'll have to maintain a tech blog, where you update your progress on a weekly basis. I use &lt;a href="http://nipunbatra.github.io/2014/04/moved-to-pelican/"&gt;pelican&lt;/a&gt; for my blog as it allows me to use embed IPython notebooks with fair ease. Also, since everything is up on github, the evaluation should be pretty transparent. Like Gsoc expects, the student should be primarily self driven.&lt;/p&gt;
&lt;h3&gt;Why nilmtk&lt;/h3&gt;
&lt;p&gt;You'll be contributing to a live project. The project is open source, uses state-of-the-art technologies, has 40+ unit tests, continuous integration, coverage testing. So, in some sense, the project is close to industrial grade and we intend to keep it this way. Although this IP would mainly be engineering focused, nothing stops you from taking this as BTP, next year summer internship or do some research work on these lines. &lt;/p&gt;
&lt;p&gt;In case you have some general queries, feel free to leave your comments below this post. For specific technical queries use github. For remaining queries, write me an email with the subject containing ["iiitd nilmtk query"].&lt;/p&gt;
&lt;p&gt;This is the first time I am opening up IP positions in this fashion. So, if things seem a bit haphazard, please feel free to report back. In general, I would be happy to answer your queries about nilmtk and related research. &lt;/p&gt;
&lt;p&gt;On a closing note, let me reiterate that don't feel shy to ask for help! Moreover, I am also trying to assess the entry barrier to nilmtk and such feedback from you all should be highly valuable. In an ideal setting, I would have allowed the application time to be about a month. However, I think that students do need to submit their final courses in the second week. In case, this sounds interesting and you are unable to apply, feel free to mail me.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Mon, 04 Aug 2014 10:40:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-08-04:2014/08/nilmtk-ip-iiitd/</guid><category>nilmtk</category></item><item><title>Testing NILMTK combinatorial optimization algorithm</title><link>http://nipunbatra.github.io/2014/08/nilmtk-test-co/</link><description>&lt;p&gt;Since December last year, &lt;a href="http://www.jack-kelly.com/"&gt;Jack&lt;/a&gt;, &lt;a href="http://blog.oliverparson.co.uk/"&gt;Oliver&lt;/a&gt; and I have been working on &lt;a href="http://nilmtk.github.io/"&gt;nilmtk&lt;/a&gt;. Our paper had been accepted at eEnergy 2014 and at NILM workshop. Since that, a lot of things have changed. Recently, &lt;a href="http://nilmtk.github.io/nilmtk/master/intro_nilmtk_v0_2.html"&gt;nilmtk v0.2&lt;/a&gt; was released. It is designed keeping in mind OOPS principles and designed to handle large data sets. We are not there yet in porting everything which worked in v0.1 to v0.2. However, we do have a combinatorial optimisation (CO) based disaggregation algorithm working. In this post, I will cover the basics of CO based disaggregation, details of our implementation and most importantly how to write a test for this algorithm. I hope that this blog post will give an idea on contributing to nilmtk. &lt;/p&gt;
&lt;h3&gt;Problem statement&lt;/h3&gt;
&lt;p&gt;I'll define the problem with a vanilla example. Let us consider that we have only two appliances in our home- a refrigerator (fridge) and an air conditioner (AC). We monitor our mains electricity meter and want to tell which of these is on and consumes how much power at a given time. To makes our life simpler, we have appliance level sensors which measure the power consumed by fridge and AC. So, we divide our task into two stages- i) training, where we learn the features about the two appliances from their respective power data collected using appliance level meter, and ii) testing, where we use this learnt model to disaggregate the power consumed by these two appliances using only the mains power data.&lt;/p&gt;
&lt;h3&gt;Combinatorial optimization based disaggregation&lt;/h3&gt;
&lt;p&gt;Let us assume that both fridge and AC are on-off devices, i.e., they are either on or off. Let us further assume that fridge consumes 0 W when off and 200 W when on and AC consumes 0 W when off and 1000 W when on. So, in total we can have 4 possible combinations of these two appliances in different states-&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;fridge off, AC off: combined power = 0 W&lt;/li&gt;
&lt;li&gt;fridge off, AC on: combined power = 1000 W&lt;/li&gt;
&lt;li&gt;fridge on, AC off: combined power = 200 W&lt;/li&gt;
&lt;li&gt;fridge on, AC off: combined power = 1200 W&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now, let us assume that we observe 0 W at the mains meter level. This implies that both fridge and AC must be off. On similar lines, if we observe 1200 W on the mains, both these appliances must be on. So, our approach will try to find out the combination of appliances which generates the closest combined power to the measured power. You must be wondering, what our algorithm would generate if the mains power was 1100 W- in which case, the fridge can be predicted to be off (case 2 above) or on (case 4 above). This is an inherent shortcoming of the algorithm which we shall ignore for now.&lt;/p&gt;
&lt;h3&gt;Training&lt;/h3&gt;
&lt;p&gt;So, the important question is how do we obtain the different numbers we previously discussed. We want to build a model for each appliance. For CO, the model consists of the power consumed in different states. We decided to use K-Means clustering to build our appliance models from the appliance level power data. However, during the course of our implementation, we figured that if the amount of data was large, clustering would take a long time and possibly give memory issues. We thus optimized our implementation using the following two tricks:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We added a default off state to each appliance and clustered data above 10 W. This reduced our data by a great amount.&lt;/li&gt;
&lt;li&gt;Even after applying the first trick, we would occasionally blow out on memory. So, after a bit of investigation and expert &lt;a href="http://sourceforge.net/p/scikit-learn/mailman/message/31731400/"&gt;advise&lt;/a&gt; from the scikit-learn community, we figured that we could subsample our data to approx. 2000 points and get almost the same results.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After applying these two tricks, our clustering is way quicker and we are able to generate models for different appliances. Our model may look something like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;fridge&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
&lt;span class="s"&gt;&amp;quot;ac&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;]}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There are further details to choosing the optimum number of clusters, which I shall not discuss in this post. &lt;/p&gt;
&lt;h3&gt;Adding a test for CO correctness to nilmtk v0.2&lt;/h3&gt;
&lt;p&gt;Having discussed the expected behaviour of nilmtk, I would now discuss how to test the same. We would write a test case where we have two appliances- fridge and ac which consume 200 W and 1000 W respectively. We would test the four cases discussed above, and hope to get the same answers from nilmtk.&lt;/p&gt;
&lt;h4&gt;Step 1: Preparing the input data&lt;/h4&gt;
&lt;p&gt;nilmtk v0.2 requires the input data to be in a specific format. We shall need to do the following high level things.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create a HDF5 store&lt;/li&gt;
&lt;li&gt;Create pandas DataFrame for each meter (fridge, ac, mains)&lt;/li&gt;
&lt;li&gt;Define minimal metadata for each meter (for instance, we have to tell that mains is the site_meter and that fridge and ac are sub meters of the same)&lt;/li&gt;
&lt;li&gt;Store the data in the HDF5 store&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Of the four, we shall focus on #2 for now. We need to create DataFrames for each meter. Initially, I decided to write just 4 cases - where each appliance can take on or off states. However, when I was testing this, I figured out that there is a bug in the current implementation. For data less than 100 points, &lt;a href="https://github.com/nilmtk/nilmtk/issues/157"&gt;nilmtk does not even bother to disaggregate&lt;/a&gt;. I also found that CO had some bad defaults and would &lt;a href="https://github.com/nilmtk/nilmtk/issues/158"&gt;downsample data at time&lt;/a&gt; (without user discretion). These two bugs should be fixed pretty soon. The fact that trying to test out one function exposes more bugs is useful. This way one can contribute even more to the project and just shows the usefulness of unit testing. For now, I decided to overcome this limitation by repeating these 4 cases a 1000 times for each meter. I have provided the entire snippet of code I used to create this HDF5 file for testing CO. It sure looks big at the initial glance, but once you read slowly, you should be able to see the mapping between the four tasks I mentioned above. The complete file can be found &lt;a href="https://github.com/nilmtk/nilmtk/blob/master/nilmtk/tests/generate_test_data.py"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_co_test_hdf5&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="c"&gt;# Bullet 1&lt;/span&gt;
    &lt;span class="n"&gt;FILENAME&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data_dir&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;co_test.h5&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c"&gt;# Bullet 2&lt;/span&gt;
    &lt;span class="n"&gt;N_METERS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
    &lt;span class="n"&gt;chunk&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;
    &lt;span class="n"&gt;N_PERIODS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;chunk&lt;/span&gt;
    &lt;span class="n"&gt;rng&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;date_range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;2012-01-01&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;freq&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;S&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;periods&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;N_PERIODS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;dfs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;OrderedDict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;OrderedDict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c"&gt;# mains meter data&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1200&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;chunk&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c"&gt;# appliance 1 data&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;chunk&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c"&gt;# appliance 2 data&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;chunk&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;dfs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;rng&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;measurement_columns&lt;/span&gt;&lt;span class="p"&gt;([(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;power&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;active&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)]))&lt;/span&gt;

    &lt;span class="n"&gt;store&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HDFStore&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;FILENAME&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;complevel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;complib&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;zlib&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c"&gt;# Bullet 3&lt;/span&gt;
    &lt;span class="n"&gt;elec_meter_metadata&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;meter&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N_METERS&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;building1/elec/meter{:d}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;meter&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Saving&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;store&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;put&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dfs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;meter&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;table&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;elec_meter_metadata&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;meter&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="s"&gt;&amp;#39;device_model&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;TEST_METER&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;model&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
            &lt;span class="s"&gt;&amp;#39;submeter_of&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="s"&gt;&amp;#39;data_location&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="c"&gt;# For mains meter, we need to specify that it is a site meter&lt;/span&gt;
    &lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="n"&gt;elec_meter_metadata&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;submeter_of&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;elec_meter_metadata&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;site_meter&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;

    &lt;span class="c"&gt;# Save dataset-wide metadata&lt;/span&gt;
    &lt;span class="n"&gt;store&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_v_attrs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;metadata&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;meter_devices&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;TEST_METER&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;model&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;TEST_METER&lt;/span&gt;&lt;span class="p"&gt;}}&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;store&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_v_attrs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;metadata&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c"&gt;# Building metadata&lt;/span&gt;
    &lt;span class="n"&gt;add_building_metadata&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;store&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;elec_meter_metadata&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;store&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;store&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="n"&gt;store&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flush&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;store&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;Step 2: Writing the unit test&lt;/h4&gt;
&lt;p&gt;The unit test is fairly simple. We need to do the following things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Read in the nilmtk HDF5 file which we created previously.&lt;/li&gt;
&lt;li&gt;Get the &lt;code&gt;elec&lt;/code&gt; data from this HDF5&lt;/li&gt;
&lt;li&gt;Train on &lt;code&gt;elec&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Disaggregate &lt;code&gt;mains&lt;/code&gt; data and store in &lt;code&gt;output.h5&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Compare the contents to &lt;code&gt;output.h5&lt;/code&gt; and the input file. Both should contain the same data.&lt;/li&gt;
&lt;li&gt;Remove the &lt;code&gt;output.h5&lt;/code&gt; once done. Done using the awesome &lt;a href="http://amoffat.github.io/sh/"&gt;sh&lt;/a&gt; python module.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Following is the code for testing this out. The complete file can be found on nilmtk github &lt;a href="https://github.com/nilmtk/nilmtk/blob/master/nilmtk/tests/test_combinatorial_optimisation.py"&gt;here&lt;/a&gt;. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;test_co_correctness&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;elec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;buildings&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elec&lt;/span&gt;
        &lt;span class="n"&gt;co&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CombinatorialOptimisation&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;co&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;elec&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;mains&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;elec&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mains&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;HDFDataStore&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;output.h5&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;co&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;disaggregate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mains&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;resample_seconds&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;meter&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;df1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;store&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;/building1/elec/meter{}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;meter&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;df2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;store&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;store&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                &lt;span class="s"&gt;&amp;#39;/building1/elec/meter{}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;meter&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;assertEqual&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;df1&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;df2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;assertEqual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;rm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;output.h5&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I wouldn't say it was trivial. It also took some time to test the function out. But, it gives us more confidence that the algorithm is doing what it is supposed to do. We also found a bug in the code which could have given us trouble later. We now have a better code coverage. We are insured of changes to this algorithm which don't conform to the intended behaviour. Furthermore, I think this test may allow similar tests to be written for other nilm algorithms which we intend to add in nilmtk. As a developer wanting to contribute to nilmtk, this may be a good first step. Hope you found the post useful.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sun, 03 Aug 2014 16:11:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-08-03:2014/08/nilmtk-test-co/</guid><category>nilmtk</category></item><item><title>Denoising revisited</title><link>http://nipunbatra.github.io/2014/08/denoising-revisited/</link><description>&lt;p&gt;Previously, I had &lt;a href="http://nipunbatra.github.io/2014/05/denoising/"&gt;discussed&lt;/a&gt; about denoising a signal using least squares. However, I had pointed that the implementation would scale poorly with input size. This was due to the fact that I used dense matrix operations when I could have done with sparse matrix operations.&lt;/p&gt;
&lt;p&gt;So, in this post, I present a sparse version of the denoising  problem and compare its performance. The following gist contains the two versions and the code to test their performance.&lt;/p&gt;
&lt;p&gt;[gist:id=086649910074426748cd]&lt;/p&gt;
&lt;p&gt;The following table compares the time taken for the two versions for different corrupt data sizes.&lt;/p&gt;
&lt;p&gt;[gist:id=da414ab86843bca1ef10]&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sat, 02 Aug 2014 15:41:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-08-02:2014/08/denoising-revisited/</guid><category>stats</category></item><item><title>Introducing NILMTK: an open source toolkit for non-intrusive load monitoring</title><link>http://nipunbatra.github.io/2014/04/introducing-nilmtk-an-open-source-toolkit-for-non-intrusive-load-monitoring/</link><description>&lt;p&gt;Today, Nipun Batra, Jack Kelly and Oliver Parson are really pleased to
announce the release of &lt;a href="http://nilmtk.github.io/"&gt;NILMTK: an open source toolkit for
non-intrusive load monitoring&lt;/a&gt;. The toolkit will allow researchers to
easily develop algorithms which disaggregate a household’s total
electricity consumption into individual appliances.&lt;/p&gt;
&lt;p&gt;Specifically, the toolkit includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a number of parsers to read public data sets into a common format&lt;/li&gt;
&lt;li&gt;a suite of statistical functions to analyse such data sets and
    identify potential problems&lt;/li&gt;
&lt;li&gt;two benchmark energy disaggregation algorithms&lt;/li&gt;
&lt;li&gt;a suite of evaluation metrics to compare disaggregation algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further details can be found in the accompanying paper recently accepted
at e-Energy 2014 available via &lt;a href="http://arxiv.org/abs/1404.3878"&gt;arXiv&lt;/a&gt; and &lt;a href="http://eprints.soton.ac.uk/364293/"&gt;Soton ePrints&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Batra, N., Kelly, J., Parson, O., Dutta, H., Knottenbelt, W.,
    Rogers, A., Singh, A., Srivastava, M. (2014). NILMTK: An Open Source
    Toolkit for Non-intrusive Load Monitoring. In Fifth International
    Conference on Future Energy Systems (ACM e-Energy). Cambridge, UK.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This release is hopefully just the beginning of the toolkit’s
contribution to energy disaggregation, and as such we welcome feedback
and contributions to all aspects of the project.&lt;/p&gt;
&lt;p&gt;This has been cross posted via &lt;a href="http://nipunbatra.github.io/"&gt;Nipun Batra’s blog&lt;/a&gt;, &lt;a href="http://jack-kelly.com/"&gt;Jack Kelly’s
blog&lt;/a&gt;, &lt;a href="http://blog.oliverparson.co.uk"&gt;Oliver Parson’s blog&lt;/a&gt; and the &lt;a href="http://intranet.orchid.ac.uk/blog"&gt;ORCHID project blog&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Wed, 16 Apr 2014 07:12:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-04-16:2014/04/introducing-nilmtk-an-open-source-toolkit-for-non-intrusive-load-monitoring/</guid><category>nilm</category><category>Python</category></item><item><title>Courses on computational sustainability, green computing, buildings</title><link>http://nipunbatra.github.io/2014/03/courses-on-computational-sustainability-green-computing-buildings/</link><description>&lt;p&gt;In this post I mention about some recent courses on computational
sustainability, green computing and related topics. I will update this
list periodically. In case you have a suggestion, please drop a comment.
Many of these courses are reading oriented and the readings cover some
of the most relevant work in the field.&lt;/p&gt;
&lt;script src="https://gist.github.com/nipunreddevil/9922f221053f39a8144f.js"&gt;&lt;/script&gt;

&lt;p&gt;NB: If you wish me to include your course, please fork this &lt;a href="https://gist.github.com/nipunreddevil/9922f221053f39a8144f"&gt;gist&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sat, 08 Mar 2014 16:11:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-03-08:2014/03/courses-on-computational-sustainability-green-computing-buildings/</guid><category>buildings</category><category>energy</category></item><item><title>Different standard deviation formulae used in R and Python</title><link>http://nipunbatra.github.io/2014/03/different-in-standard-deviation-formulae-used-in-r-and-python/</link><description>&lt;p&gt;Let us create the same arrays in both the languages and calculate their
standard deviations.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Python&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [78]: a = np.array(range(10))

In [79]: a  
Out[79]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

In [80]: np.std(a)  
Out[80]: 2.8722813232690143
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;R&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;\&amp;gt; a\&amp;lt;-c(0:9)  
\&amp;gt; a  
[1] 0 1 2 3 4 5 6 7 8 9  
\&amp;gt; sd(a)  
[1] 3.02765
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Wondering why the different results? This is due to the difference in
formulae being used in the different implementation. &lt;/p&gt;
&lt;p&gt;The following &lt;a href="http://www.mathsisfun.com/data/standard-deviation-formulas.html"&gt;link&lt;/a&gt; &lt;span style="line-height:1.5em;"&gt;contains more
information explaining the differences between the two formulae (which
differ ever so slightly)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Population&lt;/strong&gt; Standard Deviation:&lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.mi2f.com/m/data/images/standard-deviation-formula.gif" alt="[7]" title="[7]"&gt;&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Sample&lt;/strong&gt; Standard Deviation: &lt;/p&gt;
&lt;p&gt;&lt;img src="http://www.mathsisfun.com/data/images/standard-deviation-sample.gif" alt="[7]" title="[7]"&gt;&lt;/p&gt;
&lt;p&gt;In R the latter formula is used, whereas in the NumPy implementation,
the former is used.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Thu, 06 Mar 2014 18:11:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-03-06:2014/03/different-in-standard-deviation-formulae-used-in-r-and-python/</guid><category>Python</category><category>R</category></item><item><title>Plotting power consumption breakdown</title><link>http://nipunbatra.github.io/2014/03/plotting-power-consumption-breakdown/</link><description>&lt;p&gt;Itemized billing or breaking down overall energy bill can be useful to
the end user to try and understand and subsequently optimize their
energy consumption. This forms the core of NILM research. In this post,
I use &lt;a href="https://github.com/nilmtk/nilmtk"&gt;nilmtk&lt;/a&gt; to preprocess &lt;a href="http://iawe.github.io/"&gt;iAWE&lt;/a&gt; data set and plot itemized
energy consumption for a day, when ground truth is available. This
routine can also form an integral part of nilmtk soon, where the
disaggregated time series are plotted. We can see in the figure below
that a significant proportion of energy is unaccounted. This is due to
the fact that fans, lights, etc. were not instrumented owing to their
non-trivial setup. During the night time, the air conditioners are used
and heavily dominate the overall energy consumption. We can also observe
the periodic nature of refrigerator power consumption from this plot.&lt;/p&gt;
&lt;p&gt;&lt;img width="300" src="../../../images/nilm.png"&gt;&lt;/p&gt;
&lt;p&gt;The following is the code used to generate the static plot.&lt;/p&gt;
&lt;p&gt;[gist:id=9386190]&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Thu, 06 Mar 2014 15:09:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-03-06:2014/03/plotting-power-consumption-breakdown/</guid><category>dataset</category><category>energy</category></item><item><title>Does ADC wire length affect sensor reading?</title><link>http://nipunbatra.github.io/2014/03/does-adc-wire-length-affect-sensor-reading/</link><description>&lt;p&gt;In our ISSNIP paper entitled "Experiences with Occupancy Based Building
Management Systems" (&lt;a href="http://nipunbatra.files.wordpress.com/2013/01/issnip.pdf"&gt;pdf&lt;/a&gt;, &lt;a href="https://dl.dropboxusercontent.com/u/75845627/Nipun_Batra_IIIT.pptx"&gt;slides&lt;/a&gt;), we had discussed about the
implications of wire length when used to measure ADC data. The setup is
as follows. Two neighboring faculty offices were connected to a common
microcontroller board and the room temperature, motion and door status
were captured. We interfaced the motion and door status sensor over GPIO
and temperature sensor over ADC. When we simultaneously analyzed the
temperature of the two rooms, we found that there is almost a constant
significant temperature delta amongst the two. We concluded that this is
due to the difference in wire length used for carrying the ADC signal.
As wire length increases, there is significant drop in voltage and hence
the assumed measured value. I plan to release the data set used in the
paper soon. 
The following code snippet analyzes the data and shows the difference.&lt;/p&gt;
&lt;script src="https://gist.github.com/nipunreddevil/9289377.js"&gt;&lt;/script&gt;

&lt;p&gt;The static plot looks like the following. Room 2 had significantly
longer wire length and thus more signal drop!&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nipunbatra.files.wordpress.com/2014/03/temp_comparison.png"&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sat, 01 Mar 2014 19:07:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-03-01:2014/03/does-adc-wire-length-affect-sensor-reading/</guid><category>energy</category><category>Python</category><category>sensors</category><category>visualization</category></item><item><title>iAWE data collected from Android phones</title><link>http://nipunbatra.github.io/2014/02/iawe-data-collected-from-android-phones/</link><description>&lt;p&gt;In the &lt;a href="http://nipunbatra.wordpress.com/2014/02/26/preparing-bluetooth-data-collected-from-funf-for-analysis/"&gt;previous post&lt;/a&gt;, I had briefly discussed about the Android data
collected via FunF in the iAWE data set. In this post, I mention what
all data sources these Android data sets exposed. 
After the initial steps outlined before, I work in an IPython shell and
make different queries. 
&lt;script src="https://gist.github.com/nipunreddevil/9226726.js"&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;Now, we analyze each of the probes and create their respective CSVs.
Acceleromter  and location information(LocationProbe and
SimpleLocationProbe) are not of use since the phones were kept static.
Proxomity sensor did not capture any useful information.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cell Tower &lt;/strong&gt; 
The cell tower probe provides the cell tower id (cid), location area
code and "psc" &lt;/p&gt;
&lt;script src="https://gist.github.com/nipunreddevil/ecd180672e187953ddd7.js"&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;WiFi&lt;/strong&gt;&lt;/p&gt;
&lt;script src="https://gist.github.com/nipunreddevil/9227568.js"&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Audio&lt;/strong&gt; &lt;/p&gt;
&lt;script src="https://gist.github.com/nipunreddevil/9227599.js"&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Battery&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;These features not only tell about the percent charge and some estimate
of the temperature, they also tell the status of charging. This can
provide information about power outages (when phone is discharging). &lt;/p&gt;
&lt;script src="https://gist.github.com/nipunreddevil/9227804.js"&gt;&lt;/script&gt;

&lt;p&gt;Apart from these, two Android phones which were used also had Light
sensor, whose details are as follows. The light sensor gives the light
intensity in lumens. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Light&lt;/strong&gt; &lt;/p&gt;
&lt;script src="https://gist.github.com/nipunreddevil/9227888.js"&gt;&lt;/script&gt;

&lt;p&gt;All the code can be found in the following repo:
https://github.com/nipunreddevil/iawe_funf
I shall soon be adding this data set to iAWE data set contained here:
http://iawe.github.io&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Wed, 26 Feb 2014 17:02:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-02-26:2014/02/iawe-data-collected-from-android-phones/</guid><category>buildings</category><category>dataset</category><category>energy</category><category>iawe</category><category>india</category><category>nilmtk</category><category>Python</category></item><item><title>Preparing Bluetooth data collected from FunF for analysis</title><link>http://nipunbatra.github.io/2014/02/preparing-bluetooth-data-collected-from-funf-for-analysis/</link><description>&lt;p&gt;During the last summer, I undertook a deployment in a 3 person family
home in New Delhi. This led to the release of the Indian data for
ambient water and energy (iAWE). More details may be found on the [dataset page][] or on the &lt;a href="https://dl.dropboxusercontent.com/u/75845627/buildsys_paper.pdf"&gt;publication&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As a part of the deployment, we also used 5 Android phones for
collecting data such as light, Bluetooth, cell towers etc. &lt;a href="http://www.funf.org/journal.html"&gt;FunF&lt;/a&gt;
stores data in encrypted sqlite db files. The steps involved in
preparing the data for analysis are outlined here. First, we need to
decrypt the contents (need to enter the password configured while
starting FunF). This is done via decrypt utility provided in &lt;a href="https://code.google.com/p/funf-open-sensing-framework/source/browse/?repo=samples&amp;amp;name=v0.4.x"&gt;FunF analyze&lt;/a&gt;. Next, we merge these decrypted db files to a single
database. The following gist contains the code for doing the same.&lt;/p&gt;
&lt;script src="https://gist.github.com/nipunreddevil/9224681.js"&gt;&lt;/script&gt;

&lt;p&gt;Next, we leverage Pandas to read this merged sqlite db file and perform
the following operations.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Make a connection to SQLite DB&lt;/li&gt;
&lt;li&gt;Select timestamp, probe and value from the DB&lt;/li&gt;
&lt;li&gt;Filter data by bluetooth probe&lt;/li&gt;
&lt;li&gt;Make timestamp as index&lt;/li&gt;
&lt;li&gt;Convert the values from JSON to Python dict&lt;/li&gt;
&lt;li&gt;Extract RSSI, MAC and Name of Device from the above and store in the
    data frame&lt;/li&gt;
&lt;li&gt;Delete all other columns&lt;/li&gt;
&lt;li&gt;Save file to CSV&lt;/li&gt;
&lt;/ol&gt;
&lt;script src="https://gist.github.com/nipunreddevil/9224575.js"&gt;&lt;/script&gt;

&lt;p&gt;The following is the list of names seen by this Android phone.&lt;/p&gt;
&lt;script src="https://gist.github.com/nipunreddevil/9224722.js"&gt;&lt;/script&gt;

&lt;p&gt;Out of the following 4 belong to residents, whereas the remaining are of
visitors or of people from nearby homes. I will post these CSVs to the
data set page soon and will also post some initial analysis on this
data. The original merged DB file was 1.8 GB and this CSV is a mere 370
KB as a lot of redundant information has been removed.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Wed, 26 Feb 2014 12:16:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-02-26:2014/02/preparing-bluetooth-data-collected-from-funf-for-analysis/</guid><category>dataset</category></item><item><title>Paper Summary: The Case for Apportionment</title><link>http://nipunbatra.github.io/2014/02/paper-summary-the-case-for-apportionment/</link><description>&lt;p&gt;Occupants are an integral part of energy conservation measure. 
Previous research has looked at mechanisms to actively engage occupant to reduce their energy footprint.
In this post I summarize the following paper from Buildsys 2010- &lt;a href="https://www.cl.cam.ac.uk/~acr31/pubs/hay-apportionment.pdf"&gt;The case of apportionment&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The paper motivates the need of energy apportionment from a social angle citing that in a group dinner when bills are 
shared, no one tries to subsidize the fellow diners.&lt;br /&gt;
 Several apportionment strategies are discussed.
 All apportionment policies should have the following two properties:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Completeness&lt;/strong&gt;: The sum of energy apportioned to individuals must add up to total energy&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Accountability&lt;/strong&gt;: Actions by users should have maximal impact on their allocation and minimum on others&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The apportionment strategies may be summarized as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Static apportionment&lt;/strong&gt;: In this strategy the total energy consumption is divided equally among all the users. 
 It violates accountability as every user is allocated same energy use.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dynamic apportionment&lt;/strong&gt;: A prerequisite to this set of approaches is to find individual’s occupancy timings.
 For instance, if a user is not present, should she be charged for electricity consumption.&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Occupants policy&lt;/strong&gt;: In this strategy the instantaneous power consumption is divided 
among the present occupants.This violates completeness owing to base automatic loads. 
 An enhancement over this policy is to divide the base load equally among all users. 
  This however violates accountability as an occupant may shift her load to base load and get subsidies 
   for the same.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Personal load policy&lt;/strong&gt;: In contrast to the occupants policy, this policy tries to estimate individual 
 user’s load and equally divide the remaining. The strategy allocates average power consumption to a user.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Both the approaches yield similar results. The authors also discuss about refining personal consumption in shared loads. 
 While for activities like printing, the apportionment is possible by accessing printer logs, a similar analysis of 
  the coffee machine is nontrivial. While location services might reveal more information, their lablike 
   environment requirements, make them unsuitable for daily operations.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Tue, 25 Feb 2014 16:32:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-02-25:2014/02/paper-summary-the-case-for-apportionment/</guid><category>buildings</category><category>energy</category></item><item><title>Paper Summary: Challenges in Resource Monitoring for Residential Spaces</title><link>http://nipunbatra.github.io/2014/02/paper-summary-challenges-in-resource-monitoring-for-residential-spaces/</link><description>&lt;p&gt;As the adage goes, "If you can not measure it, you can not improve it",
resource monitoring is considered the first step towards improving it.
Residential spaces contain multiple resources such as electricity, water
and gas. In this post,  I summarize the following paper entitled
: &lt;a href="http://wiesel.ece.utah.edu/media/documents/pdf/2010/01/23/BUILDSYS09-YK.pdf"&gt;Challenges in Resource Monitoring for Residential Spaces&lt;/a&gt;. This
paper was presented at the first edition of Buildsys held in 2009.&lt;/p&gt;
&lt;p&gt;The paper discuss about the various resources in homes- water,
electricity, gas. The relationship between energy and water is brought
forward. Water is used to generate electricity in hydroelectric power
plants. On the other hand, electricity is used for water treatment. The
paper brings forward insights from  a 3 month deployment where water and
energy data was synchronously collected.&lt;/p&gt;
&lt;p&gt;A comparison between water and energy activities is made. Typically, the
number of water fixtures within a home is much less than the number of
electrical fixtures. Water usage is often very sporadic. In contrast,
electricity usage is more spread out and often of a compound nature.
Often, there is a static power consumption by some appliances. The water
analogy would be constantly dripping fixtures. These factors combined
with the similarity of signatures exhibited by many elelctrical
appliances, makes energy disaggregation considerably harder than its
water analogue.&lt;/p&gt;
&lt;p&gt;The authors use a  &lt;a href="http://en.wikipedia.org/wiki/Matched_filter"&gt;Matched filter&lt;/a&gt; to detect water fixture acitivity.
Owing to the characteristics described above, it is easy to match big
water consuming fixtures such as the sprinkler. The authors highlight
that the approach is limited to big water consuming fixtures and for
smaller fixtures, there exists a direct accuracy-cost tradeoff. On
similar lines, the authors discuss some of the limitations of NILM.&lt;/p&gt;
&lt;p&gt;Since the deployment covered both water and energy, the interplay
amongst the two can offer richer information. The authors illustrate
this by showing the synchronous water and energy footprint of a laundry
machine.&lt;/p&gt;
&lt;p&gt;The authors highlight the challenges in fine grained resource
monitoring, some of which are as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;User adaptation amidst&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;maintenance&lt;/li&gt;
&lt;li&gt;privacy concerns- how best to balance information and privacy
    while meeting design goals&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Design spanning cost, accuracy, reliability&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Effective data processing and visualization enabled communication
    with end users&lt;/li&gt;
&lt;li&gt;Trade offs amongst existing techniques&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;An interesting notion of efficiency incorporating ambient conditions is
discussed. For instance, simply the raw water consumption by a water
sprinkler is of less importance when compared to the environment context
(eg. why to water if it rains).&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Mon, 24 Feb 2014 15:26:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-02-24:2014/02/paper-summary-challenges-in-resource-monitoring-for-residential-spaces/</guid><category>buildings</category><category>energy</category><category>nilm</category></item><item><title>Electricity transmission losses across the world</title><link>http://nipunbatra.github.io/2014/02/electricity-transmission-losses-across-the-world/</link><description>&lt;p&gt;The following &lt;a href="http://data.worldbank.org/indicator/EG.ELC.LOSS.ZS"&gt;webpage&lt;/a&gt; contains information for electricity
transmission losses around the world. I obtained the data and plot it on
a world map. The resultant plot is shown below. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Transmission losses" src="http://nipunbatra.files.wordpress.com/2014/02/losses.png" /&gt;&lt;/p&gt;
&lt;p&gt;The redder the country encoding, the more the losses. I am working on
the legend for the same. As expected, North America, Europe and
Australia have low transmission losses. Some parts of Asia and Africa
have high transmission losses. The script used to generate the plot
(inspired from the &lt;a href="https://github.com/matplotlib/basemap/blob/master/examples/fillstates.py"&gt;following&lt;/a&gt;) is available below. The shapefile data
was downloaded from &lt;a href="http://geocommons.com/overlays/33578"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;[[ gist nipunreddevil:9168891 ]]&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sun, 23 Feb 2014 14:28:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-02-23:2014/02/electricity-transmission-losses-across-the-world/</guid><category>energy</category><category>nilm</category></item><item><title>Paper summary: Building Application Stack (BAS)</title><link>http://nipunbatra.github.io/2014/02/paper-summary-building-application-stack-bas/</link><description>&lt;p&gt;Buildings house a number of sensors  and actuator ranging across various
applications including, but not limited to, utility metering (water,
gas, electricity), HVAC control, lighting, security. Each of these
sub-systems usually expose their data over different protocols making it
difficult to design generic applications on top. This gets particularly
hard when moving across different buildings. Maybe, time to do software
engineering for buildings?&lt;/p&gt;
&lt;p&gt;In this post I summarize the paper &lt;a href="http://www.cs.berkeley.edu/~krioukov/BAS.pdf"&gt;Building Application Stack (BAS)&lt;/a&gt;
which won the best paper award at Buildsys 2012. The paper motivates the
need of an API for building applications owing to lack of "portability"
in building applications. While many Building automation protocols such
as BACnet, LONtalk partially address this via their schemes, the lack of
portability remains a concern. Another target of the paper is to be able
to answer and address queries such as the following: What is the
&lt;strong&gt;light&lt;/strong&gt; level of on all floors &lt;strong&gt;above&lt;/strong&gt; the &lt;strong&gt;10th floor?&lt;/strong&gt;For
answering such queries sensors and its abstractions are necessary, but
not complete. The various relationships among different sensors,
actuator, physical spaces, etc. should be taken into account.&lt;/p&gt;
&lt;p&gt;The approach followed in the paper is based on well known software
engineering principles. The layered architecture is summarized at
follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Close to the hardware is the interconnection interface which exposes
    the hardware points via their protocols such as BACnet. These points
    have non-trivial names such as “SDH.AH1A.SF VFD:INPUT" which is a
    speed input to variable frequency drive.&lt;/li&gt;
&lt;li&gt;To introduce portability, the next layer consists of drivers which
    expose necessary interfaces. For instance, a fan driver would expose
    get_speed() and set_speed(x). Drivers can be constructed in
    hierarchical fashion. HVAC chiller driver may contain drivers for
    fan etc.&lt;/li&gt;
&lt;li&gt;Functional and spatial relationships are needed to answer questions
    like which circuit powers lighting, which AHU serves a particular
    room. For modeling functional relationships, BAS uses directed
    graphs. For modeling spatial relationships BAS incorporates spatial
    tags.&lt;/li&gt;
&lt;li&gt;The top most layer is the query layer and allows accessing driver
    objects based on different attributes. Those who know about jQuery
    might see some parallels with the driver access. BAS query layer is
    language agnostic.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The authors use BAS and compare its tradeoff with conventional
customized building applications across two buildings and two
application scenarios. The intended purposes are evident by the minimal
changes required while porting across buildings which use different
automation protocols. In conclusion, the paper brings software
engineering to the buildings domain and the rich query interface allows
diverse set of applications to be built easily on top of BAS.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Wed, 19 Feb 2014 17:47:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-02-19:2014/02/paper-summary-building-application-stack-bas/</guid><category>buildings</category><category>energy</category></item><item><title>Best paper awards at Buildsys</title><link>http://nipunbatra.github.io/2014/02/best-paper-awards-at-buildsys/</link><description>&lt;p&gt;In this post I enlist the papers awarded the best paper, poster and
student paper awards at Buildsys.  Buildsys is a workshop held in
conjunction with SenSys.&lt;/p&gt;
&lt;p&gt;For 2011-2013, the information is available on the official Buildsys
website. For the remaining, I googled to get the information.&lt;/p&gt;
&lt;h4&gt;2013&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://www.orchid.ac.uk/eprints/177/1/01_Rogers.pdf"&gt;A Scalable Low-Cost Solution to Provide Personalised Home Heating
Advice to Households&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://blizzard.cs.uwaterloo.ca/iss4e/wp-content/uploads/2013/10/buildsys-camera.pdf"&gt;Optimal Personal Comfort Management Using SPOT&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;2012&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://www.cs.berkeley.edu/~krioukov/BAS.pdf"&gt;Building Application Stack (BAS)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://repository.upenn.edu/cgi/viewcontent.cgi?article=1069&amp;amp;context=mlab_papers"&gt;MLE+: A Tool for Integrated Design and Deployment of Energy Efficient
Building Controls&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;2011&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://repository.tudelft.nl/assets/uuid:5145ff67-ce2e-4551-93d3-b74fffe75cd7/MS-32.714.pdf"&gt;Co-simulation Based Building Controls Implementation with Networked
Sensors and Actuators&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://users.ece.cmu.edu/~agr/resources/publications/buildsys-app-class-11.pdf"&gt;Appliance Classification and Energy Management Using Multi-Modal
Sensing&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;2010&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://users.ece.cmu.edu/~agr/resources/publications/buildsys-10.pdf"&gt;Contactless Sensing of Appliance State Transitions&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;2009&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://inside.mines.edu/~qhan/research/publication/buildsys09.pdf"&gt;Using Circuit-Level Power Measurements in Household Energy Management
Systems&lt;/a&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Wed, 19 Feb 2014 15:41:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-02-19:2014/02/best-paper-awards-at-buildsys/</guid><category>buildings</category><category>research</category></item><item><title>Paper summary:: SmartCap: Flattening Peak Electricity Demand in Smart Homes</title><link>http://nipunbatra.github.io/2014/02/paper-summary-smartcap-flattening-peak-electricity-demand-in-smart-homes/</link><description>&lt;p&gt;Many studies have proposed methods of reducing electricity consumption.
However, for the utility companies, merely reducing overall consumption
may not amount to reduction in production. This is due to the fact that
the peak load drives the grid's production. Thus, reducing the peak load
on the grid by load shifting can help lower the peak demand on the grid.
To help realize such a goal, utilities often charge commercial customers
based on peak v/s non-peak demand. In this post, I summarize the
following paper titled: &lt;a href="http://citeseerx.ist.psu.edu/viewdoc/download?rep=rep1&amp;amp;type=pdf&amp;amp;doi=10.1.1.221.2314"&gt;SmartCap: Flattening Peak Electricity Demand in
Smart Homes&lt;/a&gt;, from&lt;a href="http://lass.cs.umass.edu/"&gt;LASS group&lt;/a&gt;, UMASS.&lt;br /&gt;
The paper studies the different types of loads(appliances) present in a
typical home. They are divided into two broad categories:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Interactive: such as television, microwave, which are actively
    controlled by a user&lt;/li&gt;
&lt;li&gt;Background: such as fridge, air conditioner, which have their own
    control systems and once temperature settings are maintained they
    operate without human intervention.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The authors emphasize the fact that modifying the schedule of
interactive loads is not considered as it may interfere with daily
operations. Thus, they consider scheduling only the background loads.
Background loads constitute a very small proportion of overall number of
loads (10% or so). However, they may contribute very significantly to
the overall energy consumption, eg. air conditioners and refrigerators
are usually the loads contributing the most during the peak summer
season. Both these kinds of loads show a lot of variability in their
operations- background loads due to environmental conditions and the
interactive loads due to activity.&lt;/p&gt;
&lt;p&gt;The authors draw inspiration from the Earliest deadline scheduling
algorithm, which is a well know algorithm used for scheduling real time
embedded systems.  The key component of the algorithm is "slack" which
the authors define as the extent to which a scheduler is able to
advance, defer, raise, or lower a load’s power consumption without
affecting its operational goal. In the case of electrical load
scheduling the operational goal is defined in terms of its intended
state after running, eg. after one complete cycle the internal
refrigerator temperature should reach 10 degrees.  The slack of a load
is defined as the time which it can remain off without missing its
objective. Similar to scheduling in real time embedded systems,
information about remaining slack is known. However, the important
difference is that the algorithm presented by the authors is modified to
suit the case when slacks may vary with time, unlike in many scheduling
algorithms where the slacks are pre submitted. This is an important
feature of the paper and a simple linear slack model is assumed by the
authors for the same.&lt;/p&gt;
&lt;p&gt;The authors present results both from simulation and from data collected
in real world settings. Under both these data sets, they show that their
approach helps to lower the deviation from average consumption (making
the load curve flatter). The approach provides higher gains when used in
peak consumption period such as morning breakfast hours when many
interactive loads are also on.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Tue, 18 Feb 2014 17:27:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-02-18:2014/02/paper-summary-smartcap-flattening-peak-electricity-demand-in-smart-homes/</guid><category>buildings</category><category>energy</category><category>nilm</category></item><item><title>Impact of Energy Disaggregation on Consumer Behavior: Summary</title><link>http://nipunbatra.github.io/2014/02/impact-of-energy-disaggregation-on-consumer-behavior-summary/</link><description>&lt;p&gt;The benefits of NILM or energy disaggregation have been questioned a lot
recently. Many argue that though the field is academically attractive,
it poses little value. Almost every NILM paper cites a study which
discusses that providing detailed feedback to the consumers might cut
down electricity consumption by upto 15%. Some of these are discussed by
&lt;a href="http://suman.inferlab.org/"&gt;Suman Giri&lt;/a&gt; in his following two posts about motivating NILM: &lt;a href="http://suman.inferlab.org/building-up-the-motivation-for-non-intrusive-load-monitoring/"&gt;Post
1&lt;/a&gt; and &lt;a href="http://suman.inferlab.org/building-up-the-motivation-ii/"&gt;2&lt;/a&gt;. The concerns mentioned seem very valid.&lt;/p&gt;
&lt;p&gt;Recently, there was an &lt;a href="http://escholarship.org/uc/item/62d3456p"&gt;interesting publication&lt;/a&gt; from &lt;a href="http://www.bidgely.com/"&gt;Bidgely&lt;/a&gt;, the
energy disaggregation startup from CA. In this post, I summarize some of
the main findings.&lt;/p&gt;
&lt;p&gt;The paper discusses two user studies. Firstly, to quantify the benefits
from energy disaggregation. Secondly, it discusses about user engagement
via energy disaggregation. For the first study, they recruited two kinds
of participants living in CA: those who were already exposed to Bidgely
(called Treatment group) and those who were not (called Control group).
 The recruitment and user study were carried on a rolling basis. For the
treatment group, their 3 months of energy data prior to enrolling was
taken as their control condition. The paper presents results when they
had roughly 160 users across both groups with a fairly even geographical
distribution of consumers.&lt;/p&gt;
&lt;p&gt;On an average, the Treatment group was consuming about 14% less than the
control group. Also, the authors report that with a 95% confidence,
there is a saving between 3 and 24%.  The authors believe that the users
exposed to Bidgely had energy savings of 14% on average due to
behavioral changes, as opposed to insulation or appliance upgrades.&lt;/p&gt;
&lt;p&gt;In the second case study, 150 users taking services from an
international market energy retailer were given an access to Bidgely's
energy management platform for five months. Consumers were provided the
following feedback on their consumption (varying across temporal
resolution):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Real time energy information&lt;/li&gt;
&lt;li&gt;Periodic usage alerts&lt;/li&gt;
&lt;li&gt;Summary emails&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The feedback provided historical comparison of electricity consumption
in raw and diasaggregated form, in addition to real time information. It
also hinted possible culprits when energy usage spiked up, apart from
other tips. The study measured user engagement via a 20 question survey
and Google Analytics. The study revealed that about 40% of the users
were able to discover and correct energy inefficiencies. The study also
highlighted that the consumers found the real time information,
dissaggregated information and historical comparison of energy
consumption most helpful. In contrast, the users took low liking to
energy saving tips and efficiency scores. About 90% of the consumers
reported that they would recommend such a service to others.&lt;/p&gt;
&lt;p&gt;The authors conclude by summarizing the main finding- real time energy
information and energy itemization can influence behavior which can
drive energy (and cost) savings. The authors also make a case of
understanding energy disaggregation to be a mean rather than an end and
motivating the need of providing actionable insights to the consumers.&lt;/p&gt;
&lt;p&gt;This paper was presented at the 2013 &lt;a href="http://beccconference.org/"&gt;Behavior, Energy and Climate
Change (BECC) Conference&lt;/a&gt;. Other interesting papers accepted at this
conference may be found at: &lt;a href="http://escholarship.org/uc/bie_becc_2013"&gt;http://escholarship.org/uc/bie_becc_2013&lt;/a&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sun, 16 Feb 2014 13:16:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-02-16:2014/02/impact-of-energy-disaggregation-on-consumer-behavior-summary/</guid><category>energy</category><category>nilm</category><category>phd</category></item><item><title>Contribution of buildings to energy usage</title><link>http://nipunbatra.github.io/2014/02/contributions-of-buildings-to-energy-usage/</link><description>&lt;p&gt;In this post I summarize the contribution of buildings to the overall energy footprint. Various systems such as transportation, manufacturing, buildings contribute to the overall energy consumption. Energy consumption is comprised of electricity, water, gas, etc.  The following figure shows the percentage contribution of buildings to overall energy consumption across 5 countries.&lt;/p&gt;
&lt;p&gt;&lt;img alt="contribution" src="http://nipunbatra.files.wordpress.com/2014/02/contribution.png" /&gt;&lt;/p&gt;
&lt;p&gt;The contribution of buildings to overall energy consumption in India is
significantly higher than the number in Australia.&lt;br /&gt;
All of the above numbers are referred from the various Country reports
on Building Energy Codes which are as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://www.pnl.gov/main/publications/external/technical_reports/PNNL-17925.pdf"&gt;India&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pnl.gov/main/publications/external/technical_reports/PNNL-17979.pdf"&gt;USA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pnl.gov/main/publications/external/technical_reports/PNNL-17909.pdf"&gt;China&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.pnl.gov/main/publications/external/technical_reports/PNNL-17851.pdf"&gt;Korea&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.energycodes.gov/sites/default/files/documents/CountryReport_Australia.pdf"&gt;Australia&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Building space is being added at an alarming rate and these numbers are
only expected to grow (unless measures are taken).&lt;/p&gt;
&lt;p&gt;Following is the code (and data) used to generate the above plot.&lt;/p&gt;
&lt;p&gt;[[ gist nipunreddevil:8950905 ]]&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Wed, 12 Feb 2014 11:51:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-02-12:2014/02/contributions-of-buildings-to-energy-usage/</guid></item><item><title>Decoding your electricity bill</title><link>http://nipunbatra.github.io/2014/02/decoding-your-electricity-bill/</link><description>&lt;p&gt;Natural resources are fast dwindling and subsequently electricity prices
increasing with the increase in demand. In this series of posts I will
discuss about understanding electricity consumption.&lt;/p&gt;
&lt;p&gt;In this post, I analyze my home's monthly electricity consumption. I
shall be dealing with only 1 of the meter, while the analysis for the
other one should be on same lines.&lt;br /&gt;
Let us look at the front side of the bill first.&lt;/p&gt;
&lt;p&gt;&lt;img alt="front" src="http://nipunbatra.files.wordpress.com/2014/02/front1.jpg?w=620" /&gt;&lt;/p&gt;
&lt;p&gt;The back side of the bill contains information regarding the tariff
which is as follows:&lt;/p&gt;
&lt;p&gt;&lt;img alt="back" src="http://nipunbatra.files.wordpress.com/2014/02/back.jpg?w=620" /&gt;&lt;/p&gt;
&lt;p&gt;Let us analyze the front side of the bill. It contains the follow&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Units consumed in billing period: In the above case, it being 405
    units (kWh) for a billing period of 32 days.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bill breakup: This contains the breakup of the bill as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Fixed charges: This being 100 Rs. as per the tariff mentioned
    below (on the back side)&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Slab wise energy charge: Electricity keeps getting expensive as
    you consume more. This is as per the slabs described in the
    tariff. For domestic users, it is as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;0-200 units: Rs. 3.70/unit&lt;/li&gt;
&lt;li&gt;201-400 units: Rs. 5.50/unit&lt;/li&gt;
&lt;li&gt;400+ units: Rs. 6.50/unit&lt;/li&gt;
&lt;li&gt;As we can see in the bill, the utility charged 207 units in
    the first slab and the remaining 198 in the next slab (Rs.
    5.50/unit)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Slab wise power purchase charges&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Time of day charge: I think this is relevant only to commercial
    entities&lt;/li&gt;
&lt;li&gt;Surcharge&lt;/li&gt;
&lt;li&gt;Electricity taxes&lt;/li&gt;
&lt;li&gt;Total amount (which is #1+#2+#3..+#6)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We can observe that the amount we pay for actual usage (#2) is about
Rs.  1850 which is about Rs. 500 less than the total amount we paid. We
do pay a lot of taxes!&lt;/p&gt;
&lt;p&gt;If we observe the tariff in minute details, we can observe that a lot of
entities such as Delhi Jal Board (Water utility), DMRC (Metro) pay for
kVAh as opposed to kWh. The technical difference being that kWh is
active energy whereas kVAh is apparent energy. This suggests that in
these entities, inductive loads contribute significantly.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Fri, 07 Feb 2014 12:24:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-02-07:2014/02/decoding-your-electricity-bill/</guid><category>electricity</category></item><item><title>Kingsoft office for Linux</title><link>http://nipunbatra.github.io/2014/01/kingsoft-office-for-linux/</link><description>&lt;p&gt;I had been shifting to Windows every time I needed to make a
presentation (non-LaTeX and no-HTML5). Libre Office is good, but,
somehow, I found MS Office much friendlier to use.&lt;/p&gt;
&lt;p&gt;Recently, I got to know about Kingsoft office, which is a clone of MS
Office made by a Chinese firm. And really it is a clone.&lt;/p&gt;
&lt;p&gt;&lt;img alt="kingsoft" src="http://nipunbatra.files.wordpress.com/2014/01/kingsoft.png?w=620" /&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Fri, 31 Jan 2014 18:21:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-01-31:2014/01/kingsoft-office-for-linux/</guid><category>linux</category><category>office</category></item><item><title>Plugins for Python development in Sublime Text</title><link>http://nipunbatra.github.io/2014/01/plugins-for-python-development-in-sublime-text/</link><description>&lt;p&gt;Recently, I was having a conversation with &lt;a href="http://correa.in/"&gt;Denzil&lt;/a&gt;, comparing
&lt;a href="http://www.rstudio.com/"&gt;RStudio&lt;/a&gt; with IDEs supporting Python. We both felt that Python IDEs
are not that complete. Both of us and many other people developing
Python code run &lt;a href="http://www.sublimetext.com/"&gt;Sublime Text&lt;/a&gt;. Sublime Text comes with a rich suite
of user written plugins. In this post, I highlight some of the plugins
which I have currently installed and have been helpful in Python
development.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/wistful/SublimeAutoPEP8"&gt;AutoPep8&lt;/a&gt;: "Code is read more often than it is written". Sticking
    to PEP8 does help. This plugin helps you to automatically convert
    your code to PEP8. I have modified the default behavior and AutoPEP8
    is triggered every time I save a file.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://sublimecodeintel.github.io/SublimeCodeIntel/"&gt;SublimeCodeIntel&lt;/a&gt;: Intellisense + Lot more. Also shows up the
    docstrings for a function&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/wuub/SublimeREPL"&gt;SublimeREPL&lt;/a&gt;: A full REPL inside Sublime Text. The biggest win is
    IPython! You can evaluate parts of code, selection, blocks, etc.
     just with a few keystrokes. The figure below shows an IPython
    session making a Matplotlib plot based on the code in the other
    panel. Before using this plugin, I would copy paste stuff into an
    IPython shell when I wanted to run bits of the code.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="auto complete" src="http://nipunbatra.files.wordpress.com/2014/01/auto_complete.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="plot" src="http://nipunbatra.files.wordpress.com/2014/01/plot.png" /&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Thu, 30 Jan 2014 12:47:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-01-30:2014/01/plugins-for-python-development-in-sublime-text/</guid><category>Python</category></item><item><title>Avoiding thrashing by memory hungry Python programs</title><link>http://nipunbatra.github.io/2014/01/avoiding-thrashing-by-memory-hungry-python-programs/</link><description>&lt;p&gt;While I was developing NILM algorithms for &lt;a href="https://github.com/nilmtk/nilmtk"&gt;NILM toolkit&lt;/a&gt;, I
encountered OS thrashing and I had to restart my OS several times.
Thrashing occurs when your program runs out of RAM and the OS starts
allocating disk for the process's memory requirement. For the curious,
the algorithm which I was working on is called Factorial Hidden Markov
Model. &lt;a href="https://github.com/nilmtk/nilmtk/issues/67"&gt;Here&lt;/a&gt; is the corresponding issue on Github.&lt;/p&gt;
&lt;p&gt;I read a bit on setting memory limits for programs. Some relevant links
include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;http://docs.python.org/2/library/resource.html&lt;/li&gt;
&lt;li&gt;http://stackoverflow.com/questions/1760025/limit-python-vm-memory&lt;/li&gt;
&lt;li&gt;http://stackoverflow.com/questions/4285185/python-memory-limit&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Following is a tiny snippet illustrating the concept:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;resource&lt;/span&gt;  
&lt;span class="n"&gt;megs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;  
&lt;span class="n"&gt;resource&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setrlimit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;resource&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RLIMIT&lt;/span&gt;\&lt;span class="n"&gt;_AS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;megs&lt;/span&gt; \&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="il"&gt;1048576L&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="il"&gt;1L&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;  
    &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This program has a limit of 5 MB. Does it take more than that? Lets
try!  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;nipun@nipun-Satellite-L850:&lt;span class="se"&gt;\~&lt;/span&gt;/Desktop&lt;span class="se"&gt;\$&lt;/span&gt; python &lt;span class="nb"&gt;test&lt;/span&gt;&lt;span class="se"&gt;\_&lt;/span&gt;limit.py  
Traceback &lt;span class="o"&gt;(&lt;/span&gt;most recent call last&lt;span class="o"&gt;)&lt;/span&gt;:  
File &lt;span class="s2"&gt;&amp;quot;test\_limit.py&amp;quot;&lt;/span&gt;, line 4, in &lt;span class="se"&gt;\&amp;lt;&lt;/span&gt;module&lt;span class="se"&gt;\&amp;gt;&lt;/span&gt;  
&lt;span class="k"&gt;for&lt;/span&gt; i in range&lt;span class="o"&gt;(&lt;/span&gt;10000&lt;span class="o"&gt;)&lt;/span&gt;:  
MemoryError  
Error in sys.excepthook:  
Traceback &lt;span class="o"&gt;(&lt;/span&gt;most recent call last&lt;span class="o"&gt;)&lt;/span&gt;:  
File &lt;span class="s2"&gt;&amp;quot;/usr/lib/python2.7/dist-packages/apport\_python\_hook.py&amp;quot;&lt;/span&gt;, line
64, in apport&lt;span class="se"&gt;\_&lt;/span&gt;excepthook  
from apport.fileutils import likely&lt;span class="se"&gt;\_&lt;/span&gt;packaged, get&lt;span class="se"&gt;\_&lt;/span&gt;recent&lt;span class="se"&gt;\_&lt;/span&gt;crashes  
File &lt;span class="s2"&gt;&amp;quot;/usr/lib/python2.7/dist-packages/apport/\_\_init\_\_.py&amp;quot;&lt;/span&gt;, line 5,
in &lt;span class="se"&gt;\&amp;lt;&lt;/span&gt;module&lt;span class="se"&gt;\&amp;gt;&lt;/span&gt;  
from apport.report import Report  
File &lt;span class="s2"&gt;&amp;quot;/usr/lib/python2.7/dist-packages/apport/report.py&amp;quot;&lt;/span&gt;,   line 12, in
&lt;span class="se"&gt;\&amp;lt;&lt;/span&gt;module&lt;span class="se"&gt;\&amp;gt;&lt;/span&gt;  
import subprocess, tempfile, os.path, re, &lt;span class="nb"&gt;pwd&lt;/span&gt;, grp, os  
MemoryError

Original exception was:  
Traceback &lt;span class="o"&gt;(&lt;/span&gt;most recent call last&lt;span class="o"&gt;)&lt;/span&gt;:  
File &lt;span class="s2"&gt;&amp;quot;test\_limit.py&amp;quot;&lt;/span&gt;, line 4, in &lt;span class="se"&gt;\&amp;lt;&lt;/span&gt;module&lt;span class="se"&gt;\&amp;gt;&lt;/span&gt;  
&lt;span class="k"&gt;for&lt;/span&gt; i in range&lt;span class="o"&gt;(&lt;/span&gt;10000&lt;span class="o"&gt;)&lt;/span&gt;:  
MemoryError
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So a list of 10000 takes more than 5 MB in the Address Space and hence
the program throws an exception.&lt;/p&gt;
&lt;p&gt;Aside, this may be a good time to test xrange() vs range() in terms of
memory requirement. I just modified the range() call to xrange() call in
the program and the program ran fine!&lt;/p&gt;
&lt;p&gt;Clearly, when we just need to iterate, use xrange() over range() as the
latter creates a list in the Address space.&lt;br /&gt;
Hopefully, no more restarts due to thrashing now!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Wed, 01 Jan 2014 11:35:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2014-01-01:2014/01/avoiding-thrashing-by-memory-hungry-python-programs/</guid><category>nilm</category><category>Python</category></item><item><title>When memory matters: float64 vs float32 for storing data</title><link>http://nipunbatra.github.io/2013/12/when-memory-matters/</link><description>&lt;p&gt;Dealing with large dataset can be a bit of bother. Hardware has grown,
but so have the datasets. Recently, while loading some Electricity
datasets into memory with Pandas and processing on them, I was running
out of memory.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://jack-kelly.com/"&gt;Jack&lt;/a&gt; suggested that I use float32 instead of the default float64
provided by Pandas. Following is a comparison of the in-memory
comparisons between the two datatypes for representing the same data.&lt;/p&gt;
&lt;p&gt;Firstly, as suggested by Jeff on &lt;a href="http://stackoverflow.com/questions/18089667/pandas-how-to-estimate-how-much-memory-a-dataframe-will-need"&gt;Stack overflow&lt;/a&gt;, here is small
function to find the size requirements (in bytes) of a DataFrame&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [2]: def sizedf(df):  
...: return df.values.nbytes + df.index.nbytes + df.columns.nbytes
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let us create a large dataframe.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [3]: a =pd.DataFrame(random.randn(100000,10))

In [4]: a  
Out[4]:  
&amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt; 
Int64Index: 100000 entries, 0 to 99999  
Data columns (total 10 columns):  
0 100000 non-null values  
1 100000 non-null values  
2 100000 non-null values  
3 100000 non-null values  
4 100000 non-null values  
5 100000 non-null values  
6 100000 non-null values  
7 100000 non-null values  
8 100000 non-null values  
9 100000 non-null values  
dtypes: float64(10)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can see that the data type of the dataframe is float64. Let us now
create a dataframe b, casted as float32.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [5]: b = a.astype(float32)

In [6]: b  
Out[6]:  
\&amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;\&amp;gt;  
Int64Index: 100000 entries, 0 to 99999  
Data columns (total 10 columns):  
0 100000 non-null values  
1 100000 non-null values  
2 100000 non-null values  
3 100000 non-null values  
4 100000 non-null values  
5 100000 non-null values  
6 100000 non-null values  
7 100000 non-null values  
8 100000 non-null values  
9 100000 non-null values  
dtypes: float32(10)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now, let us compare the in-memory sizes of the two dataframes.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [7]: size_df(a)  
Out[7]: 8800080

In [8]: size_df(b)  
Out[8]: 4800080
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The dataframe with datatype as float32 does a lot better. What about
memory usage on disk?&lt;br /&gt;
Let us export the data to HDF5 store and see.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [9]: a.to_hdf(&amp;#39;df_a.h5&amp;#39;, &amp;#39;df&amp;#39;)

In [10]: b.to_hdf(&amp;#39;df_b.h5&amp;#39;, &amp;#39;df&amp;#39;)

In [11]: ! ls -lah df_a.h5  
-rw-rw-r-- 1 nipun nipun 8.4M Dec 16 15:22 df_a.h5

In [12]: ! ls -lah df_b.h5  
-rw-rw-r-- 1 nipun nipun 4.6M Dec 16 15:42 df_b.h5
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Clearly, we save a lot of on disk and raw memory when using float32 as
opposed to float64(which is the default). Whenever, we don't need such
high precision, float32 might just save you a lot of memory issues!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Mon, 16 Dec 2013 15:49:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-12-16:2013/12/when-memory-matters/</guid><category>Machine Learning</category><category>Python</category></item><item><title>Using namedtuples as column names in Pandas and indexing on them</title><link>http://nipunbatra.github.io/2013/12/using-namedtuples-as-column-names-in-pandas-and-indexing-on-them/</link><description>&lt;p&gt;Named tuples are interesting collection datatype in Python. They are
similar to regular Python tuple (and thus immutable), however, they
allow to &lt;strong&gt;name&lt;/strong&gt; the tuple entries. This functionality makes them
similar to structures in C.&lt;/p&gt;
&lt;p&gt;The following answer on Stack Overflow provide details about
namedtuples.&lt;/p&gt;
&lt;p&gt;&lt;a href="What%20are%20“named%20tuples”%20in%20Python?"&gt;What are “named tuples” in Python?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Now, let us explore namedtuples as column names in Pandas. The use case
comes from handling  datasets containing electricity information. In
terms of vectors, power has two orthogonal dimensions (real/active and
reactive). Let us explore this via an IPython session shown below.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;33&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;namedtuple&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;34&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;measurement&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;namedtuple&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;measurement&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;physical_quantity&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="s"&gt;&amp;quot;type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;35&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;power_active&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;measurement&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;power&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;active&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;36&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;power_active&lt;/span&gt;  
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;36&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;measurement&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;physical_quantity&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;power&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;active&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;37&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;power_active&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;  
&lt;span class="n"&gt;power_active&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="n"&gt;power_active&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;
&lt;span class="n"&gt;power_active&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;physical_quantity&lt;/span&gt; &lt;span class="n"&gt;power_active&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;37&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;power_active&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt;  
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;37&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;active&amp;quot;&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;38&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;39&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;43&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;  
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;43&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;Index&lt;/span&gt;&lt;span class="p"&gt;([(&lt;/span&gt;&lt;span class="s"&gt;u&amp;quot;power&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;quot;active&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt; &lt;span class="kp"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;44&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;power_reactive&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;measurement&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;power&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;reactive&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;45&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="n"&gt;power_active&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="n"&gt;power_reactive&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)})&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;46&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;  
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;46&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;  
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;power&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;power&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reactive&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mf"&gt;0.766687&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.514405&lt;/span&gt;  
&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mf"&gt;0.755576&lt;/span&gt; &lt;span class="mf"&gt;0.064147&lt;/span&gt;  
&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.652324&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.356600&lt;/span&gt;  
&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.685074&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.806747&lt;/span&gt;  
&lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.611555&lt;/span&gt; &lt;span class="mf"&gt;1.211177&lt;/span&gt;  
&lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.470568&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.414123&lt;/span&gt;  
&lt;span class="mi"&gt;6&lt;/span&gt; &lt;span class="mf"&gt;0.666507&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.657422&lt;/span&gt;  
&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.062245&lt;/span&gt; &lt;span class="mf"&gt;0.274607&lt;/span&gt;  
&lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.373324&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.101033&lt;/span&gt;  
&lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="mf"&gt;1.811883&lt;/span&gt; &lt;span class="mf"&gt;0.321797&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;47&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;  
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;47&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;Index&lt;/span&gt;&lt;span class="p"&gt;([(&lt;/span&gt;&lt;span class="s"&gt;u&amp;quot;power&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;quot;active&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;u&amp;quot;power&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;u&amp;quot;reactive&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt;
&lt;span class="kp"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;59&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;active&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;  
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;59&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;  
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;power&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mf"&gt;0.766687&lt;/span&gt;  
&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mf"&gt;0.755576&lt;/span&gt;  
&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.652324&lt;/span&gt;  
&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.685074&lt;/span&gt;  
&lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.611555&lt;/span&gt;  
&lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.470568&lt;/span&gt;  
&lt;span class="mi"&gt;6&lt;/span&gt; &lt;span class="mf"&gt;0.666507&lt;/span&gt;  
&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.062245&lt;/span&gt;  
&lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.373324&lt;/span&gt;  
&lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="mf"&gt;1.811883&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;60&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="n"&gt;col&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;col&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;physical_quantity&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt;
&lt;span class="s"&gt;&amp;quot;power&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;  
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;60&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;  
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;power&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;power&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reactive&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mf"&gt;0.766687&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.514405&lt;/span&gt;  
&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mf"&gt;0.755576&lt;/span&gt; &lt;span class="mf"&gt;0.064147&lt;/span&gt;  
&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.652324&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.356600&lt;/span&gt;  
&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.685074&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.806747&lt;/span&gt;  
&lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.611555&lt;/span&gt; &lt;span class="mf"&gt;1.211177&lt;/span&gt;  
&lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.470568&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.414123&lt;/span&gt;  
&lt;span class="mi"&gt;6&lt;/span&gt; &lt;span class="mf"&gt;0.666507&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.657422&lt;/span&gt;  
&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.062245&lt;/span&gt; &lt;span class="mf"&gt;0.274607&lt;/span&gt;  
&lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.373324&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.101033&lt;/span&gt;  
&lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="mf"&gt;1.811883&lt;/span&gt; &lt;span class="mf"&gt;0.321797&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In Line 3, we create the named tuple for "measurement". This has 2
attributes the physical quantity and the subtype.&lt;br /&gt;
In Line 25, we create a dataframe with namedtuples for active and
reactive power as the column header.&lt;br /&gt;
In Line 44, we select columns based on a condition on a "measurement"
field.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sun, 15 Dec 2013 11:07:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-12-15:2013/12/using-namedtuples-as-column-names-in-pandas-and-indexing-on-them/</guid><category>Python</category></item><item><title>Revisiting Matt Might's 3 shell scripts to improve your writing</title><link>http://nipunbatra.github.io/2013/08/revisiting-matt-mights-3-shell-scripts-to-improve-your-writing/</link><description>&lt;p&gt;Having made extensive use, and greatly benefited by Matt Might's article
entitled -"3 shell scripts to improve your writing", i thought of
sharing how we can apply this same set of scripts on already published
work, available only as pdf. Maybe, it can help a reviewer! I use a
recent &lt;a href="http://fredjiang.com/papers/MobiSys2013Auditeur.pdf"&gt;2013 Mobisys paper&lt;/a&gt; for illustration.&lt;/p&gt;
&lt;p&gt;Following are the required steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Convert pdf to text or HTML&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ pdftotext MobiSys2013Auditeur.pdf&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;or  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;pdftohtml MobiSys2013Auditeur.pdf  
&lt;span class="nv"&gt;$ &lt;/span&gt;lynx -dump MobiSys2013Auditeur.html &amp;gt;&amp;gt; MobiSys2013Auditeur.txt
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Remove non printable characters&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;perl -lpe s/[^[:print:]]+//g MobiSys2013Auditeur.txt &amp;gt;&amp;gt; clean.txt
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Now using Matt's scripts (located in the same folder) to find
    lexical illusions&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;perl dups clean.txt       
clean.txt:429 Space      
clean.txt:552 soundlet       
clean.txt:850 Mean       
clean.txt:1630 two
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This means that the following words have been used consecutively. Let us
analyze.&lt;br /&gt;
The "Space" repetition is shown by the script due to our "hacky" method
of getting text from pdf. In the paper, Private Space and Public Space
are used in a figure.&lt;br /&gt;
The other one is "soundlet". Now this happens to be a Java object
initialization: Soundlet soundlet and thus is perfectly fine.&lt;br /&gt;
"Mean" also occurs twice in a figure. Again it is due to our flawed
hack!&lt;br /&gt;
"two" occurs in the following sentence: "Vehicle Sense&lt;br /&gt;
and Kitchen Sense are trained on samples collected from members of two
two-person families, and are tested on them separately in 3-5 hours long
experiments."&lt;br /&gt;
So this is again not a lexical illusion. Good to go to finding weasel
words.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Checking weasel words&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;sh weasel clean.txt       
88:Beyond just &lt;span class="nb"&gt;time&lt;/span&gt;, many developers &lt;span class="k"&gt;do&lt;/span&gt; not have the necessary technical background to implement these functions correctly or efficiently. Because of this, there is a growing trend where smartphone         
94:Smartphones have begun to use their microphones &lt;span class="k"&gt;for&lt;/span&gt; various        
144:Several salient features when taken in combination make Auditeur unique. First, Auditeur provides a simple yet powerful API       
...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I have only captured the top few suggestions. Going through the
suggestions, it seems that the writing is OK and the usage of words like
"many", "several" is justified.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Checking incorrect passive voice usage&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- --&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;sh passive clean.txt
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Since the script suggested a lot of places where passive voice was used-
i just took a snapshot.&lt;/p&gt;
&lt;p&gt;There might be some scope of improvement. Overall, the paper is very
well written! Extracting text out of pdf might create some problems.&lt;br /&gt;
References&lt;br /&gt;
1. &lt;a href="http://matt.might.net/articles/shell-scripts-for-passive-voice-weasel-words-duplicates/"&gt;Matt Might's scripts&lt;/a&gt;&lt;br /&gt;
2. &lt;a href="http://skipperkongen.dk/2011/09/07/creating-a-word-cloud-from-pdf-documents/"&gt;Creating a wordle from pdf&lt;/a&gt;- Plan to use this soon for generating
my wordle!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sun, 11 Aug 2013 20:17:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-08-11:2013/08/revisiting-matt-mights-3-shell-scripts-to-improve-your-writing/</guid><category>latex</category></item><item><title>Trends in NILM research</title><link>http://nipunbatra.github.io/2013/08/trends-in-nilm-research/</link><description>&lt;p&gt;Hart originally presented his NILM work way back in 1992. Since then,
the field has grown enormously and is growing quicker with each passing
year. In this small post, i try to show how NILM research is trending.
My approach is simple. I see the citation count/year of Hart's original
paper (which i think would be cited by every work in this
domain).&lt;/p&gt;
&lt;p&gt;&lt;img alt="trends" src="http://nipunbatra.files.wordpress.com/2013/08/trends.png?w=660" /&gt;&lt;/p&gt;
&lt;p&gt;Since 2010, more than 50 papers per year are citing Hart's paper (which
in some sense approximates to trends in NILM and computational
sustainability). REDD dataset for NILM was released in 2011 and it is
clear why these numbers shoot up after that time. Curious to know why
2010 had a lot of work and what really triggered this change.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sun, 11 Aug 2013 10:41:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-08-11:2013/08/trends-in-nilm-research/</guid><category>Python</category><category>research</category></item><item><title>Information about versions of different Python packages</title><link>http://nipunbatra.github.io/2013/07/information-about-versions-of-different-python-packages/</link><description>&lt;p&gt;Many times questions on Stack Overflow are asked and immediately there
are comments asking about which version of the software the user is
using.&lt;br /&gt;
Following is a small set of lines, which one may use to know the
different versions of s/w. This covers most of the packages a computer
scientist needs.&lt;br /&gt;
It is also very useful to include the o/p of this program, before
distributing code. The users are well aware of all the dependencies and
the versions.&lt;br /&gt;
For instance if some code works on my system and fails on someone
else's it might be a case that they are using some other version of
Python, thus providing such details makes the code more "reproducible".&lt;br /&gt;
For instance 3/2 in Python 2.X is 1.5, whereas in Python 3.X it is 1.&lt;br /&gt;
Following is the small script and the corresponding output.&lt;/p&gt;
&lt;p&gt;[[ gist nipunreddevil:5956172 ]]&lt;/p&gt;
&lt;p&gt;[[ gist nipunreddevil:8951840 ]]&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Tue, 09 Jul 2013 15:26:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-07-09:2013/07/information-about-versions-of-different-python-packages/</guid><category>Python</category></item><item><title>Spell Checking in LaTeX</title><link>http://nipunbatra.github.io/2013/07/spell-checking-in-latex/</link><description>&lt;p&gt;Very often one needs to do a spell check in LaTeX. This can ofcourse be
done in some text editor. I use TeXStudio IDE in Ubuntu, but
unfortunately it's spell checker was not picking up mistakes. So shifted
to command line and used the &lt;strong&gt;aspell &lt;/strong&gt;utility. The utility has a CLI
and is very fast for editing! All one needs to do is to invoke&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;aspell -t -c name_of_tex.tex
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It can form a part of the LaTeX build workflow.&lt;/p&gt;
&lt;p&gt;References&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://tex.stackexchange.com/questions/42843/is-there-a-spell-check-package-for-latex"&gt;Stack exchange question&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://en.wikibooks.org/wiki/LaTeX/Tips_and_Tricks#Spell-checking_and_Word_Counting"&gt;Wiki LaTeX tips&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Mon, 08 Jul 2013 18:59:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-07-08:2013/07/spell-checking-in-latex/</guid><category>latex</category></item><item><title>Data Cleaning with sed, awk, grep...</title><link>http://nipunbatra.github.io/2013/06/data-cleaning-with-sed-awk-grep/</link><description>&lt;p&gt;Being mostly a Python user, loathed using awk, sed,.. and did not feel
comfortable with them. But after spending a few hours in cleaning a file
and trying to do so wihtout using lower level stuff like reading a file
and stuff, i resorted to shell tools. The data cleaning process is
required due to the fact that data is collected from sensors and a lot
of reasons may cause it to have more characters, lines merged etc.&lt;br /&gt;
Usually i collect data in CSV. Here is one such CSV whose head and tail
looks clean.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;head -n &lt;span class="m"&gt;4&lt;/span&gt; data.csv
1370500041.39,0
1370500041.59,0
1370500041.79,0
1370500041.99,0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So the characteristics of a correct line are that it should have a
delimiter (","), the portion before the delimiter is epoch time obtained
in Python and is in seconds, the portion after the comma should be a 0
or a 1.&lt;br /&gt;
While analysing data in Pandas i realized some of my lines had much
more characters than required. First lets count the number of lines in
the file. I used &lt;strong&gt;wc&lt;/strong&gt; for this.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;wc -l &amp;lt; data.csv 
3249743
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we find lines which have more than 15 characters. Will use awk for
this.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt; awk &lt;span class="s1"&gt;&amp;#39;length&amp;gt;15&amp;#39;&lt;/span&gt; data.csv 
13705051370503037.59,0
13706751370672237.1,0
1370744413.53,01370744236.88,0
1370752771370751437.64,0
137071370751438.98,0
137079701370794636.9,0
1370865773.91370863036.87,1
1370914473.69,1370913437.91,0
1371040575.321371039437.08,0
1371198314.1371197837.01,0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So quiet a lot of lines which would have created trouble while parsing.
Removing these and finding the number of lines in the new cleaned file.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; $ awk &amp;#39;length cleaned.csv
$ wc -l &amp;lt; cleaned.csv
3249733
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Only 10 lines were creating havoc in analysis. Just checking now if
there is a comma in every line. Or finding all those lines where "," is
not in the file.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;grep -vn &lt;span class="s2"&gt;&amp;quot;,&amp;quot;&lt;/span&gt; cleaned.csv
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;No output from this grep means that all the lines now contain a ","&lt;/p&gt;
&lt;p&gt;Much more stuff can be done. But for now this much suffices. Need to
learn a bit of shell stuff as well!&lt;br /&gt;
Python is not the universal solution!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sat, 15 Jun 2013 16:24:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-06-15:2013/06/data-cleaning-with-sed-awk-grep/</guid><category>Python</category><category>shell</category></item><item><title>Obtaining weather information and establishing relationship between temperature and humidity</title><link>http://nipunbatra.github.io/2013/06/obtaining-weather-information-and-establishing-relationship-between-temperature-and-humidity/</link><description>&lt;p&gt;&lt;a href="http://openweathermap.org/"&gt;OpenWeatherMap&lt;/a&gt; provides an excellent API to get near realtime
weather information, such as temperature, humidity etc. In this post i
shall get some historical information regarding temperature, humidity
and pressure using this API and do a Pearson correlation test between
temperature and pressure. From the geography books we remember that
higher the temperature lower the pressure and vice versa. Thus, the
correlation amongst these two should be tending towards -1.&lt;br /&gt;
The following are the three things plotted on the same x-axis.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="sample" src="http://nipunbatra.files.wordpress.com/2013/06/sample.png?w=660" /&gt; &lt;/p&gt;
&lt;p&gt;Here is the code used.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;#Plotting historical weather data from OPEN Weather API&lt;/span&gt;

&lt;span class="c"&gt;#Importing the APP ID&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;weather_password&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;APPID&lt;/span&gt;

&lt;span class="c"&gt;#City ID for Delhi&lt;/span&gt;
&lt;span class="n"&gt;CITY_ID&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1273294&lt;/span&gt;
&lt;span class="c"&gt;#How much history (Currently could get only 78 records)&lt;/span&gt;
&lt;span class="n"&gt;COUNT_RECORDS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;
&lt;span class="c"&gt;#Base URL&lt;/span&gt;
&lt;span class="n"&gt;BASE_URL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http://openweathermap.org/data/2.1/history/city/&amp;quot;&lt;/span&gt;
&lt;span class="c"&gt;#Custom HTTP request URL&lt;/span&gt;
&lt;span class="n"&gt;REQUEST_URL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;BASE_URL&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;?id=&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s"&gt;&amp;amp;cnt=&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s"&gt;&amp;amp;APPID=&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;CITY_ID&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;COUNT_RECORDS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;APPID&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.dates&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;mdates&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;datetime&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;scipy.stats&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;st&lt;/span&gt;

&lt;span class="c"&gt;#Getting historical data&lt;/span&gt;
&lt;span class="n"&gt;json_data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;REQUEST_URL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;num_records&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;json_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;cnt&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Response received from server containing &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s"&gt; records&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_records&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;list_of_records&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;json_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;list&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c"&gt;#Pushing humidity, pressure, temperature and timestamp&lt;/span&gt;
&lt;span class="n"&gt;humidity&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;num_records&lt;/span&gt;
&lt;span class="n"&gt;pressure&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;num_records&lt;/span&gt;
&lt;span class="n"&gt;temperature&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;num_records&lt;/span&gt;
&lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;num_records&lt;/span&gt;
&lt;span class="n"&gt;dates&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;num_records&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_records&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;humidity&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;list_of_records&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;main&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;humidity&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;pressure&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;list_of_records&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;main&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;pressure&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;temperature&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;list_of_records&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;main&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;temp&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;273.15&lt;/span&gt;
    &lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;list_of_records&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dt&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;dates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fromtimestamp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="c"&gt;#Pearson correlation between temperature and pressure&lt;/span&gt;
&lt;span class="n"&gt;r_correlation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;st&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pearsonr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pressure&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;temperature&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Correlation b/w temperature and pressure is &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;r_correlation&lt;/span&gt;

&lt;span class="c"&gt;#Plotting on 3 subplots and sharing the same x axis to ensure we can equally zoom into all&lt;/span&gt;
&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;ax1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;311&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;312&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sharex&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;313&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sharex&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dates&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;humidity&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;g+-&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xaxis&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_major_formatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mdates&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DateFormatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;%H hrs &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s"&gt;-%m&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Humidity (%)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;ax2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dates&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;pressure&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;ro-&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xaxis&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_major_formatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mdates&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DateFormatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;%H hrs &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s"&gt;-%m&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;ax2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Pressure (hPa)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;ax3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dates&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;temperature&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;b*-&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xaxis&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_major_formatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mdates&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DateFormatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;%H hrs &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s"&gt;-%m&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;ax3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Temperature (Cel)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tight_layout&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The correlation results obtained are as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; ----------------------------- -----------------
Correlation variables (X,Y)   Correlation (r)
Pressure, Temperature         -0.75
Humidity, Temperature         -0.85
----------------------------- -----------------
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Thus, from the table we can see that temperature and humidity and
temperature and pressure are inversely correlated to a high degree.&lt;/p&gt;
&lt;p&gt;Caveats:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is my first test with Pearson correlation and i am may be wrong
    in my understanding&lt;/li&gt;
&lt;li&gt;Scipy.Stats states that for a good test, the variables must be
    normally distributed and sample size should be 500 plus, which is
    not a case in our analysis.&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Fri, 14 Jun 2013 12:29:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-06-14:2013/06/obtaining-weather-information-and-establishing-relationship-between-temperature-and-humidity/</guid><category>Python</category></item><item><title>Book Review: NumPy Beginner's Guide Second Edition</title><link>http://nipunbatra.github.io/2013/06/book-review-numpy-beginners-guide-second-edition/</link><description>&lt;p&gt;I got an opportunity to review &lt;a href="http://www.packtpub.com/numpy-mathematical-2e-beginners-guide/book"&gt;NumPy Beginner's Guide Second
Edition&lt;/a&gt;. Since i do most of my scientific analysis in Python, having
a stronger grip on NumPy is very essential. This is also very important
since almost all of Data analysis toolkits in Python leverage NumPy very
heavily. Here are the reviews:&lt;/p&gt;
&lt;h4&gt;Chapter 1&lt;/h4&gt;
&lt;p&gt;Talks about installing and other stuff. For someone who has been using
Python and its scientific packages for some time now, most of the stuff
can be ommitted. However, for new comers it may be very helpful to see
how to use the executables, installing from source and different
techniques mentioned here. It pretty early introduces IPython which is
important.&lt;/p&gt;
&lt;!--more--&gt;

&lt;h4&gt;Chapter 2&lt;/h4&gt;
&lt;p&gt;Starts with a gentle introduction to ndarray. The pop quiz about how
size of an array is stored is important as it tells the user how to deal
with it when performing operations based on size. Something new which i
learnt was that we can specify the dtype even with arange function. This
might be very handy when we know beforehand the maximum number expected.
The introduction to record data type is very helpful and again something
which i was not very confident about earlier.&lt;br /&gt;
The section on indexing and slicing is very well explained and the
analogy of room makes it much more accessible even to new audience.&lt;br /&gt;
The section on manipulating array shapes is good, but i feel it is not
highligting well enough if these methods are in place or not. This can
avoid a lot of commonly occuring confusions.&lt;br /&gt;
Felt that the section on stacking could be improved by explaining more
about depth stacking and in general usage from real world examples could
make the understanding more concrete.&lt;br /&gt;
A newcomer might be unhappy that he doesn't get to play with the code
snippets in IPython notebook. That would surely have been very helpful.&lt;/p&gt;
&lt;h4&gt;Chapter 3&lt;/h4&gt;
&lt;p&gt;For some reason the code in the beginning of this #### Chapter is not run in
IPython. Something which may be worked upon in the future releases. For
instances, after saving the csv to disk, a simple !cat file.csv would
have shown that the write was successful. The section on CSV introduces
the stock price data, which is a very good dataset to illustrate the
concepts, but the source of the dataset and how to obtain it is not
mentioned. Might be useful to include the same in future release. Using
the unpack parameter in reading CSV is something which i hadn't used
before and is definitely a value addition. Earlier i used to read stuff
into bag arrays and then index them to get specific columns. When the
sorting example is provided msort is being used. Again it shows that how
many NumPy tricks are hidden. The example on stock returns though shows
a good use of NumPy's methods, but looks a little inaccessible to me
without plots.&lt;br /&gt;
I liked the example on dealing with dates. One reason why i found it
very useful is that since i use Pandas a lot, which builds on top of
NumPy and has similar functions, so getting to understand how they
happen at NumPy level is useful. The function apply_along_axis is
another important function about which i did not know before and find it
to be very useful. The exmaple on using linalg is very helpful, although
an accompanying plot would have been more illustrative. The factorial
example to illustare cumprod() is about the best which can come to mind.&lt;/p&gt;
&lt;h4&gt;Chapter 4&lt;/h4&gt;
&lt;h4&gt;Chapter 4 begins with a good example of estimating correlation between&lt;/h4&gt;
&lt;p&gt;two companies' stock prices. Since i play with time series a lot, this
example looks helpful and even clears some statistical concepts. The
second example on polynomial fitting reminds of the days when i used to
fiddle around with Matlab GUI doing curve fitting. The same thing can be
done very easily using NumPy. The third example illustrates the use of
sign() which again i feel would be very useful for stuff like SVM and
Neural Nets. The section on Vectorizing is important and can be expanded
more to include more examples.&lt;/p&gt;
&lt;h4&gt;Chapter 5&lt;/h4&gt;
&lt;p&gt;Golden Ratios example to illustrate the concept of matrices is actually
very good. Revisited Lissajous curves after a long time, alas the
example wasn't descriptive enough! It was an interesting bend to study
about square wave generation. Maybe something on lines of animating it
would have been much cooler! The methods for bit manipulation are
helpful in illustrating how functions are broadcasted.&lt;/p&gt;
&lt;h4&gt;Chapter 6&lt;/h4&gt;
&lt;p&gt;Solving linear systems is easy in NumPy. I thought that i would have to
resort to some specialized libraries for the same. The definition of
eigen values is goofed up, maybe something which should be corrected in
next release. Now SVD techniques are useful, but without a motivating
example it may get difficult to grasp such concepts. Was a pleasant
surprise to read about FFT in the book. But felt that this topic could
either have been ommitted or described in more details. Distributions
and their handling was a warm welcome.&lt;/p&gt;
&lt;h4&gt;Chapter 7&lt;/h4&gt;
&lt;p&gt;Saw the &gt;&gt;&gt; prompt. Maybe for sake of consistency, only IPython
should be used. A very good use case of search sorted is presented,
talking about inserting after seeing correct position. Extract function
was another new function which i saw and found very useful. Would have
been interesting if the author drew parallels with smart indexing and
where method. I decided to give the remaining #### Chapter a skip, since i
didn't see immediate benefits in my data analysis.&lt;/p&gt;
&lt;h4&gt;Chapter 8&lt;/h4&gt;
&lt;p&gt;This #### Chapter seems to be very important especially while writing large
functions where manual inspection may not be possible. Also very
importantly the #### Chapter talks about how floating point arithmetic won't
be exact. The small example explaining TDD is very helpful and useful
for people willing to contribute to open source projects.&lt;/p&gt;
&lt;h4&gt;Chapter 9&lt;/h4&gt;
&lt;p&gt;I feel the #### Chapter came in a little late. I would have liked a little
more description about the different components-axis, figure, canvas
etc. The scatter plot example is very interesting and helpful. Having
used fill_between before i can only recommend that it be included in a
lot of books. Thankfully this books shows a clear descriptive example.
Surprisingly for me the annotations plot in the book does not show
annotations! Come 3D plotting.&lt;br /&gt;
The image talking about the function of z in terms of x and y is
blurred and would best be replaced in forthcoming issues.&lt;/p&gt;
&lt;h4&gt;Chapter 10&lt;/h4&gt;
&lt;p&gt;The #### Chapter starts on a good note, showing that in a practical world,
one may need to look beyond NumPy and need to see how to integrate the
outside world with it. Apart from learning NumPy, i also learnt a bit of
stats along the way. For instance the KS test was useful to learn about.
There are some examples from different domains. Just had a quick look.
Would get back when needed.&lt;/p&gt;
&lt;h4&gt;Chapter 11&lt;/h4&gt;
&lt;p&gt;I am not fully convinced about using PyGame. Had used it a few years
back for Graphics course, but there are serious contenders out there.
The example from scikit-learn was interesting. Maybe pointing to SVM GUI
example from scikit-learn would have been a good choice as well.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Tue, 11 Jun 2013 17:15:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-06-11:2013/06/book-review-numpy-beginners-guide-second-edition/</guid></item><item><title>LaTeX and annoying errors</title><link>http://nipunbatra.github.io/2013/06/latex-and-annoying-errors/</link><description>&lt;p&gt;While starting afresh on an IEEE template got the following error:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;! Latex Error: Something&amp;#39;s wrong--perhaps a missing \item
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
Needless to say, debugging these is not easy.  
Cause: Had not made a single call to

    cite

Doing that sufficed!</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Tue, 11 Jun 2013 12:24:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-06-11:2013/06/latex-and-annoying-errors/</guid><category>latex</category></item><item><title>Dynamic Time Warping using rpy and Python</title><link>http://nipunbatra.github.io/2013/06/dynamic-time-warping-using-rpy-and-python/</link><description>&lt;p&gt;Dynamic Time Warping is a technique used for measuring similarity
between sequences. Since i deal mostly with time series data which is
essentially sequential, i had been told to give DTW a try. There are
numerous implementations of DTW, but i found the implementation in R to
be most complete. Since it has been a long time since i last used R
seriously and since i do most of my work in Python, i chose to use rpy2,
which is a bridge between R and Python. R has a lot of open source well
implemented code and rpy2 allows to leverage that while maintaining the
comfort of Python.&lt;br /&gt;
In this post i download financial stock data from Yahoo finance and
leverage Pandas' libraries for the same. I also present results
comparing the implementation in R and in Python (mlpy).&lt;/p&gt;
&lt;p&gt;Loading the data&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pandas.io.data&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DataReader&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;datetime&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;goog&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DataReader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;GOOG&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="s"&gt;&amp;quot;yahoo&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;goog&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;

&lt;span class="n"&gt;DatetimeIndex&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1857&lt;/span&gt; &lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2004&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;08&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt; &lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="mi"&gt;2011&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt; &lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;
&lt;span class="n"&gt;Data&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="n"&gt;Open&lt;/span&gt;         &lt;span class="mi"&gt;1857&lt;/span&gt;  &lt;span class="n"&gt;non&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt;
&lt;span class="n"&gt;High&lt;/span&gt;         &lt;span class="mi"&gt;1857&lt;/span&gt;  &lt;span class="n"&gt;non&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt;
&lt;span class="n"&gt;Low&lt;/span&gt;          &lt;span class="mi"&gt;1857&lt;/span&gt;  &lt;span class="n"&gt;non&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt;
&lt;span class="n"&gt;Close&lt;/span&gt;        &lt;span class="mi"&gt;1857&lt;/span&gt;  &lt;span class="n"&gt;non&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt;
&lt;span class="n"&gt;Volume&lt;/span&gt;       &lt;span class="mi"&gt;1857&lt;/span&gt;  &lt;span class="n"&gt;non&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt;
&lt;span class="n"&gt;Adj&lt;/span&gt; &lt;span class="n"&gt;Close&lt;/span&gt;    &lt;span class="mi"&gt;1857&lt;/span&gt;  &lt;span class="n"&gt;non&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt;
&lt;span class="n"&gt;dtypes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;float64&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Separating out data for the years 2008 and 2009 in different dataframes.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [8]: goog_2008=goog[goog.index.year==2008]
In [9]: goog_2009=goog[goog.index.year==2009]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Plotting the "Volume" field of the two dataframes&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;n [79]: goog_2008.Volume.plot(title=&amp;quot;2008 Volume&amp;quot;)
Out[79]: 
In [80]: goog_2009.Volume.plot(title=&amp;quot;2009 Volume&amp;quot;)
Out[80]:
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here is how the data looks like&lt;br /&gt;
&lt;img alt="2008_title" src="http://nipunbatra.files.wordpress.com/2013/06/2008_title.png?w=300" /&gt; 
&lt;img alt="2009_title" src="http://nipunbatra.files.wordpress.com/2013/06/2009_title.png?w=300" /&gt;&lt;/p&gt;
&lt;p&gt;Importing stuff to make R work from within Python&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;rpy2.robjects.numpy2ri&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;rpy2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;robjects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numpy2ri&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;activate&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;rpy2.robjects.packages&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;importr&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;rpy2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;robjects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;DTW&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;importr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;dtw&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Computing the alignment of the two sequences&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [17]: alignment = R.dtw(goog_2008.Volume.values, goog_2009.Volume.values, keep=True)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Plotting the `twoway` and `threeway` type plot for the alignment
obtained.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [20]: R.plot(alignment,type=&amp;quot;twoway&amp;quot;);
In [21]: R.plot(alignment,type=&amp;quot;threeway&amp;quot;);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="2way" src="http://nipunbatra.files.wordpress.com/2013/06/2way.png?w=285" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="3way" src="http://nipunbatra.files.wordpress.com/2013/06/3way.png?w=287" /&gt;&lt;/p&gt;
&lt;p&gt;Finding the distance between the two time series&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [21]: dist = alignment.rx(&amp;#39;distance&amp;#39;)[0][0]
In [22]: dist
Out[22]: 417765600.0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now, we try and do the same analysis using MlPy's DTW implementation.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;mlpy&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;26&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.cm&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;cm&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;27&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;dist&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cost&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mlpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dtw_std&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;goog_2008&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Volume&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;goog_2009&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Volume&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dist_only&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="n"&gt;dist&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="mf"&gt;377532600.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For some reason the distance obtained using the two implementation is
not the same. Next, we aim to draw the warped path.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [29]: fig = plt.figure(1)
In [30]: ax = fig.add_subplot(111
In [31]: plot1 = plt.imshow(cost.T, origin=&amp;#39;lower&amp;#39;, cmap=cm.gray, interpolation=&amp;#39;nearest&amp;#39;)
In [32]: plot2 = plt.plot(path[0], path[1], &amp;#39;w&amp;#39;)
In [33]: xlim = ax.set_xlim((-0.5, cost.shape[0]-0.5))
In [34]: ylim = ax.set_ylim((-0.5, cost.shape[1]-0.5))
In [35]: plt.draw()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="dtw_mlpy" src="http://nipunbatra.files.wordpress.com/2013/06/dtw_mlpy.png?w=300" /&gt;&lt;/p&gt;
&lt;p&gt;Both the alignment diagrams look very similar, which is as expected.&lt;br /&gt;
This is probably all that can be easily done using mlpy, since the
documentation is only a single page. Whereas R's DTW package is a lot
more feature and documentation rich.&lt;br /&gt;
For example, we first plot the cost density plot. Again this can be
plotted using Matplotlib, but having the convenience of a method to do
it for you looks better!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [37]: R.plot(alignment,type=&amp;quot;density&amp;quot;);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="cost_density" src="http://nipunbatra.files.wordpress.com/2013/06/cost_density.png?w=287" /&gt;&lt;/p&gt;
&lt;p&gt;Also, now we can use "DTW" as similarity metric for computing distance
matrices. We can further use this distance matrix to perform clustering.
HClust inherently supports distance matrices.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [39]: distMatrix =R.dist(goog_2009.values, method=&amp;quot;DTW&amp;quot;)
In [40]: distMatrix
Out[40]:

[2557065.470000, 5629523.270000, 1768054.390000, ..., 81622.300000, 410006.360000, 491625.100000]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Performing hclust&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [42]: hc =R.hclust(distMatrix, method=&amp;quot;average&amp;quot;)
In [43]: R.plot(hc)
Out[43]: rpy2.rinterface.NULL
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The Dendogram produced was way too shabby to be included in this post,
so ommitted it.&lt;br /&gt;
Takeaway:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;R's DTW package has a lot more features and is well documented&lt;/li&gt;
&lt;li&gt;It has inbuilt plotting features which make the plots intuitive&lt;/li&gt;
&lt;li&gt;R can allow you to use DTW as a distance metric, which means it can
    be used in clustering approaches. This is on current action list&lt;/li&gt;
&lt;li&gt;For  initial analysis, mlpy might also be very good&lt;/li&gt;
&lt;li&gt;rpy2 is easy to use and really extends data mining in Python&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What would be good to have&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If Pandas would allow these operations natively on DataFrame
    objects. So we could easily play with more than 1 dimension. R code
    is GPL and has a significant chunk written in C. Not sure if that
    can be directly used in Python&lt;/li&gt;
&lt;li&gt;Ability to use different distance metrics in different clustering
    implementations&lt;/li&gt;
&lt;li&gt;More open source code from research community. Some publications do
    talk about DTW and finance and clustering, but absence of code ,
    makes it hard to reproduce the results&lt;/li&gt;
&lt;li&gt;More Pandas documentation on fiddling with rpy2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;References&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;http://rdatamining.wordpress.com/2011/08/23/time-series-analysis-and-mining-with-r/&lt;/li&gt;
&lt;li&gt;http://stackoverflow.com/questions/5695388/dynamic-time-warping-in-python&lt;/li&gt;
&lt;li&gt;http://data-matters.blogspot.in/2008/07/simple-implementation-of-dtwdynamic.html&lt;/li&gt;
&lt;li&gt;http://mlpy.sourceforge.net/docs/3.4/dtw.html&lt;/li&gt;
&lt;li&gt;https://en.wikipedia.org/wiki/Dynamic_time_warping&lt;/li&gt;
&lt;li&gt;https://github.com/pydata/pandas/issues/3810&lt;/li&gt;
&lt;li&gt;http://www.jstatsoft.org/v31/i07/paper&lt;/li&gt;
&lt;li&gt;http://stat.ethz.ch/R-manual/R-patched/library/stats/html/hclust.html&lt;/li&gt;
&lt;li&gt;http://pandas.pydata.org/pandas-docs/dev/io.html&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Caveat: I am pretty new to DTW and my analysis might be highly flawed.
Also the dataset used is only for demo purposes and may not be a good
one to illustrate the concept. A better dataset may be ECG data or some
of the applications mentioned in [7]&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sun, 09 Jun 2013 12:44:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-06-09:2013/06/dynamic-time-warping-using-rpy-and-python/</guid><category>Python</category><category>R</category></item><item><title>Pandas: Reading CSV with Unix timestamps and converting to local timezone</title><link>http://nipunbatra.github.io/2013/06/pandas-reading-csv-with-unix-timestamps-and-converting-to-local-timezone/</link><description>&lt;p&gt;In this post we shall learn how to use pandas to analyse timeseries CSV
data with epoch based timestamps. Epoch timestamp represent the number
of seconds since Jan 1, 1970 and are commonly used for data recording in
many scientific applications. Unix command date can be used to give the
current time and we can also extract the current epoch timestamp as
follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="sx"&gt;!date&lt;/span&gt;

&lt;span class="n"&gt;Thu&lt;/span&gt; &lt;span class="n"&gt;Jun&lt;/span&gt;  &lt;span class="mi"&gt;6&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;01&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="n"&gt;IST&lt;/span&gt; &lt;span class="mi"&gt;2013&lt;/span&gt;

&lt;span class="sx"&gt;!date +%s&lt;/span&gt;

&lt;span class="mi"&gt;1370489477&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We now create a dummy dataset using pandas containing 10 rows and 2
columns and save it locally as a CSV.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__version__&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nn"&gt;time&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DataFrame&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="mf"&gt;0.11&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;

&lt;span class="n"&gt;start_time&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;start_time&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;column_1&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;column_2&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;timestamp&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;column_1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;column_1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;column_2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;column_2&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;

    &lt;span class="n"&gt;column_1&lt;/span&gt;    &lt;span class="n"&gt;column_2&lt;/span&gt;    &lt;span class="n"&gt;timestamp&lt;/span&gt;
&lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mf"&gt;0.620274&lt;/span&gt;    &lt;span class="mf"&gt;0.720347&lt;/span&gt;    &lt;span class="mi"&gt;1370489479&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mf"&gt;0.603379&lt;/span&gt;    &lt;span class="mf"&gt;0.214927&lt;/span&gt;    &lt;span class="mi"&gt;1370489480&lt;/span&gt;
&lt;span class="mi"&gt;2&lt;/span&gt;   &lt;span class="mf"&gt;0.508877&lt;/span&gt;    &lt;span class="mf"&gt;0.562860&lt;/span&gt;    &lt;span class="mi"&gt;1370489481&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mf"&gt;0.236682&lt;/span&gt;    &lt;span class="mf"&gt;0.062259&lt;/span&gt;    &lt;span class="mi"&gt;1370489482&lt;/span&gt;
&lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mf"&gt;0.923264&lt;/span&gt;    &lt;span class="mf"&gt;0.278048&lt;/span&gt;    &lt;span class="mi"&gt;1370489483&lt;/span&gt;
&lt;span class="mi"&gt;5&lt;/span&gt;   &lt;span class="mf"&gt;0.105673&lt;/span&gt;    &lt;span class="mf"&gt;0.246425&lt;/span&gt;    &lt;span class="mi"&gt;1370489484&lt;/span&gt;
&lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mf"&gt;0.204324&lt;/span&gt;    &lt;span class="mf"&gt;0.770854&lt;/span&gt;    &lt;span class="mi"&gt;1370489485&lt;/span&gt;
&lt;span class="mi"&gt;7&lt;/span&gt;   &lt;span class="mf"&gt;0.206739&lt;/span&gt;    &lt;span class="mf"&gt;0.702672&lt;/span&gt;    &lt;span class="mi"&gt;1370489486&lt;/span&gt;
&lt;span class="mi"&gt;8&lt;/span&gt;   &lt;span class="mf"&gt;0.180858&lt;/span&gt;    &lt;span class="mf"&gt;0.440023&lt;/span&gt;    &lt;span class="mi"&gt;1370489487&lt;/span&gt;
&lt;span class="mi"&gt;9&lt;/span&gt;   &lt;span class="mf"&gt;0.269232&lt;/span&gt;    &lt;span class="mf"&gt;0.684387&lt;/span&gt;    &lt;span class="mi"&gt;1370489488&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Saving the dataframe into a CSV file.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;df.to_csv(&amp;#39;epoch_demo.csv&amp;#39;,index=False)
!cat epoch_demo.csv

column_1,column_2,timestamp
0.6202741436145147,0.7203473783163402,1370489479
0.603378652829255,0.2149274411077019,1370489480
0.5088772165417312,0.5628600230105181,1370489481
0.23668184075365228,0.062259281774838415,1370489482
0.923263574664376,0.27804805708797475,1370489483
0.10567266566500166,0.24642510043158228,1370489484
0.20432401714102266,0.7708544521037892,1370489485
0.20673911644596843,0.7026719669208518,1370489486
0.1808583958327319,0.4400233442122533,1370489487
0.2692318429010231,0.684387368168343,1370489488


df_2=pd.read_csv(&amp;#39;epoch_demo.csv&amp;#39;,index_col=2)
df_2

    column_1    column_2
timestamp       
1370489479  0.620274    0.720347
1370489480  0.603379    0.214927
1370489481  0.508877    0.562860
1370489482  0.236682    0.062259
1370489483  0.923264    0.278048
1370489484  0.105673    0.246425
1370489485  0.204324    0.770854
1370489486  0.206739    0.702672
1370489487  0.180858    0.440023
1370489488  0.269232    0.684387
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can notice that currently the index is of integer type. To convert it
into DateTime type we use to_datetime() function, which accepts time in
nanoseconds.&lt;br /&gt;
1 second=10\^9 nanoseconds&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;df_2.index=pd.to_datetime((df_2.index.values*1e9).astype(int))
df_2

    column_1    column_2
2013-06-06 03:31:19     0.620274    0.720347
2013-06-06 03:31:20     0.603379    0.214927
2013-06-06 03:31:21     0.508877    0.562860
2013-06-06 03:31:22     0.236682    0.062259
2013-06-06 03:31:23     0.923264    0.278048
2013-06-06 03:31:24     0.105673    0.246425
2013-06-06 03:31:25     0.204324    0.770854
2013-06-06 03:31:26     0.206739    0.702672
2013-06-06 03:31:27     0.180858    0.440023
2013-06-06 03:31:28     0.269232    0.684387

df_2.index


[2013-06-06 03:31:19, ..., 2013-06-06 03:31:28]
Length: 10, Freq: None, Timezone: None
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;However, now we can see that the time is lagging the current local time
and the index does not yet have an associated timezone. Thus, we first
put the index in UTC to associate a timezone and then localize with our
timezone (Asia/Kolkata) in our case.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;df_2.index=df_2.index.tz_localize(&amp;#39;UTC&amp;#39;).tz_convert(&amp;#39;Asia/Kolkata&amp;#39;)
df_2

                                 column_1   column_2
2013-06-06 09:01:19+05:30   0.620274    0.720347
2013-06-06 09:01:20+05:30   0.603379    0.214927
2013-06-06 09:01:21+05:30   0.508877    0.562860
2013-06-06 09:01:22+05:30   0.236682    0.062259
2013-06-06 09:01:23+05:30   0.923264    0.278048
2013-06-06 09:01:24+05:30   0.105673    0.246425
2013-06-06 09:01:25+05:30   0.204324    0.770854
2013-06-06 09:01:26+05:30   0.206739    0.702672
2013-06-06 09:01:27+05:30   0.180858    0.440023
2013-06-06 09:01:28+05:30   0.269232    0.684387

df_2.index


[2013-06-06 09:01:19, ..., 2013-06-06 09:01:28]
Length: 10, Freq: None, Timezone: Asia/Kolkata
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So, we are done finally. Read the CSV and converted the datetime index
into our local timezone.&lt;/p&gt;
&lt;p&gt;References&lt;br /&gt;
https://github.com/pydata/pandas/issues/3757&lt;br /&gt;
https://github.com/pydata/pandas/issues/3746&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Fri, 07 Jun 2013 07:51:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-06-07:2013/06/pandas-reading-csv-with-unix-timestamps-and-converting-to-local-timezone/</guid><category>Python</category></item><item><title>Reading 'unclean' data CSV using Pandas</title><link>http://nipunbatra.github.io/2013/06/reading-unclean-data-csv-using-pandas/</link><description>&lt;p&gt;If you collect sensor data, you would know it comes with varieties of
noise, unclean stuff, different data types, strings interspersed with
numbers, missing data and so on!&lt;br /&gt;
I encountered something similar while working on a real world problem.
So here i illustrate using a toy example on how to do the same using
Pandas. I use IPython shell throughout.&lt;/p&gt;
&lt;p&gt;Customary Pandas import&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__version__&lt;/span&gt;
&lt;span class="mf"&gt;0.11&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here is how our unclean CSV looks. Note that the last row in the first
column, there is a string, whereas there should only be numeric data.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [2]: !cat test_bad.csv
a,b
1.1,3.1
3.4,4,5
5.6,6.2
c3,7.2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For reading the CSV,we need to add &lt;code&gt;error_bad_lines= True&lt;/code&gt;, since we
wish bad lines to be ignored and CSV still be read.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [4]: df=pd.read_csv(&amp;#39;test_bad.csv&amp;#39;,error_bad_lines=False)
Skipping line 3: expected 2 fields, saw 3
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We now wish to see the data and type corresponding to 'a' column.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [7]: df.a
Out[7]: 
0    1.1
1    5.6
2     c3
Name: a, dtype: object
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Pandas automatically assigned &lt;code&gt;object&lt;/code&gt; as the most valid datatype for
the series! Now, we don't want that. So, in the next step we tell it
explicitly use numeric type for this series.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [8]: df.a=df.a.convert_objects(convert_numeric=True)

In [9]: df.a
Out[9]: 
0    1.1
1    5.6
2    NaN
Name: a, dtype: float64
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Much better! Now we can use the series and do all our maths on it!&lt;br /&gt;
Ok, what if we knew beforehand that the whole dataframe should be
numeric. To our rescue, the DataFrame also like Series. Here is the code
for the same.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;In [12]: df=df.convert_objects(convert_numeric=True)

In [13]: df
Out[13]: 
     a    b
0  1.1  3.1
1  5.6  6.2
2  NaN  7.2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;References&lt;br /&gt;
https://github.com/pydata/pandas/issues/3761&lt;/p&gt;
&lt;p&gt;Special thanks to https://github.com/jreback for helping with this
trick.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Thu, 06 Jun 2013 22:45:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-06-06:2013/06/reading-unclean-data-csv-using-pandas/</guid><category>Python</category></item><item><title>Storing Laptop CPU and Memory Usage in Tempo-DB</title><link>http://nipunbatra.github.io/2013/05/storing-laptop-cpu-and-memory-usage-in-tempo-db/</link><description>&lt;p&gt;Very often i deal with timeseries data and end up storing collected data
in MySQL. I have also used MongoDB a lot. This time decided to give
&lt;a href="https://tempo-db.com/"&gt;Tempo-DB&lt;/a&gt; which is a timeseries database a try. The API is fairly
simple to use and within a couple of minutes one can publish data and
also visualize it with some basic statistics. The caveat is that the DB
is hosted on the cloud and available as a service over the internet. So
if you want to push some timeseries data real quick and visualize it,
Tempo-DB looks promising. In this post, i shall be pushing my CPU
percentage usage and free RAM (MB) to the DB i created. The code
follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nn"&gt;psutil&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nn"&gt;time&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nn"&gt;pytz&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tempodb&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Client&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;DataPoint&lt;/span&gt;

&lt;span class="c"&gt;# Modify these with your credentials found at: http://tempo-db.com/manage/&lt;/span&gt;
&lt;span class="n"&gt;API_KEY&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;*************************&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;API_SECRET&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;**************************&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;TEMP_DATA&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;CPU Temperature&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;RAM_DATA&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Available RAM&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Client&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;API_KEY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;API_SECRET&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;now&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pytz&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timezone&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Asia/Kolkata&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write_key&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TEMP_DATA&lt;/span&gt;&lt;span class="p"&gt;,[&lt;/span&gt;&lt;span class="n"&gt;DataPoint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;psutil&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cpu_percent&lt;/span&gt;&lt;span class="p"&gt;())])&lt;/span&gt;
    &lt;span class="n"&gt;client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write_key&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;RAM_DATA&lt;/span&gt;&lt;span class="p"&gt;,[&lt;/span&gt;&lt;span class="n"&gt;DataPoint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;psutil&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;avail_phymem&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;1000000&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
    &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So within few LOC you can be up and running. The following screenshot
shows visualization for free RAM on my system.&lt;/p&gt;
&lt;p&gt;&lt;img alt="tempo" src="http://nipunbatra.files.wordpress.com/2013/05/tempo.png?w=660" /&gt;&lt;/p&gt;
&lt;p&gt;While i have not given querying a try, on initial looks Tempo-DB looks
promising. The &lt;a href="https://tempo-db.com/features/"&gt;Features&lt;/a&gt; page on their site also mentions that query
time is independent of DB size and only dependent on the query size!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Fri, 17 May 2013 19:49:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-05-17:2013/05/storing-laptop-cpu-and-memory-usage-in-tempo-db/</guid><category>Python</category></item><item><title>Prettifying Matplotlib plots</title><link>http://nipunbatra.github.io/2013/05/prettifying-matplotlib-plots/</link><description>&lt;p&gt;I thought that by default Matplotlib plots look great. Not until i saw
the visualization &lt;a href="http://pandas.pydata.org/pandas-docs/stable/visualization.html"&gt;page&lt;/a&gt; on Pandas website and the plots in 
&lt;a href="http://nbviewer.ipython.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter1_Introduction/Chapter1_Introduction.ipynb"&gt;Probabilistic Programming and Bayesian Methods for Hackers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I tried using the Matplotlib rc parameters used in the Probabilstic
Programming book.  The following code is used to illustrate the
difference.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Drawing plot with default rc parameters.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;x=np.arange(100)
y=x*x
z=x*x+10*x
plt.plot(x,y,label=&amp;#39;Y=x*x&amp;#39;);
plt.plot(x,z,label=&amp;#39;Y=x*x+10*x&amp;#39;);
plt.title(&amp;#39;Before&amp;#39;);
plt.legend();
plt.plot();
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now opening the &lt;strong&gt;rc&lt;/strong&gt; file and updating the rc parameters to be used
for the next plot.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;
&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;https://raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/styles/bmh_matplotlibrc.json&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;matplotlib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rcParams&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finally drawing the plot again with updated rc values. The difference is
vast and for the good. I would like to thank the original author who
posted this rc file. You can see the different properties we changed in
the rc file &lt;a href="https://raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/styles/bmh_matplotlibrc.json"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nipunbatra.files.wordpress.com/2013/05/prettify_matplotlib_fig_00.png" alt="[before]" title="[before]"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nipunbatra.files.wordpress.com/2013/05/prettify_matplotlib_fig_01.png" alt="[after]" title="[after]"&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sun, 12 May 2013 15:32:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-05-12:2013/05/prettifying-matplotlib-plots/</guid><category>Python</category></item><item><title>Simulating a Discrete Hidden Markov Model</title><link>http://nipunbatra.github.io/2013/05/simulating-a-discrete-hidden-markov-model/</link><description>&lt;p&gt;In this post we shall create a Hidden Markov Model [1] for the Unfair
Casino problem [2]. In short the problem is as follows: In a casino
there may be two die- one fair and the other biased. The biased die is
much more likely to produce a 6 than the other numbers. With the fair
die all the outcomes (1 through 6) are equally likely. For the biased
die, probability of observing a 6 is 0.5 and observing 1,2,3,4,5 is 0.1
each. Also, there are probabilies associated with the choice of a die to
be thrown. The observer is only able to observe the values of die being
thrown, without having a knowldge whether a fair or biased die were
used.&lt;/p&gt;
&lt;p&gt;In all it matches the description of a discrete Hidden Markov Model. The
different components of the Discrete HMM are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Observed States&lt;/strong&gt; : 1 through 6 on the die faces&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hidden States&lt;/strong&gt; : Fair or Biased Die&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prior (pi)&lt;/strong&gt; : Probability that the first throw is made from a
    fair or a biased die, which is : Pr (first throw is fair) and Pr
    (first throw is biased), which is represented as a 1 X 2 row matrix&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transition Matrix (A)&lt;/strong&gt;: Matrix encoding the probability of the 4
    possible transition between fair and biased die, which are: Fair-&gt;
    Fair, Fair-&gt; Biased, Biased-&gt; Fair and Biased-&gt;Biased, which is
    represented as a 2 X 2 matrix&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Emission Matrix (B)&lt;/strong&gt; : Matrix encoding the probability of an
    observation given the hidden state. It is a 2 X 6 Matrix&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Next, we import the basic set of libraries used for matrix manipulation
and for plotting.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt;
&lt;span class="c"&gt;#Setting Font Size as 20&lt;/span&gt;
&lt;span class="n"&gt;matplotlib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rcParams&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;font.size&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, we define the different components of HMM which were described
above.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&amp;#39;&amp;#39;&amp;#39;
Pi : Fair die is twice as likely as biased die

A  : The die thrower likes to keep in one state (fair/biased), and the tranisition from 
1. Fair-&amp;gt; Fair : .95
2. Fair-&amp;gt;Biased: 1-.95=.05
3. Biased-&amp;gt;Biased: .90
4. Biased-&amp;gt;Biased=1-.90=.10

B  : The fair die is equally likely to produce observations 1 through 6, for the biased die
Pr(6)=0.5 and Pr(1)=Pr(2)=Pr(3)=Pr(4)=Pr(5)=0.1
&amp;#39;&amp;#39;&amp;#39;
pi=np.array([2.0/3,1.0/3])
A=np.array([[.95,.05],[.1,.9]])
B=np.array([[1.0/6 for i in range(6)],[.1,.1,.1,.1,.1,.5]])
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now based on these probability sequences we need to produce a sequence
of &lt;strong&gt;observed&lt;/strong&gt; and &lt;strong&gt;hidden&lt;/strong&gt; states. We use the notion of weighted
sampling, which basically means that terms/states with higher
probabilies assigned to them are more likely to be selected/sampled. For
example,let us consider the starting state. For this we need to use the
&lt;strong&gt;pi&lt;/strong&gt; matrix, since that encodes the likiliness of starting in a
particular state. We observe that for starting in &lt;strong&gt;Fair&lt;/strong&gt; state the
probability is .667 and twice that of starting in &lt;strong&gt;Biased&lt;/strong&gt; state.
Thus, it is much more likely that we start in Fair state. We use
&lt;strong&gt;Fitness Proportionate Selection&lt;/strong&gt; [3] to sample states based on
weights (probability). For selection of starting state we would proceed
as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We choose a random value between 0 and 1&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We iterate over the list of values (prior) and iteratively subtract
    the value at current position from the number which we chose at
    random and as soon as it becomes negative, we return the index. Let
    us demonstrate this with a function.&lt;/p&gt;
&lt;p&gt;'''
Returns next state according to weigted probability array. Code based on Weighted random generation in Python [4]
'''
def next_state(weights):
    choice = random.random() * sum(weights)
    for i, w in enumerate(weights):
        choice -= w
        if choice &amp;lt; 0:
            return i&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We test the above function by making a call to it 1000 times and then we
try to see how many times do we get a 0 (Fair) wrt 1 (Biased), given the &lt;strong&gt;pi&lt;/strong&gt; vector.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;count=0
for i in range(1000):
    count+=next_state(pi)
print &amp;quot;Expected number of Fair states:&amp;quot;,1000-count
print &amp;quot;Expected number of Biased states:&amp;quot;,count

Expected number of Fair states: 649
Expected number of Biased states: 351
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, we write the following functions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;create_hidden_sequence (pi,A,length): which creates a hidden
    sequence (Markov Chain) of desired length based on &lt;strong&gt;Pi&lt;/strong&gt; and &lt;strong&gt;A&lt;/strong&gt;.
    The algorithm followed is as follows: We choose the first state as
    described above. Next on the basis of current state, we see it's
    transition matrix and assign the next state by weighted sampling (by
    invoking next_state with argument as A[current_state])&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;create_observed_sequence (hidden_sequence,B): which create an
    observed sequence based on hidden states and associated &lt;strong&gt;B&lt;/strong&gt;. Based
    on current hidden state, we use it's emission parameters to sample
    the observation.&lt;/p&gt;
&lt;p&gt;def create_hidden_sequence(pi,A,length):
    out=[None]*length
    out[0]=next_state(pi)
    for i in range(1,length):
        out[i]=next_state(A[out[i-1]])
    return out&lt;/p&gt;
&lt;p&gt;def create_observation_sequence(hidden_sequence,B):
    length=len(hidden_sequence)
    out=[None]*length
    for i in range(length):
        out[i]=next_state(B[hidden_sequence[i]])
    return out&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thus, using these functions and the HMM paramters we decided earlier, we
create length 1000 sequence for hidden and observed states.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;hidden=np.array(create_hidden_sequence(pi,A,1000))
observed=np.array(create_observation_sequence(hidden,B))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now, we create helper functions to plot the two sequence in a way we can
intuitively understand the HMM.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&amp;#39;&amp;#39;&amp;#39;Group all contiguous values in tuple. Recipe picked from Stack Overflow [5]&amp;#39;&amp;#39;&amp;#39;
def group(L):
    first = last = L[0]
    for n in L[1:]:
        if n - 1 == last: # Part of the group, bump the end
            last = n
        else: # Not part of the group, yield current group and start a new
            yield first, last
            first = last = n
    yield first, last # Yield the last group

&amp;#39;&amp;#39;&amp;#39;Create tuples of the form (start, number_of_continuous values&amp;#39;&amp;#39;&amp;#39;
def create_tuple(x):
    return [(a,b-a+1) for (a,b) in x]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now the main code&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;#Tuples of form index value, number of continuous values corresponding to Fair State
indices_hidden_fair=np.where(hidden==0)[0]
tuples_contiguous_values_fair=list(group(indices_hidden_fair))
tuples_start_break_fair=create_tuple(tuples_contiguous_values_fair)

#Tuples of form index value, number of continuous values corresponding to Biased State
indices_hidden_biased=np.where(hidden==1)[0]
tuples_contiguous_values_biased=list(group(indices_hidden_biased))
tuples_start_break_biased=create_tuple(tuples_contiguous_values_biased)

#Tuples for observations
observation_tuples=[]
for i in range(6):
    observation_tuples.append(create_tuple(group(list(np.where(observed==i)[0]))))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we plot the hidden and observation sequences&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nt"&gt;plt&lt;/span&gt;&lt;span class="nc"&gt;.figsize&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;20&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;10&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="nt"&gt;plt&lt;/span&gt;&lt;span class="nc"&gt;.subplot&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;2&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="nt"&gt;plt&lt;/span&gt;&lt;span class="nc"&gt;.xlim&lt;/span&gt;&lt;span class="o"&gt;((&lt;/span&gt;&lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1000&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
&lt;span class="nt"&gt;plt&lt;/span&gt;&lt;span class="nc"&gt;.title&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Observations&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="nt"&gt;for&lt;/span&gt; &lt;span class="nt"&gt;i&lt;/span&gt; &lt;span class="nt"&gt;in&lt;/span&gt; &lt;span class="nt"&gt;range&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;6&lt;/span&gt;&lt;span class="o"&gt;):&lt;/span&gt;
    &lt;span class="nt"&gt;plt&lt;/span&gt;&lt;span class="nc"&gt;.broken_barh&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;observation_tuples&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="o"&gt;,(&lt;/span&gt;&lt;span class="nt"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="nc"&gt;.5&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;facecolor&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;k&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="nt"&gt;plt&lt;/span&gt;&lt;span class="nc"&gt;.subplot&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;2&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;2&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="nt"&gt;plt&lt;/span&gt;&lt;span class="nc"&gt;.xlim&lt;/span&gt;&lt;span class="o"&gt;((&lt;/span&gt;&lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1000&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
&lt;span class="nt"&gt;plt&lt;/span&gt;&lt;span class="nc"&gt;.title&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Hidden States Green:Fair, Red: Biased&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="nt"&gt;plt&lt;/span&gt;&lt;span class="nc"&gt;.broken_barh&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;tuples_start_break_fair&lt;/span&gt;&lt;span class="o"&gt;,(&lt;/span&gt;&lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;facecolor&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;g&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="nt"&gt;plt&lt;/span&gt;&lt;span class="nc"&gt;.broken_barh&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;tuples_start_break_biased&lt;/span&gt;&lt;span class="o"&gt;,(&lt;/span&gt;&lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;&lt;span class="nt"&gt;facecolor&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Following is the produced output. Red indicates biased die and green
indicates fair die. We can confirm our HMM simulation by seeing a very
high number of 6 when biased die is used and a similar observation for
other states. &lt;/p&gt;
&lt;p&gt;&lt;img src="http://nipunbatra.files.wordpress.com/2013/05/index.png" alt="[before]" title="[before]"&gt;&lt;/p&gt;
&lt;p&gt;This code is part of a HMM package that i am building, which can be
found here on &lt;a href="https://github.com/nipunreddevil/PyHMM"&gt;Github&lt;/a&gt;. Contributions welcome!  The IPython notebook
for this example can be found &lt;a href="http://nbviewer.ipython.org/5558903"&gt;here&lt;/a&gt;. Similar IPython based tutorials
can be found in the &lt;a href="http://nipunbatra.github.io/tutorials"&gt;tutorials&lt;/a&gt; section.&lt;/p&gt;
&lt;p&gt;Watch out for the next post on this topic describing Simulating
Continuous HMM's.&lt;/p&gt;
&lt;p&gt;References&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;http://en.wikipedia.org/wiki/Hidden_Markov_model&lt;/li&gt;
&lt;li&gt;http://www.stanford.edu/class/stats366/hmmR2.html&lt;/li&gt;
&lt;li&gt;http://en.wikipedia.org/wiki/Fitness_proportionate_selection&lt;/li&gt;
&lt;li&gt;http://eli.thegreenplace.net/2010/01/22/weighted-random-generation-in-python/&lt;/li&gt;
&lt;li&gt;http://stackoverflow.com/questions/2154249/identify-groups-of-continuous-numbers-in-a-list&lt;/li&gt;
&lt;/ol&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sat, 11 May 2013 10:05:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-05-11:2013/05/simulating-a-discrete-hidden-markov-model/</guid><category>Hidden Markov Model</category><category>Python</category></item><item><title>Simple is better than complex.</title><link>http://nipunbatra.github.io/2013/05/simple-is-better-than-complex/</link><description>&lt;p&gt;You would have read this on the Zen of Python. Going through Wes' book
on Data Analysis in Python, encountered a recipe showing exactly the
same.&lt;/p&gt;
&lt;p&gt;The problem is a classic one. Creating counts of attributes using
dictionaries.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def counts_1(sequence):
    counts={}
    for i in sequence:
        if i in counts:
            counts[i] +=1
        else:
            counts[i]=1
    return counts
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And the cleaner version making use of DefaultDict&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def counts_2(sequence):
    counts=defaultdict(int)
    for i in sequence:
        counts[i] +=1 
    return counts
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Simpler, more elegant, less branching!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Fri, 10 May 2013 19:22:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-05-10:2013/05/simple-is-better-than-complex/</guid><category>Python</category></item><item><title>Resources for Scientific Computing in Python</title><link>http://nipunbatra.github.io/2013/05/resources-for-scientific-computing-in-python/</link><description>&lt;p&gt;A tweet regarding suggested tutorials for Matplotlib made me wonder if i
should create a post regarding resources for scientific research in the
Python ecosystem.  I have tried to put down some stuff beyond the
official documentation.&lt;/p&gt;
&lt;p&gt;&lt;span style="text-decoration:underline;"&gt;&lt;strong&gt;Books&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;http://www.packtpub.com/matplotlib-python-development/book&lt;/li&gt;
&lt;li&gt;http://www.packtpub.com/learning-scipy-for-numerical-and-scientific-computing/book&lt;/li&gt;
&lt;li&gt;http://www.packtpub.com/numpy-for-python-cookbook/book&lt;/li&gt;
&lt;li&gt;http://www.packtpub.com/numpy-mathematical-2e-beginners-guide/book&lt;/li&gt;
&lt;li&gt;http://www.packtpub.com/learning-ipython-for-interactive-computing-and-data-visualization/book&lt;/li&gt;
&lt;li&gt;http://www.amazon.com/SciPy-NumPy-An-Overview-Developers/dp/1449305466&lt;/li&gt;
&lt;li&gt;http://shop.oreilly.com/product/0636920023784.do&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here is a Work in Progress regarding the same.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style="text-decoration:underline;"&gt;Matplotlib&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Articles:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;http://www.loria.fr/\~rougier/teaching/matplotlib/&lt;/li&gt;
&lt;li&gt;http://nbviewer.ipython.org/urls/raw.github.com/jrjohansson/scientific-python-lectures/master/Lecture-4-Matplotlib.ipynb&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Videos&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;http://pyvideo.org/video/617/plotting-with-matplotlib&lt;/li&gt;
&lt;li&gt;http://pyvideo.org/video/1344/advanced-matplotlib&lt;/li&gt;
&lt;li&gt;http://pyvideo.org/video/971/advanced-matplotlib-tutorial-library-author-john-h
    (Advanced)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span style="text-decoration:underline;"&gt;&lt;strong&gt;Numpy&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Articles&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;http://www.scipy.org/NumPy_for_Matlab_Users (The article which i
    refer the most)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Videos&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;http://pyvideo.org/video/620/high-performance-python-ii&lt;/li&gt;
&lt;li&gt;http://pyvideo.org/video/1190/introduction-to-numpy-and-matplotlib&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I will keep on updating this list and would to be happy to add stuff
based on comments.&lt;/p&gt;
&lt;p&gt;Also i personally follow http://glowingpython.blogspot.in/ for learning
some cool tricks.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TODO&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Add resources for Scipy, Pandas, Scikit Learn&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Fri, 10 May 2013 16:38:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-05-10:2013/05/resources-for-scientific-computing-in-python/</guid><category>Python</category></item><item><title>Kronecker Product in Python</title><link>http://nipunbatra.github.io/2013/05/kronecker-product-in-python/</link><description>&lt;p&gt;While developing &lt;a href="https://github.com/nipunreddevil/PyHMM"&gt;code&lt;/a&gt; for Hidden Markov Models in Python, i had to
do a particular type of matrix multiplication. Unfortunately i did not
know what it was called. So here's what you are supposed to do: Given a
m X m and a n X n matrix you need to element wise multiply to produce a
mn X mn matrix. Here is an illustration of the same.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Matrix X
--------------
x1 x2 x3
x1| a b c
x2| d e f
x3| g h i

Matrix Y
--------------
y1 y2
y1| j k
y2| l m

Matrix Z (Output)
----------------------------------------
x1y1 x1y2 x2y1 x2y2 x3y1 x3y2
x1y1| aj ak bj bk cj ck
x1y2| al am bl bm cl cm
x2y1| dj dk ej ek fj fk

.
.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The code for the same is not that difficult to figure out once the
problem is worked on paper. The code is as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def transition_multiply(X,Y):
    num_rows_X=len(X)
    num_rows_Y=len(Y)
    out=[]
    count=0
    for i in range(num_rows_X):     
        for j in range(num_rows_Y):         
            out.append([])          
            for x in X[i]:
                 for y in Y[j]:                 
                     out[count].append(x*y)             
            count+=1
    return out
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;But i felt that the code was naive and being non vectorized it was going
to be very slow. So i asked about the same on &lt;a href="http://stackoverflow.com/questions/16330971/efficiently-computing-element-wise-product-of-transition-matrices-mm-nn"&gt;Stack Overflow&lt;/a&gt;. The
answer was short and simple, this multiplication technique is called
Kronecker product. NumPy routine &lt;strong&gt;kron&lt;/strong&gt; would have sufficed. I am sure
the NumPy routine would be much more stable and quick!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Tue, 07 May 2013 21:28:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2013-05-07:2013/05/kronecker-product-in-python/</guid><category>Linear Algebra</category><category>Python</category></item><item><title>How Computer Algorithms and Elementary Physics helped to keep my laptop cool</title><link>http://nipunbatra.github.io/2011/11/how-computer-algorithms-and-elementary-physics-helped-to-keep-my-laptop-cool/</link><description>&lt;p&gt;I am a computer science student and as such someone with an inclination
towards software rather than hardware. So if you have a laptop which
heats up soon or may even shutdown due to that read on.Most probably if
you are an AMD user,you must read on. My CPU fan seems to have
accumulated some dust and thus my lappie heats up a hell lot and to
prevent com ponent damage,it shuts down.&lt;br /&gt;
So here i was looking for a solution. My screwdriver didn't work. So i
couldn't clean the fan.&lt;br /&gt;
Had to think of something better. A couple of years back a college
senior had advised me that Algos is a must for each Comp Sci student.
That struck me.&lt;br /&gt;
Here i was with Cormen-Intro to Algorithms. Yes the same book which i
used as a dumbell when i stopped hitting the gym. To prevent the heating
problems now was an elementary physics problem.Who says that Physics is
not required for Comp Science students. It took me less than a min to
balance forces,probably my laptop rested perfectly on Cormen and here i
was done.Now my laptop is at a better height. My laptop fan has enough
free space to dispense heat. My cupboard has space for more books.&lt;br /&gt;
So next time anyone tells you how important Algorithms are,pay heed!!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Wed, 02 Nov 2011 19:28:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2011-11-02:2011/11/how-computer-algorithms-and-elementary-physics-helped-to-keep-my-laptop-cool/</guid><category>algorithms</category></item><item><title>An interesting question-Where are the pigeons coming from?</title><link>http://nipunbatra.github.io/2011/10/an-interesting-question-where-are-the-pigeons-coming-from/</link><description>&lt;p&gt;Assume that you are getting a continuous stream of data (ascii
characters). How best can you tell that there is a repetition in it.&lt;/p&gt;
&lt;p&gt;Think........&lt;br /&gt;
................&lt;/p&gt;
&lt;p&gt;
When i first heard it, i thought of making a hashmap, since only 128
such characters exist. And in O(n) i'll be able to report a repetition.
The easier answer:

    The moment the length of stream is greater than 128,there is a repetition. Pigeonhole principle!</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sat, 08 Oct 2011 20:08:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2011-10-08:2011/10/an-interesting-question-where-are-the-pigeons-coming-from/</guid><category>algorithms</category></item><item><title>Playing with strings</title><link>http://nipunbatra.github.io/2011/08/playing-with-strings/</link><description>&lt;p&gt;This program deals with reversing a string word wise.For eg. "hello
welcome to india" should return "india to welcome hello".&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.Arrays&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.HashMap&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="n"&gt;public&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;StringLibrary&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;

    &lt;span class="n"&gt;private&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;reverseStringWordWise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;toCharArray&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
        &lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="n"&gt;space&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
        &lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;Finding&lt;/span&gt; &lt;span class="n"&gt;position&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;spaces&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;lt&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="n"&gt;space&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
                &lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
                &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

            &lt;span class="p"&gt;}&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;substring&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;space&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
        &lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="n"&gt;spaceIndex&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;spaceIndex&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;lt&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;

            &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot; &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;substring&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;space&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;spaceIndex&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;space&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;spaceIndex&lt;/span&gt;&lt;span class="p"&gt;]));&lt;/span&gt;
            &lt;span class="n"&gt;spaceIndex&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;

        &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot; &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;substring&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;space&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]));&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="n"&gt;public&lt;/span&gt; &lt;span class="n"&gt;static&lt;/span&gt; &lt;span class="n"&gt;void&lt;/span&gt; &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;StringLibrary&lt;/span&gt; &lt;span class="n"&gt;st&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new&lt;/span&gt; &lt;span class="n"&gt;StringLibrary&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
        &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;This is just a test string&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;st&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reverseStringWordWise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;st&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reverseStringWordWise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;hello world&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;st&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reverseStringWordWise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;There has been some effort to make this progarm work&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;

    &lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It works for the test cases i tried. Would like to figure out if it
breaks in any case.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Fri, 26 Aug 2011 21:11:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2011-08-26:2011/08/playing-with-strings/</guid><category>algorithms</category></item><item><title>String functions Part 1</title><link>http://nipunbatra.github.io/2011/08/string-functions-part-1/</link><description>&lt;p&gt;An interesting question.How to check whether a string has all unique
characters. I came up with 2 solutions to this. Maybe they can be
further optimized for space and time.Would like to hear from other about
the same.&lt;br /&gt;
Here is the first solution which is O(nlgn)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;public boolean isAllUniqueChar1(String inp)
    {
        //O(nlogn) sorting +O(n) checking for duplicates
        String sortedString=sortString(inp);
        int length=sortedString.length();
        if(length==1)
        {
            return true;

        }
        for(int i=0;i&amp;lt;length-1;i++)
        {
            if(sortedString.charAt(i)==sortedString.charAt(i+1))
            {
                System.out.println(sortedString.charAt(i)+&amp;quot; is repeated&amp;quot;);
                return false;
            }
        }
        return true;


    }
    private String sortString(String inp) {
        char [] c = inp.toCharArray();
        Arrays.sort(c);
        return new String(c);

    }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A better approach is to use a 2\^8 i.e 256 length boolean array which
tells whether a particular ascii value had been encountered before. This
solution is O(n)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;private boolean isAllUniqueChar2(String inp) {
        //O(n) time and constant space
        int length=inp.length();
        if(length==1)
        {
            return true;
        }
        boolean[] isCharSet=new boolean[256];
        int asciiValue;
        for(int i=0;i&amp;lt;length;i++)
        {
            asciiValue=inp.charAt(i);
            if(isCharSet[asciiValue])
            {
                return false;
            }
            else
            {
                isCharSet[asciiValue]=true;
            }
        }

        return true;

    }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A third more fancier solution on the same lines using a Hashmap&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;private boolean isAllUniqueChar3(String test) {
        //Hashmap has only 2 values for each key
        //Null if char was not encountered before or true if it were encountered before
        if(test.length()==1)
        {
            return true;
        }
        HashMap charSet=new HashMap();
        char[] testChar=test.toCharArray();
        for(char c:testChar)
        {
            if(charSet.get(Character.valueOf(c))!=null)
            {
                return false;
            }
            else
            {
                 charSet.put(Character.valueOf(c),Boolean.valueOf(true));
            }
        }
        return true;
    }
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sun, 21 Aug 2011 15:31:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2011-08-21:2011/08/string-functions-part-1/</guid><category>algorithms</category></item><item><title>Python script to send mail via SMTP</title><link>http://nipunbatra.github.io/2011/02/python-script-to-send-mail-via-smtp/</link><description>&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;smtplib&lt;/span&gt;
&lt;span class="n"&gt;SMTP_SERVER&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;smtp.gmail.com&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;SMTP_PORT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;587&lt;/span&gt;
&lt;span class="n"&gt;sender&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;a@a.com &amp;#39;&lt;/span&gt;&lt;span class="c"&gt;##Enter your mail id here&lt;/span&gt;
&lt;span class="n"&gt;password&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="c"&gt;####Enter your password here&lt;/span&gt;
&lt;span class="n"&gt;recipient&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="c"&gt;##Enter recepient mail id here&lt;/span&gt;
&lt;span class="n"&gt;subject&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="c"&gt;##Enter subject here&lt;/span&gt;
&lt;span class="n"&gt;body&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Enter here the body of the mail&amp;#39;&lt;/span&gt;
&lt;span class="s"&gt;&amp;quot;Sends an e-mail to the specified recipient.&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;body&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;body&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;headers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;From: &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;sender&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
           &lt;span class="s"&gt;&amp;quot;Subject: &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;subject&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
           &lt;span class="s"&gt;&amp;quot;To: &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;recipient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
           &lt;span class="s"&gt;&amp;quot;MIME-Version: 1.0&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
           &lt;span class="s"&gt;&amp;quot;Content-Type: text/html&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;headers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\r\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;session&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;smtplib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SMTP&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;SMTP_SERVER&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;SMTP_PORT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ehlo&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;starttls&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ehlo&lt;/span&gt;
&lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;login&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sender&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sendmail&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sender&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;recipient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;headers&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\r\n\r\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;body&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;quit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Liked it??&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sun, 20 Feb 2011 12:43:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2011-02-20:2011/02/python-script-to-send-mail-via-smtp/</guid><category>Python</category></item><item><title>Let Python brighten up your desktop</title><link>http://nipunbatra.github.io/2011/02/let-python-brighten-up-your-desktop/</link><description>&lt;p&gt;Wanna control your laptop brightness using Python? It ain't that
difficult. Having found a lot of guides on how to do it from shell it
wasn't that difficult to let Python do it for me. Let us get to the code
straight away.&lt;br /&gt;
&lt;strong&gt;NB&lt;/strong&gt;Not sure how to do this on Windows,would like to know the same
from the readers.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;subprocess&lt;/span&gt;
&lt;span class="n"&gt;subprocess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;sudo chown $USERNAME:$USERNAME /proc/acpi/video/VGA/LCD/brightness&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;subprocess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;quot; echo -n 50 &amp;gt; /proc/acpi/video/VGA/LCD/brightness&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now what may come to your mind is whether we can give any value to the
brightness figure. This ain't true. Only certain levels are allowed. One
may navigate down to /proc/....and use "cat" command to figure out the
levels. On my system they are as:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;levels&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="mi"&gt;25&lt;/span&gt; &lt;span class="mi"&gt;35&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt; &lt;span class="mi"&gt;60&lt;/span&gt; &lt;span class="mi"&gt;75&lt;/span&gt; &lt;span class="mi"&gt;90&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let us let Python do the needful for us.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;subprocess&lt;/span&gt;
&lt;span class="n"&gt;subprocess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;sudo chown $USERNAME:$USERNAME /proc/acpi/video/VGA/LCD/brightness&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;files&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;/proc/acpi/video/VGA/LCD/brightness&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;r+&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;files&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ain't it easy!!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sat, 19 Feb 2011 13:13:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2011-02-19:2011/02/let-python-brighten-up-your-desktop/</guid><category>Python</category></item><item><title>Software Review:Mobile Media Converter</title><link>http://nipunbatra.github.io/2011/02/software-reviewmobile-media-converter/</link><description>&lt;p&gt;
Fed up with trial software, i found this great piece of software called
Mobile Media converter. Now it does most of the things you would want
out of such a software.  
1.Supports youtube video downloads  
2.Supported on Windows,Mac,Linux(yipee!)  
3.Variety of formats supported  
4.Free!!  
5.Fits well into right context menu  
6.Cool drag and drop facility  
Find more at:

    http://www.miksoft.net/mobileMediaConverter.htm

[![][]][]

  []: http://nipunbatra.files.wordpress.com/2011/02/11.png
    "MMC in action!"
  [![][]]: http://nipunbatra.files.wordpress.com/2011/02/11.png</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sat, 19 Feb 2011 10:20:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2011-02-19:2011/02/software-reviewmobile-media-converter/</guid></item><item><title>No. of possible paranthesisations</title><link>http://nipunbatra.github.io/2010/08/no-of-possible-paranthesisations/</link><description>&lt;p&gt;Now this is a problem which we encounter while using matrix
multiplication in the most efficient manner.&lt;br /&gt;
A simple problem on CodeChef wanted to give the possible number of
paranthesisations given the number of matrices.&lt;br /&gt;
The recurrence relation&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; P(n)=summation i from 1 to n-1 on P(i)*P(n-i)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;would suffice.&lt;br /&gt;
Now this evaluates to some expression in terms of combinations which
didnt work for me.&lt;br /&gt;
Thus i used this recurrence relation along with memoization to get the
thing done.&lt;br /&gt;
The code follows. A bottom up approach could also have been very
efficient.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;map intToFunction;

int P(int n)
    {
        int r;
        if(n==1)
            {
                return 1;
            }
        else{
            r=intToFunction[n];
            if(r==0)
                {
                int sum=0;
                int k;
                for(k=1;k&amp;lt;n;k++)
                sum+=P(k)*P(n-k);

                intToFunction[n]=sum;
                r=sum;

                }
            return r;
    }
    }
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sun, 22 Aug 2010 18:30:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2010-08-22:2010/08/no-of-possible-paranthesisations/</guid><category>algorithms</category><category>cpp</category></item><item><title>Counting the number of 1's (binary set bits given a hex input)</title><link>http://nipunbatra.github.io/2010/08/counting-the-number-of-1sbinary-set-bits-given-a-hex-input/</link><description>&lt;p&gt;Now this is one of the questions i was asked at one of the
interviews.For eg i have a string as "AAC8".&lt;br /&gt;
Then it's equivalent binary would be :&lt;br /&gt;
1010 1010 1010 1000&lt;br /&gt;
And the number of 1's would be 7.&lt;br /&gt;
Now a simple solution could be to store number of 1's for each
character. eg A:2,8:1 and so forth.&lt;br /&gt;
But i was told to use lesser number of switch cases.So i found a
pattern amongst the number of 1's and the equivalent decimal number as:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;

&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;

&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;

&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now a pattern emerged. Like we need to save only the first member of the
group in the switch.&lt;br /&gt;
For eg. A i.e.10&lt;br /&gt;
10/4=2&lt;br /&gt;
Corresponding to 2 we store 1&lt;br /&gt;
10%4=2&lt;br /&gt;
Corresponding to 2 we store 1&lt;br /&gt;
Therefore we add these two to get 2 as number of set bits in A.&lt;br /&gt;
The C++ code follows.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;#include&amp;lt;iostream&amp;gt;&lt;/span&gt;
&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="k"&gt;namespace&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;toDecimal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;0&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;=&lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;9&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;0&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

    &lt;span class="k"&gt;else&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="sc"&gt;&amp;#39;A&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

    &lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;noOfOnesGivenHex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;hexString&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;ans&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hexString&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="k"&gt;switch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;toDecimal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hexString&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                    &lt;span class="p"&gt;{&lt;/span&gt;
                        &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
                        &lt;span class="n"&gt;ans&lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
                        &lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
                        &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
                        &lt;span class="n"&gt;ans&lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
                        &lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
                        &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
                        &lt;span class="n"&gt;ans&lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
                        &lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
                        &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
                        &lt;span class="n"&gt;ans&lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
                    &lt;span class="p"&gt;}&lt;/span&gt;
                    &lt;span class="c1"&gt;//cout&amp;lt;&amp;lt;toDecimal(hexString[i])%4;&lt;/span&gt;
                &lt;span class="k"&gt;switch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;toDecimal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hexString&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                    &lt;span class="p"&gt;{&lt;/span&gt;
                        &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
                        &lt;span class="n"&gt;ans&lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
                        &lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
                        &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
                        &lt;span class="n"&gt;ans&lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
                        &lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
                        &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
                        &lt;span class="n"&gt;ans&lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
                        &lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
                        &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
                        &lt;span class="n"&gt;ans&lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
                    &lt;span class="p"&gt;}&lt;/span&gt;
                &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

            &lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;ans&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;


        &lt;span class="n"&gt;cout&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;noOfOnesGivenHex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;AAC8&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There has to be some better way of doing this,maybe without a switch
case.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sat, 21 Aug 2010 18:23:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2010-08-21:2010/08/counting-the-number-of-1sbinary-set-bits-given-a-hex-input/</guid><category>algorithms</category></item><item><title>Largest palindromic substring</title><link>http://nipunbatra.github.io/2010/08/largest-palindromic-substring/</link><description>&lt;p&gt;Now this is a question which my classmate Nikhil had asked. The best
solution to find a palindromic substring given a string.An example which
he cited was:
Longest Palindromic substring for abclevelabc is level&lt;/p&gt;
&lt;p&gt;Thus i set trying to solve it.Here's a naive O(n^3) solution and i am
trying to figure out how to optimise this program after which will try
to find a better algo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;char* substring(char*s,int start,int finish)
    {
        int ctr=0;
        char str[1000];
        while(start&amp;lt;=finish)
            {
                str[ctr]=s[start];
                start+=1;
                ctr+=1;
            }
        str[ctr]=&amp;#39;&amp;#39;;
        return str;
    }

bool isPalindrome(char *s)
    {
        int size=strlen(s);
        int j=size-1;
        int i=0;
        while((s[i]==s[j])&amp;amp;&amp;amp;(i=j)
        return true;
        else
        return false;
    }
int main()
    {

        int i,j;
        char s[100];
        cin&amp;gt;&amp;gt;s;

        int size=strlen(s);
        int tempMax=size-1;
        while(tempMax&amp;gt;1)
        {
        for(i=0;i+tempMax&amp;lt;size;i++)
            {
                if(isPalindrome(substring(s,i,i+tempMax)))//O(n)
                    {
                        puts(substring(s,i,i+tempMax));
                        cout&amp;lt;&amp;lt;&amp;quot; of size &amp;quot;&amp;lt;&amp;lt;tempMax&amp;lt;&amp;lt;&amp;quot;\n&amp;quot;;
                        break;
                    }
            }
        tempMax-=1;
        }


        return 0;
    }
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sat, 21 Aug 2010 16:22:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2010-08-21:2010/08/largest-palindromic-substring/</guid><category>algorithms</category></item><item><title>Swapping two numbers</title><link>http://nipunbatra.github.io/2010/08/swapping-two-numbers/</link><description>&lt;p&gt;Found an interesting approach and have included it in the program,never
thought XOR to be so useful and simple.&lt;br /&gt;
Now i would be interested to see how these methods compare on different
machines.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;#include&lt;/span&gt;
&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="k"&gt;namespace&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;swapUsingExtraVariable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;temp&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;temp&lt;/span&gt;&lt;span class="o"&gt;=*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;=*&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;temp&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;swapUsingAddition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;=*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;+*&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;=*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;-*&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;=*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;-*&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;swapUsingXor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;=*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;^*&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;=*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;^*&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;=*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;^*&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="n"&gt;swapUsingExtraVariable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;swapUsingAddition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;swapUsingXor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;cout&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Thu, 19 Aug 2010 21:27:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2010-08-19:2010/08/swapping-two-numbers/</guid><category>algorithms</category></item><item><title>When Memoization helps</title><link>http://nipunbatra.github.io/2010/02/when-memoization-helps/</link><description>&lt;p&gt;SPOJ has some intriguing problems and one such problem kept me stuck to
my laptop for hours. 
The link to the problem is :&lt;a href="http://www.spoj.pl/problems/NG0FRCTN/"&gt;here&lt;/a&gt;.
Now when i began i took a bottom up approach computing from 1 up till
maximum value reqd. 
This took me beyond the normal programming limits and i had to resort
to using vectors which I had not done before extensively.It took a long
time to code but alas it didnt work. Then I shifted the same algo to
Python. But even Python started complaining about memory usage. 
Now it was quite clear that this approach would fail. Thus recursion
had to be tried. But plain recursion would obviously get timed out. Then
I resorted to "memoization" in Python and wow it didnt complain and was
damn fast. But again SPOJ complained timing me out. A few optimizations
and still no respite,i shifted back to C++. 
This time I was forced to use STL again. This time for memoization and yipee i was able to get accepted this time. Though I
have the worst accepted time in C++. Wonder what algo others have used. 
Would be looking forward to knowing better ways of doing this problem. 
This is a wonderful problem and taught me many concepts. Sometimes it
pays to persevere.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sat, 20 Feb 2010 17:24:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2010-02-20:2010/02/when-memoization-helps/</guid><category>algorithms</category><category>Python</category></item><item><title>ProjectEuler Prob 97</title><link>http://nipunbatra.github.io/2010/01/projecteuler-prob-97/</link><description>&lt;p&gt;Now since i learnt about the modular exponentiation technique it's been
easier to solve otherwise difficult questions on Spoj and on project
euler.Now this problem would otherwise take a lot of time to be
evaluated using standard techniques.But i was able to solve it within
the blink of an eye. Here is what the problem states:
28433*2\^7830457+1.&lt;br /&gt;
Find the last ten digits of this prime number,&lt;br /&gt;
Here is my Python code for the same.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;def modeexp(x,y):
    if y==0:
        return 1
    z=modeexp(x,int(y/2))
    if y%2==0:
       return (z*z)%10000000000
    else :
       return (x*(z*z))%10000000000

x=2
y=7830457
c=int(modeexp(x,y))
d=(c*28433+1)%10000000000
print d
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hope using this technique i am able to do those problems which earlier
gave me a headache.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sun, 31 Jan 2010 13:21:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2010-01-31:2010/01/projecteuler-prob-97/</guid><category>algorithms</category><category>Python</category></item><item><title>888!</title><link>http://nipunbatra.github.io/2010/01/888/</link><description>&lt;p&gt;Picked up a very interesting problem from SPOJ called three fat ladies.&lt;br /&gt;
Objective: Given input k,tell the kth number whose cube ends with 888.&lt;br /&gt;
Now using the traditional cubing and division would obviously be timed
out,so an optimization was needed.&lt;br /&gt;
1.Clearly number must end with 2&lt;br /&gt;
2.Computing first few terms showed the pattern:192,442,692,942,1192 and
so on.So the problem was merely reduced to string manipulations with
minimum calculations.&lt;br /&gt;
Here is the Python code for the same&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;raw_input&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;raw_input&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;str1&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;192&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;str1&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;442&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;str1&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;692&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;str1&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;942&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;=&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;str1&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;str2&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;str2&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;str1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now this gave a time of .07 on the server, so clearly it's not very
optimized.&lt;br /&gt;
A much better solution could involve using modular exponentiation. The
problem is of the form x\^y%n which is polynomial in nature. Looking
forward to better code or algo than this.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Thu, 07 Jan 2010 12:51:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2010-01-07:2010/01/888/</guid><category>algorithms</category><category>Python</category></item><item><title>Decision Tree based classification</title><link>http://nipunbatra.github.io/2010/01/decision-tree-based-classification/</link><description>&lt;p&gt;Now having done the descriptive analysis comes the more important task
of classification of data. What I did was created a decision tree model
of 4 subjects marks and using it predicted whether the 5th subject marks
are lesser or greater than 55 (POM explains the reason for lower
classification point).&lt;/p&gt;
&lt;p&gt;I split my database into two, one for training containing 25 elements and
the other for testing containing 10 elements. 
Firstly I made a decision tree of depth 1 which looks like.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nipunbatra.files.wordpress.com/2010/01/1.png" alt="[1]" title="[1]"&gt;&lt;/p&gt;
&lt;p&gt;In all these decision trees v4,..v7 means subject 1 through subject 4. 
Now this tree clearly uses subject 2(v5) for determining the class(&gt;
or \&amp;lt; than 55 marks for subject5). What it says is that all that who got
less than 68 in subject 2 got less than 55 with an accuracy of
84%(MCE=16%). 
When this fitting function was used on test data,it yielded a poor
performance of 50% prediction accuracy. So a deeper decision tree was
required. 
The next figure is a decision tree of depth 2.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nipunbatra.files.wordpress.com/2010/01/2.png" alt="[2]" title="[2]"&gt;&lt;/p&gt;
&lt;p&gt;Now the prediction improved to 80% on test data and on training data it
was 92%. 
Still it could be improved.So next a decision tree of depth 3 was made
as shown in next figure.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nipunbatra.files.wordpress.com/2010/01/3.png" alt="[3]" title="[3]"&gt;&lt;/p&gt;
&lt;p&gt;This did not improve the prediction capability on the test data though on
training data it obviously improved and was 96%. 
The final decision tree I made was of depth 4 which actually turned out
to be a case of overfitting. It is shown next.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nipunbatra.files.wordpress.com/2010/01/4.png" alt="[4]" title="[4]"&gt;&lt;/p&gt;
&lt;p&gt;Thus the analysis using &lt;strong&gt;binary greedy decision trees&lt;/strong&gt; revealed a
classification rule as per figure 3 or fig2 with an accuracy of 80% or
Misclassification error of 20%. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The above analysis was done using R&lt;/strong&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sun, 03 Jan 2010 17:36:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2010-01-03:2010/01/decision-tree-based-classification/</guid><category>R</category></item><item><title>Are good mathematicians good programmers or vice versa</title><link>http://nipunbatra.github.io/2010/01/are-good-mathematicians-good-programmers-or-vice-versa/</link><description>&lt;p&gt;This is a basic attempt for making some association results,again based
on 2nd sem marks of my batch.&lt;br /&gt;
Test 1&lt;br /&gt;
Good in Maths implies Good in Programming&lt;br /&gt;
Now for this test i used values above mean of the class as good for
both the exams.Open Office Spreadsheet was used for the tests.&lt;br /&gt;
Observation 1:Total sample size =35&lt;br /&gt;
Observation 2:Good in Maths =28&lt;br /&gt;
Observation 3:Good in Prog. =25&lt;br /&gt;
Thus support(good in maths)=28/35 and support (good in prog)=25/35&lt;br /&gt;
Observation 4:Good in Prog. and Maths=23&lt;br /&gt;
Support(good in maths and prog)=23/35&lt;br /&gt;
Now the confidence of the association(good in maths-&gt;good in prog)
is:support(good in maths and prog)/support(good in maths)=23/28 which is
appx. :0.821428571&lt;/p&gt;
&lt;p&gt;Test 2&lt;br /&gt;
Finding confidence of the inverse relation(good in prog-&gt;good in
maths)&lt;br /&gt;
For this we have ,required confidence=support(good in maths and
prog)/support(good in prog)=23/25=0.92&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thus this random test reveals that the association rule that good
programmers are good mathematicians is much better than it's inverse.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;N.B.:This test does not reveal the larger picture for which more test
data is required.Also &lt;strong&gt;Simpson's paradox&lt;/strong&gt; has not been taken into
consideration.&lt;br /&gt;
Programmers Rock!&lt;br /&gt;
More association rules coming soon.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sun, 03 Jan 2010 13:05:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2010-01-03:2010/01/are-good-mathematicians-good-programmers-or-vice-versa/</guid><category>R</category></item><item><title>Analysis with R part 3</title><link>http://nipunbatra.github.io/2010/01/analysis-with-r-part-3/</link><description>&lt;p&gt;Now it gets interesting.Comparing two subjects' marks in one plot will
be a much better analysis than simply studying them separately. 
So again with simple R stuff I was able to make a plot containing the
Maths and PEE marks of my batch and they are compared firstly on a
frequency polygon graph as shown in this image.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nipunbatra.files.wordpress.com/2010/01/screenshot-8.png" alt="[7]" title="[7]"&gt;&lt;/p&gt;
&lt;p&gt;However this freq.plot reveals little(atleast to me).Thus a much better
comparison could be done using cumulative plots as shown in this
screenshot.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nipunbatra.files.wordpress.com/2010/01/screenshot-9.png" alt="[7]" title="[7]"&gt;&lt;/p&gt;
&lt;p&gt;Now if you watch a lot of cricket this graph may provide you a false
lead.No,PEE wasn't more scoring than Maths. How? 
This plot was based on CDF,thus the Maths performance is better since
it lies lower(or rightwards)in the plot. 
Still confusing. Only a scatter plot can help now and here it
is.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nipunbatra.files.wordpress.com/2010/01/screenshot-10.png" alt="[7]" title="[7]"&gt;&lt;/p&gt;
&lt;p&gt;Now it clearly shows that more people scored well in Maths than they
did in PEE(those above line y=x).
Those who scored better in PEE wrt their Maths scores lie below the y=x
line.
Conclusion:Maths in second sem was more scoring wrt PEE for our batch. 
Now it would be interesting to cut short all work using boxplot.Thus in
a simple command,boxplot depicting the performance of people in my batch
in all subjects is shown in the next figure. Quite clearly POM was a
disaster.One noticeable thing is that in Prog. There was little
difference in marks obtained by people getting 75 percentile wrt people
getting 25 percentile,when compared to other subjects.This plot also
depicts an outlier in Prog.Someone barely got 40.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nipunbatra.files.wordpress.com/2010/01/screenshot-11.png" alt="[7]" title="[7]"&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Fri, 01 Jan 2010 20:04:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2010-01-01:2010/01/analysis-with-r-part-3/</guid><category>R</category></item><item><title>Data Analysis in R part 2</title><link>http://nipunbatra.github.io/2010/01/data-analysis-in-r-part-2/</link><description>&lt;p&gt;Having made a histogram,the next step has to be plotting frequency
polygon for the same data.Again simple stuff,though this time it
required fooling the histogram function. 
This is the analysis with bin width of 5 and following it in the image
gallery is the one with bin width of 1.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nipunbatra.files.wordpress.com/2010/01/screenshot-31.png" alt="[31]" title="[31]"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nipunbatra.files.wordpress.com/2010/01/screenshot-4.png" alt="[4]" title="[4]"&gt;&lt;/p&gt;
&lt;p&gt;Also a side by side comparison of the histogram and the freq. polygon
is shown next. &lt;/p&gt;
&lt;p&gt;&lt;img src="http://nipunbatra.files.wordpress.com/2010/01/screenshot-6.png" alt="[6]" title="[6]"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nipunbatra.files.wordpress.com/2010/01/screenshot-7.png" alt="[7]" title="[7]"&gt;&lt;/p&gt;
&lt;p&gt;And now the Cumulative plot is made. The cumulative plot clearly
confirms the median to be around seventy and would be extremely useful
in determining percentile relation with marks.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Fri, 01 Jan 2010 14:06:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2010-01-01:2010/01/data-analysis-in-r-part-2/</guid><category>R</category></item><item><title>Analyzing Data in R Part 1</title><link>http://nipunbatra.github.io/2010/01/analyzing-data-in-r-part-1/</link><description>&lt;p&gt;Just started with a bit of Data Mining.&lt;br /&gt;
Realized the importance of visualization before we do other standard
statistical analysis.&lt;br /&gt;
Here is what i did.&lt;br /&gt;
The above gallery shows a histogram made for 2nd sem marks of our batch
in PEE.&lt;br /&gt;
The procedure followed was simple&lt;br /&gt;
1.Importing the data in R using read.csv&lt;br /&gt;
2.Using hist() function for plotting the results.&lt;br /&gt;
[gallery columns="2"]&lt;br /&gt;
A simple mean() function over the same column showed how high scoring
this subject was,the mean being 72.3.&lt;br /&gt;
Also the median was found to be 74.&lt;br /&gt;
Much more coming soon.Hope to make a predictive model soon.Any
suggestions where such an analysis could be applied(where data is freely
available)?&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Fri, 01 Jan 2010 12:03:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2010-01-01:2010/01/analyzing-data-in-r-part-1/</guid><category>R</category></item><item><title>When it comes to handling large numbers, i trust Python</title><link>http://nipunbatra.github.io/2009/12/when-it-comes-to-handling-large-numbersi-trust-python/</link><description>&lt;p&gt;Solving Project Euler's Prob 16, i decided to use Python, considering
the huge number involved. Now although using C would have been
faster,but at the cost of lots of code. A simple Python code did the
same for me. Problem statement:Finding number of digits in 2\^1000. Here
is the first solution.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;b=2
i=1
while i&amp;lt;1000:

    b=b*2
    i+=1
sum=0
print b
while b:
    sum=sum+b%10
    b=b/10

print sum
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now solution 2 requires even lesser coding. Have a look.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sum=0
b=2**1000
while b:
    sum=sum+b%10
    b=b/10

print sum
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ok, now this is child's play.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;print len(str(2**1000))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Will be looking forward to even more elegant solutions especially in
terms of algorithmic optimizations.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Thu, 24 Dec 2009 09:43:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2009-12-24:2009/12/when-it-comes-to-handling-large-numbersi-trust-python/</guid><category>algorithms</category><category>Python</category></item><item><title>For a change no Spiralling around</title><link>http://nipunbatra.github.io/2009/12/for-a-change-no-spiralling-around/</link><description>&lt;p&gt;Project euler problems can be tough and at times very tough and can get
your head spinning.Fortunately problem number 28 titled spirall...turned
out to be quiet an easy one.Here's my solution.If you have a better one
please do comment.Also using C has been a priority especially when i
read that scanf and printf are about thrice as fast as cout and cin.  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;#include int l_sum(int n)     {     if (n==1)         return 1;     else         return l_sum(n-2)+(n-2)*(n-2)+n*n;     } int r_sum(int n)     {     if (n==1)         return 1;     else         return r_sum(n-2)+((3*(n*n)+(n-2)*(n-2))/2);     } int main()     {&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;printf("%d",l_sum(1001)+r_sum(1001)-1);&lt;br /&gt;
}&lt;/code&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Wed, 23 Dec 2009 10:02:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2009-12-23:2009/12/for-a-change-no-spiralling-around/</guid><category>algorithms</category><category>Python</category></item><item><title>The Prime Hour</title><link>http://nipunbatra.github.io/2009/12/the-prime-hour/</link><description>&lt;p&gt;Just picked up a problem from Project euler.Problem no:10&lt;/p&gt;
&lt;p&gt;Here's the statement:&lt;/p&gt;
&lt;p&gt;Find the sum of prime numbers below 2 million.&lt;/p&gt;
&lt;p&gt;Now when next time someone tell you that algorithms are important pay
heed. I ran my program and ....&lt;/p&gt;
&lt;p&gt;it took about an hour to produce the result.The reqd answer
being:142913828922&lt;br /&gt;
Still figuring out how to solve it without using brute force.Prime
numbers have given me a lot of trouble of late,and am still trying hard
to find and implement better algorithm for generation of prime
numbers.If anyone's got a non-brute force solution,do leave it as a
comment here.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">nipunbatra</dc:creator><pubDate>Sun, 20 Dec 2009 10:41:00 +0530</pubDate><guid>tag:nipunbatra.github.io,2009-12-20:2009/12/the-prime-hour/</guid></item></channel></rss>