{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "from warnings import warn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "\n",
    "from nilmtk.feature_detectors import cluster\n",
    "from nilmtk.disaggregate import Disaggregator\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Fix the seed for repeatibility of experiments\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "class FHMM_across_homes(Disaggregator):\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    model : dict\n",
    "    predictions : pd.DataFrame()\n",
    "    meters : list\n",
    "    MIN_CHUNK_LENGTH : int\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = {}\n",
    "        self.predictions = pd.DataFrame()\n",
    "        self.MIN_CHUNK_LENGTH = 100\n",
    "        self.MODEL_NAME = 'FHMM'\n",
    "\n",
    "    def train(self, list_of_homes, list_of_appliances, min_activation=0.05, **load_kwargs):\n",
    "        \"\"\"Train using 1d FHMM.\n",
    "\n",
    "        Places the learnt model in `model` attribute\n",
    "        The current version performs training ONLY on the first chunk.\n",
    "        Online HMMs are welcome if someone can contribute :)\n",
    "        Assumes all pre-processing has been done.\n",
    "        \"\"\"\n",
    "        models = {}\n",
    "\n",
    "        for appliance in list_of_appliances:\n",
    "            print appliance, \"training\"\n",
    "            o = []\n",
    "            for building_num in list_of_homes:\n",
    "\n",
    "                building = ds.buildings[building_num]\n",
    "                elec = building.elec\n",
    "                try:\n",
    "                    df = elec[appliance].load(**load_kwargs).next().squeeze()\n",
    "                    appl_power = df.dropna().values.reshape(-1,1)\n",
    "                    activation = (df>10).sum()*1.0/len(df)\n",
    "                    if activation>min_activation:\n",
    "                        o.append(appl_power)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            if len(o)>1:\n",
    "                o = np.array(o)\n",
    "                mod = hmm.GaussianHMM(2, \"full\")\n",
    "                mod.fit(o)\n",
    "                models[appliance] = mod\n",
    "                print \"Means for %s are\" %appliance\n",
    "                print mod.means_\n",
    "            else:\n",
    "                print \"Not enough samples for %s\" %appliance\n",
    "        \n",
    "        self.individual = new_learnt_models\n",
    "        self.model = learnt_model_combined\n",
    "\n",
    "    def disaggregate_chunk(self, test_mains):\n",
    "        \"\"\"Disaggregate the test data according to the model learnt previously\n",
    "\n",
    "        Performs 1D FHMM disaggregation.\n",
    "\n",
    "        For now assuming there is no missing data at this stage.\n",
    "        \"\"\"\n",
    "        # See v0.1 code\n",
    "        # for ideas of how to handle missing data in this code if needs be.\n",
    "\n",
    "        # Array of learnt states\n",
    "        learnt_states_array = []\n",
    "        test_mains = test_mains.dropna()\n",
    "        length = len(test_mains.index)\n",
    "        temp = test_mains.values.reshape(length, 1)\n",
    "        learnt_states_array.append(self.model.predict(temp))\n",
    "\n",
    "        # Model\n",
    "        means = OrderedDict()\n",
    "        for elec_meter, model in self.individual.iteritems():\n",
    "            means[elec_meter] = (\n",
    "                model.means_.round().astype(int).flatten().tolist())\n",
    "            means[elec_meter].sort()\n",
    "\n",
    "        decoded_power_array = []\n",
    "        decoded_states_array = []\n",
    "\n",
    "        for learnt_states in learnt_states_array:\n",
    "            [decoded_states, decoded_power] = decode_hmm(\n",
    "                len(learnt_states), means, means.keys(), learnt_states)\n",
    "            decoded_states_array.append(decoded_states)\n",
    "            decoded_power_array.append(decoded_power)\n",
    "\n",
    "        prediction = pd.DataFrame(\n",
    "            decoded_power_array[0], index=test_mains.index)\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    def disaggregate(self, mains, output_datastore, **load_kwargs):\n",
    "        '''Disaggregate mains according to the model learnt previously.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mains : nilmtk.ElecMeter or nilmtk.MeterGroup\n",
    "        output_datastore : instance of nilmtk.DataStore subclass\n",
    "            For storing power predictions from disaggregation algorithm.\n",
    "        sample_period : number, optional\n",
    "            The desired sample period in seconds.\n",
    "        **load_kwargs : key word arguments\n",
    "            Passed to `mains.power_series(**kwargs)`\n",
    "        '''\n",
    "        load_kwargs = self._pre_disaggregation_checks(load_kwargs)\n",
    "\n",
    "        load_kwargs.setdefault('sample_period', 60)\n",
    "        load_kwargs.setdefault('sections', mains.good_sections())\n",
    "\n",
    "        timeframes = []\n",
    "        building_path = '/building{}'.format(mains.building())\n",
    "        mains_data_location = building_path + '/elec/meter1'\n",
    "        data_is_available = False\n",
    "\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "\n",
    "        for chunk in mains.power_series(**load_kwargs):\n",
    "            # Check that chunk is sensible size before resampling\n",
    "            if len(chunk) < self.MIN_CHUNK_LENGTH:\n",
    "                continue\n",
    "\n",
    "            # Record metadata\n",
    "            timeframes.append(chunk.timeframe)\n",
    "            measurement = chunk.name\n",
    "\n",
    "            # Start disaggregation\n",
    "            predictions = self.disaggregate_chunk(chunk)\n",
    "\n",
    "            for meter in predictions.columns:\n",
    "                meter_instance = meter.instance()\n",
    "                cols = pd.MultiIndex.from_tuples([chunk.name])\n",
    "\n",
    "                predicted_power = predictions[[meter]]\n",
    "                if len(predicted_power) == 0:\n",
    "                    continue\n",
    "                data_is_available = True\n",
    "                output_df = pd.DataFrame(predicted_power)\n",
    "                output_df.columns = pd.MultiIndex.from_tuples([chunk.name])\n",
    "                key = '{}/elec/meter{}'.format(building_path, meter_instance)\n",
    "                output_datastore.append(key, output_df)\n",
    "\n",
    "            # Copy mains data to disag output\n",
    "            output_datastore.append(key=mains_data_location,\n",
    "                                    value=pd.DataFrame(chunk, columns=cols))\n",
    "\n",
    "        if data_is_available:\n",
    "            self._save_metadata_for_disaggregation(\n",
    "                output_datastore=output_datastore,\n",
    "                sample_period=load_kwargs['sample_period'],\n",
    "                measurement=measurement,\n",
    "                timeframes=timeframes,\n",
    "                building=mains.building(),\n",
    "                meters=self.meters\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires tomorrow\n",
      "\n",
      "    After the trial mode has expired, if you want to use mkl thereafter,\n",
      "    please purchase a license at http://continuum.io\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nilmtk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nilmtk import *\n",
    "import os\n",
    "import nilmtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = DataSet(\"/Users/nipunbatra/Downloads/wikienergy-2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air conditioner training\n",
      "Means for air conditioner are\n",
      "[[    7.53691615]\n",
      " [ 1139.82086448]]\n",
      "fridge training\n",
      "Means for fridge are\n",
      "[[ 172.06615343]\n",
      " [  59.94911461]]\n",
      "washer dryer training\n",
      "Means for washer dryer are\n",
      "[[   0.36924346]\n",
      " [ 128.36346017]]\n",
      "spin dryer training\n",
      "Means for spin dryer are\n",
      "[[ 404.68524686]\n",
      " [   0.93259225]]\n",
      "dishwasher training\n",
      "Not enough samples for dishwasher\n",
      "microwave training\n",
      "Means for microwave are\n",
      "[[  4.07876205]\n",
      " [ 82.86502975]]\n",
      "furnace training\n",
      "Not enough samples for furnace\n",
      "washing machine training\n",
      "Means for washing machine are\n",
      "[[   0.65830403]\n",
      " [ 229.74056184]]\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "for appliance in [\"air conditioner\", \"fridge\", \"washer dryer\", \"spin dryer\", \n",
    "                  \"dishwasher\", \"microwave\",\"furnace\",\"washing machine\"]:\n",
    "    print appliance, \"training\"\n",
    "    o = []\n",
    "    for building_num in range(1, 190):\n",
    "        \n",
    "        building = ds.buildings[building_num]\n",
    "        elec = building.elec\n",
    "        try:\n",
    "            df = elec[appliance].load(cols=[('power','active')], sample_period=600).next().squeeze()\n",
    "            appl_power = df.dropna().values.reshape(-1,1)\n",
    "            activation = (df>10).sum()*1.0/len(df)\n",
    "            if activation>0.05:\n",
    "                o.append(appl_power)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if len(o)>1:\n",
    "        o = np.array(o)\n",
    "        mod = hmm.GaussianHMM(2, \"full\")\n",
    "        mod.fit(o)\n",
    "        models[appliance] = mod\n",
    "        print \"Means for %s are\" %appliance\n",
    "        print mod.means_\n",
    "    else:\n",
    "        print \"Not enough samples for %s\" %appliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nilmtk.disaggregate.fhmm_exact import sort_learnt_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_learnt_models = OrderedDict()\n",
    "for appliance, appliance_model in models.iteritems():\n",
    "    startprob, means, covars, transmat = sort_learnt_parameters(\n",
    "                    appliance_model.startprob_, appliance_model.means_,\n",
    "                    appliance_model.covars_, appliance_model.transmat_)\n",
    "    new_learnt_models[appliance] = hmm.GaussianHMM(\n",
    "                startprob.size, \"full\", startprob, transmat)\n",
    "    new_learnt_models[appliance].means_ = means\n",
    "    new_learnt_models[appliance].covars_ = covars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nilmtk.disaggregate.fhmm_exact import create_combined_hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learnt_model_combined = create_combined_hmm(new_learnt_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nilmtk.disaggregate.fhmm_exact import FHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = FHMM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f.model = learnt_model_combined\n",
    "f.individual = new_learnt_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(f, open( \"../fhmm_model.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = ds.buildings[191].elec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeterGroup(meters=\n",
       "  ElecMeter(instance=1, building=191, dataset='WikiEnergy', site_meter, appliances=[])\n",
       "  ElecMeter(instance=2, building=191, dataset='WikiEnergy', appliances=[Appliance(type='air conditioner', instance=1)])\n",
       "  ElecMeter(instance=3, building=191, dataset='WikiEnergy', appliances=[Appliance(type='spin dryer', instance=1)])\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = ds.buildings[191].elec.mains().load(cols=[('power','active')], sample_period=600).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n"
     ]
    }
   ],
   "source": [
    "preds = {}\n",
    "for building in range(191, 240):\n",
    "    print building\n",
    "    preds[building] = []\n",
    "    try:\n",
    "        iterator_mains_data = ds.buildings[building].elec.mains().load(cols=[('power','active')], sample_period=600)\n",
    "        for mains_df in iterator_mains_data:\n",
    "            pred = f.disaggregate_chunk(mains_df)\n",
    "            preds[building].append(pred)\n",
    "        out_df = pd.concat(preds[building])\n",
    "        out_df.to_csv(\"/Users/nipunbatra/Dropbox/ss_results/%d.csv\" %building)\n",
    "    except:\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-f79933d996af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mbuilding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuilding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'power'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'active'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "print building\n",
    "ds.buildings[building].elec.mains().load(cols=[('power','active')], sample_period=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-0efa9f9282ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m199\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'power'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'active'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "ds.buildings[199].elec.mains().load(cols=[('power','active')], sample_period=600).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = ds.buildings[193].elec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeterGroup(meters=\n",
       "  ElecMeter(instance=2, building=193, dataset='WikiEnergy', appliances=[Appliance(type='air conditioner', instance=1)])\n",
       "  ElecMeter(instance=3, building=193, dataset='WikiEnergy', appliances=[Appliance(type='spin dryer', instance=1)])\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.submeters().load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.207079013041\n"
     ]
    }
   ],
   "source": [
    "print (pred['refrigerator1'].sum()-df_26['refrigerator1'].sum())/df_26['refrigerator1'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianHMM(algorithm='viterbi', covariance_type='full', covars_prior=0.01,\n",
       "      covars_weight=1,\n",
       "      init_params='abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ',\n",
       "      means_prior=None, means_weight=0, n_components=2, n_iter=10,\n",
       "      params='abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ',\n",
       "      random_state=None, startprob=None, startprob_prior=1.0, thresh=0.01,\n",
       "      transmat=None, transmat_prior=1.0)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit([o[0].reshape(-1,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.        ],\n",
       "       [ 987.96043864]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "startprob = np.array([0.6, 0.3, 0.1, 0.0])\n",
    "# The transition matrix, note that there are no transitions possible\n",
    "# between component 1 and 3\n",
    "transmat = np.array([[0.7, 0.2, 0.0, 0.1],\n",
    "                     [0.3, 0.5, 0.2, 0.0],\n",
    "                     [0.0, 0.3, 0.5, 0.2],\n",
    "                     [0.2, 0.0, 0.2, 0.6]])\n",
    "# The means of each component\n",
    "means = np.array([[0.0,  0.0],\n",
    "                  [0.0, 11.0],\n",
    "                  [9.0, 10.0],\n",
    "                  [11.0, -1.0]])\n",
    "# The covariance of each component\n",
    "covars = .5 * np.tile(np.identity(2), (4, 1, 1))\n",
    "\n",
    "# Build an HMM instance and set parameters\n",
    "model = hmm.GaussianHMM(n_components=4, covariance_type=\"full\",\n",
    "                        random_state=42)\n",
    "\n",
    "# Instead of fitting it from the data, we directly set the estimated\n",
    "# parameters, the means and covariance of the components\n",
    "model.startprob_ = startprob\n",
    "model.transmat_ = transmat\n",
    "model.means_ = means\n",
    "model.covars_ = covars\n",
    "###############################################################\n",
    "\n",
    "# Generate samples\n",
    "X, Z = model.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianHMM(algorithm='viterbi', covariance_type='full', covars_prior=0.01,\n",
       "      covars_weight=1,\n",
       "      init_params='abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ',\n",
       "      means_prior=None, means_weight=0, n_components=4, n_iter=10,\n",
       "      params='abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ',\n",
       "      random_state=42, startprob=None, startprob_prior=1.0, thresh=0.01,\n",
       "      transmat=None, transmat_prior=1.0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.32035166e-01,   1.47944834e-01,   1.01478454e-01,\n",
       "          1.85415463e-02],\n",
       "       [  1.76165797e-01,   7.25388601e-01,   9.84454431e-02,\n",
       "          1.58890415e-07],\n",
       "       [  3.42950776e-02,   2.47572979e-01,   6.16853483e-01,\n",
       "          1.01278460e-01],\n",
       "       [  7.03806603e-01,   6.67735612e-08,   2.95388532e-01,\n",
       "          8.04797824e-04]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'refrigerator1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-19b17a560e61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'refrigerator1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2013'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"15T\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/nipunbatra/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1795\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1797\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nipunbatra/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1802\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionaility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nipunbatra/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nipunbatra/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2852\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nipunbatra/anaconda/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method)\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \"\"\"\n\u001b[1;32m   1571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1572\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3824)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3704)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12231)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'refrigerator1'"
     ]
    }
   ],
   "source": [
    "df['refrigerator1']['2013'].resample(\"15T\").head(10000).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
